\documentclass{sig-alternate}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}        % standard LaTeX graphics tool

\providecommand{\e}[1]{\ensuremath{\times 10^{#1}}}
\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{GECCO'13,} {July 6-10, 2013, Amsterdam, The Netherlands.}
    \CopyrightYear{2013}
    \crdata{TBA}
    \clubpenalty=10000
    \widowpenalty = 10000

\title{Effect of population size in heterogeneous and homogeneous machines in a distributed EA}

%\subtitle{[Extended Abstract]
%\titlenote{A full version of this paper is available as
%\textit{Author's Guide to Preparing ACM SIG Proceedings Using
%\LaTeX$2_\epsilon$\ and BibTeX} at
%\texttt{www.acm.org/eaddress.htm}}}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.


\numberofauthors{2}
 \author{
 \alignauthor
 Fergu, JJ, Pedro, Jesús, Maribel, Antonio\\
        \affaddr{Lost island}\\
        \affaddr{Unknown}\\
        \affaddr{Pacific Ocean}\\
        \email{jack,sawyer,hurley@lost.com}
 \alignauthor
 Carlos\\
 \affaddr{Lost island}\\
 \affaddr{Unknown}\\
 \affaddr{Pacific Ocean}\\
 \email{lock@lost.com}
 }

%\numberofauthors{2}
% \author{
% \alignauthor
% J.J. Merelo, A.M. Mora, C. M. Fernandes\\
%        \affaddr{University of Granada}\\
%        \affaddr{Department of Computer Architecture and Technology, ETSIIT}\\
%        \affaddr{18071 - Granada}\\
%        \email{jmerelo,amorag,cfernandes@geneura.ugr.es}
% \alignauthor
% Anna I. Esparcia-Alcázar\\
% \affaddr{S2 Grupo}\\
% \email{aesparcia@s2grupo.es}
% }


%\numberofauthors{4} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%

%\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
%\alignauthor
%Jack\\
%       \affaddr{Lost island}\\
%       \affaddr{unknow}\\
%       \affaddr{Pacific Ocean}\\
%       \email{jack_the_doctor@lost.com}
% 2nd. author
%\alignauthor
%Sawyer\\
%       \affaddr{Lost island}\\
%       \affaddr{unknow}\\
%       \affaddr{Pacific Ocean}\\
%       \email{sawyer_tom@lost.com}
% 3rd. author
%\alignauthor 
%Lock\\
%       \affaddr{Lost island}\\
%       \affaddr{unknow}\\
%       \affaddr{Pacific Ocean}\\
%       \email{lock@lost.com}
% 4rd. author
%\alignauthor 
%Hurley\\
%       \affaddr{Lost island}\\
%       \affaddr{unknow}\\
%       \affaddr{Pacific Ocean}\\
%       \email{hugo@lost.com}
%}

%\and  % use '\and' if you need 'another row' of author names
% 4th. author
%\alignauthor Lawrence P. Leipuner\\
%       \affaddr{Brookhaven Laboratories}\\
%       \affaddr{Brookhaven National Lab}\\
%       \affaddr{P.O. Box 5000}\\
%       \email{lleipuner@researchlabs.org}
% 5th. author
%\alignauthor Sean Fogarty\\
%       \affaddr{NASA Ames Research Center}\\
%       \affaddr{Moffett Field}\\
%       \affaddr{California 94035}\\
%       \email{fogartys@amesres.org}
% 6th. author
%\alignauthor Charles Palmer\\
%       \affaddr{Palmer Research Laboratories}\\
%       \affaddr{8600 Datapoint Drive}\\
%       \affaddr{San Antonio, Texas 78229}\\
%       \email{cpalmer@prl.com}
%}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
%\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
%email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
%(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
%\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle

\begin{abstract}
This paper shows a preliminary study about population size adaptation in an distributed genetic algorithm. This adaptation is done taking into account the computational power of an heterogeneous cluster. Two problems have been tested: MMDP and OneMax. Results show that setting this parameter decreases the time to obtain the optimum in both problems in heterogeneous clusters.
\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{G.1.6}{Mathematics of Computing}{NUMERICAL ANALYSIS}[Optimization]


%sures, performance measures
\terms{Algorithms}


\keywords{parameter setting, distributed algorithms, island model}


%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   INTRODUCTION   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Introduction}
\label{sec:intro}
%
New trends such as Cloud Computing \cite{CLOUD}, GRID \cite{GRID} or Service Oriented Science are leading to heterogeneous computational devices working at the same time. Distributed Evolutionary Algorithms (dEAs) have been proved in these systems with SUCCES?. A heterogeneous dEA can be seen as two points of view: a dEA where the parameters are different in each island (heterogeneous parameters) or the same algorithm in heterogeneous hardware. It also have been proved that this kind of algorithms even are more efficient in heterogeneous hardware configurations than in homogeneous devices \cite{HETEROGENEOUSHARD}. This can be explained by different reasons, such as different memory access times, caché, or even implementation languages or compilers in each machine, leading to different explotation rate of the search space. The heterogeneous parameters configuration also have been proved as more efficient that a fixed set of parameters for different problems \cite{HETEROGENEOUS}. The idea of this work is combine both systems adapting the population size of the islands to the heterogeneous hardware. Two different problems (MMDP and OneMax) have been used as a benchmark.



In this work, a proof-of-concept system has been developed to solve the next research questions:
\begin{itemize}
 \item QUE?
 \item Has the proposed adaptation of the population size to the computational power any effect in both systems?
 \item Is there any difference in homogeneous and heterogeneous clusters?
\end{itemize}


The rest of the work is structured as follows: after the state of
the art, we present the developed algorithms and experimental setting. 
Then, the results of the experiments are shown (Section \ref{sec:results}), followed by conclusions and suggestions for future work.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  SOA  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{State of the art}
\label{sec:soa}
%

Parameter setting and parameter control in Evolutionary Algorithms (EAs) refer to set the initial 

 In \cite{HETEROGENEOUSHARD} authors compare a distributed GA in homogeneous and heterogeneous clusters. Super-linear performance is obtained in the heterogeneous clusters, being more efficient that the same algorithm in homogeneous clusters. Some authors have expanded this idea adapting the algorithm to be executed: in \cite{HYDROCM} a distributed meta-heuristic executes simpler algorithms in simpler nodes. In \cite{HETEROTOPOLOGY} different configurations of heterogeneous machines for a tree topoly are studied. However, the heterogeneity is simulated in an homogeneous clusters. In the area of heterogeneous parameters, but homogeneous hardware, setting each island a random set of parameters can also increase the performance of a distributed Genetic Algorithm (dGA), as explained in \cite{RANDOMPARAMETERS}. That model outperformed a tuned canonical dGA with the same parameters in all islands. For our knowledge, there are not works that modify parameters of the GA depending of the node where the island is being executed.

%%%%%%%%%%%%%%%%%%  Experiments  %%%%%%%%%%%%%%%%%%%

\section{Experimental setup}
\label{subsec:experiments}
This section presents the parameters and systems to conduce the experiments.

The algorithm to improve is a steady-state distributed Genetic Algorithm (dGA). Parameters are described in Table \ref{table:parameters}. A ring topology has been used. Because the operating system heterogeneity the OSGiLiath framework \cite{OSGILIATH}, based in Java, has been used. Also, to avoid bottlenecks in distributed executions, asynchronous communication must be provided to avoid idle time. This kind of communication offers excellent performance when working with different nodes and operating systems, as demonstrated by \cite{HETEROGENEOUSHARD}. In our case the best individual is sent after a fixed number of generations. The transmission mechanism is based in ECF Generic server (over TCP). Two different parameters configurations have been used: 64 individuals per node (homogeneous size) and a different number of individuals proportional to the number of generations attained in this first homogeneous execution.


\begin{table}
\centering
\begin{tabular}{|c|c|} \hline
Name & Value\\ \hline
Total individuals & 256\\ \hline
Population size in HoSi & 64 \\ \hline
Population size in HeSi & 98 84 66 8\\ \hline
Crossover rate & 0.5\\ \hline
Mutation rate & 1/genome size\\ \hline
Selection & 2-tournament \\ \hline
Generations to migrate & 64 \\
\hline\end{tabular}
\label{table:parameters}
\caption{Parameters used}
\end{table}

The problems to evaluate are the Massively Multimodal Deceptive Problem (MMDP) and OneMax. The MMDP
\cite{goldberg92massive} is designed to be difficult for an EA, due to
its multimodality and deceptiveness. It is composed of $k$ subproblems of 6 bits each one ($s_i$). Depending of
the number of ones (unitation) $s_i$ takes the values shown in Table \ref{table:mmdp}.  

\begin{table}[h]

\centering
{\scriptsize
\begin{tabular}{|c|c|}
\hline
\texttt{Unitation}&\texttt{Subfunction value}\\
\hline
0 & 1.000000 \\
\hline
1 & 0.000000 \\
\hline
2 & 0.360384 \\
\hline
3 & 0.640576\\
\hline
4 & 0.360384\\
\hline
5 & 0.000000\\
\hline
6 & 1.000000\\
\hline

\end{tabular}
}
\caption{ Basic deceptive bipolar function ($s_i$) for MMDP
\label{table:mmdp}}
\end{table}
%%%%%%%%%%%%%%%%%%



The fitness value is defined as the sum of the $s_i$ subproblems with an optimum of $k$ (equation \ref{eq:mmdp}).
The search space is composed of $2^{6k}$ combinations from which there
are only $2^k$ global solutions with $22^k$ deceptive
attractors. Hence, a search method will have to find a global solution
out of $2^{5k}$ additionally to deceptiveness. In this work $k=25$

\begin{equation}\label{eq:mmdp}
\scriptsize
f_{MMDP}(\vec s)= \sum_{i=1}^{k} fitness_{s_i}
\end{equation}\\



To test the algorithm two different computational systems have been used: an {\em heterogeneous cluster} and an {\em homogeneous cluster}. The first one is formed by 4 different computers with different processors, operating systems and memory. The latter is a cluster formed by WHATEVER. Table \ref{tab:computers} shows the CARACTERISTICAS of each system.

\begin{table*}
\centering
\caption{Details of the clusters used.}
\begin{tabular}{|c|c|c|c|c|} \hline
Name 		 & Processor 	& Memory 	& Operating System  & Network  \\ \hline
\multicolumn{5}{|c|}{Homogeneous cluster} \\ \hline
Cluster node &			    &			&					&		  	\\ \hline
\hline
\multicolumn{5}{|c|}{Heterogeneous cluster} \\ \hline
N1	&			    &			&					&		  	\\ \hline
N2 	&			    &			&					&		  	\\ \hline
N3 	&			    &			&					&		  	\\ \hline
N4 	&			    &			&					&		  	\\ \hline
\end{tabular}
\label{tab:computers}
\end{table*}

Each different configuration has been tested 30 times. Acronyms for each configuration are HoSi (homogeneous population size), HeSi (heterogeneous population size), HoHa (homogeneous hardware) and HeHa (heterogeneous hardware).
%%%%%%%%%%%%%%%%%%  Results  %%%%%%%%%%%%%%%%%%%

\section{Results}
\label{sec:results}

As claimed by \cite{PARALLELEVALUATION} the number of evaluations can be misleading in the parallel algorithms area. In our case, for example, the evaluation time is different in each node of the heterogeneous cluster, and the real algorithm speed could not be reflected correctly. Also, the main interest in parallel programming is to reduce time. However, the number of evaluations has been added for comparison between the results of the HoHa system. It is difficult to compare between the HoHa and HeHa for the same reasons: the evaluation time is different in each system (and machine).

\subsection{MMDP Problem}

Table \ref{tab:resultsMMDP} shows the results for the MMDP problem. In the HeHa system, adapting the population to the computational power of each nodes makes the algorithm to end faster. The number of evaluations in this case is also lower. On the other hand, in the HoHa system, setting the same population sizes makes the system slower (although the number of evaluations is also decreased). ESTO ES DEBIDO A... These results are also show in the boxplots of the Figure \ref{fig:evalsMMDP} (evaluations) and Figure \ref{fig:timeMMDP} (time). Table \ref{tab:kruskal} shows the statistical significance of the results. First, a Kolmogorov-Smirnoff test is performed to asset the normality of the distributions. If the results are normal, then a Student's T-Test is performed. Otherwise, the non-parametric test Wilcoxon signed rank is applied. PONER CITAS GUAPAS.

\begin{table*}
\centering
\caption{Results for the MMDP problem.}
\begin{tabular}{|c|c|c|c|c|} \hline
Configuration	& Max. generations			& Total generations			& 	Total evaluations			& Time (ms) \\ \hline
HoSi/HeHa		& 146401,48	$\pm$ 65699,69	& 380967,25	$\pm$ 168568,84	& 24382416,51 $\pm$	10788405,87	& 136914,03 $\pm$ 60028,48\\ \hline
HeSi/HeHa		& 96051,5	$\pm$ 45110,90	& 289282,3	$\pm$ 135038,10	& 21784528,66 $\pm$	10161989,38	& 109875,76 $\pm$ 49185,51\\ \hline \hline
HoSi/HoHa		& 107334,46 $\pm$ 78167,19  & 393119,86 $\pm$ 241835,27	& 25273201,06 $\pm$ 15386663,12	& 237759,43 $\pm$ 178709,86\\ \hline
HeSi/HoHa		& 149732,6 $\pm$ 81983,74	& 438171,16	$\pm$ 240169,19	& 24430043,46 $\pm$ 13395037,34	& 245776,93 $\pm$ 134715,52\\ \hline

\end{tabular}
\end{table*}
%%%%CAMBIAR EL ORDEN!!!

%MMDP EVALS
%HomoSizeHomoHard-HomoSizeHeteroHard 22.83333     23.69541      FALSE
%HomoSizeHomoHard-HeteroSizeHomoHard  4.90000     23.69541      FALSE
%HomoSizeHomoHard-HeteroSizeHeteroHard 37.53333     23.69541       TRUE
%HomoSizeHeteroHard-HeteroSizeHomoHard 27.73333     23.69541       TRUE
%HomoSizeHeteroHard-HeteroSizeHeteroHard 14.70000     23.69541      FALSE
%HeteroSizeHomoHard-HeteroSizeHeteroHard 42.43333     23.69541       TRUE



\begin{figure}
\centering
\epsfig{file=images/evalsMMDP.eps, width = 9cm}
\caption{Number of evaluations for MMDP problem.}
\label{fig:evalsMMDP}
\end{figure}

\begin{figure}
\centering
\epsfig{file=images/timeMMDP.eps, width = 9cm}
\caption{Time to obtain the optimum in the MMDP problem (millis).}
\label{fig:timeMMDP}
\end{figure}

To see the difference of how the evolution is being performed, the average fitness in each node of HeHa is shown in Figures TAL. As can be seen...

\begin{figure}
\centering
\epsfig{file=images/homosize_heterohard_avg.eps, angle=-90, width = 9cm}
\caption{First 1000 millis of execution of the four nodes of the heterogeneous system with the same population sizes.}
\end{figure}

\begin{figure}
\centering
\epsfig{file=images/heterosize_heterohard_avg.eps, angle=-90, width = 9cm}
\caption{First 1000 millis of execution of the four nodes of the heterogeneous system with different population sizes.}
\end{figure}

\subsection{OneMax Problem}

Results for this problem are shown in Table \ref{tab:onemaxresults}. As before, in this problem, also changing the population sizes decreases the time in the heterogeneous cluster. However, in this case the number of evaluations remains the same (see statistical significance in Table \ref{tab:significance}). ESTO SE DEBE A... In the homogeneous system, the effect of changing this sizes is more evident, and this time the evaluations (and therefore, the time) are reduced (both significally). OneMax is PATATIN

\begin{table*}
\centering
\caption{Results for the OneMax problem.}
\begin{tabular}{|c|c|c|c|c|} \hline
Configuration	& Max. generations			& Total generations			& 	Total evaluations			& Time (ms) \\ \hline
HoSi/HeHa		& 4739,41$\pm$	305,32 		&	12081,51$\pm$	776,35 	&	773729,03$\pm$	49686,72 	&	72152,32$\pm$	4994,71 \\ \hline
HeSi/HeHa		&	3438,03 $\pm$	149,47 &	11277,33$\pm$	471,77 &	794157,73$\pm$	31843,10 	&	61870,2	$\pm$ 2518,74 \\ \hline
HoSi/HoHa		&	3133,36$\pm$	101,70 	&	12347,83$\pm$	394,99 	&	790773,33$\pm$	25279,52 	&	62105,03$\pm$	1964,75 \\ \hline
HeSi/HoHa		& 13897,86$\pm$	625,27 		&	20725,63$\pm$	929,43 	&	651952,8 $\pm$	29114,54	&	56120,53$\pm$	2491,92 \\ \hline
\end{tabular}
\label{tab:onemaxresults}
\end{table*}

\begin{figure}
\centering
\epsfig{file=images/evalsOneMax.eps, width = 9cm}
\caption{Number of evaluations for OneMax problem.}
\end{figure}

\begin{figure}
\centering
\epsfig{file=images/timeOneMax.eps, width = 9cm}
\caption{Time to obtain the optimum in the OneMax problem (millis).}
\end{figure}


\begin{table*}
\centering
\caption{Statistical significance of the results.}
\begin{tabular}{|c|c|c|c|c|} \hline

Configuration			&Normal	&Test applied			&P-value & Significant difference?\\ \hline
\multicolumn{5}{|c|}{Time for MMDP} \\ \hline
HoSi/HeHa vs HeSi/HeHa	&Yes	&T-Test			&0.032 	 & Yes \\ \hline
HoSi/HoHa vs HeSi/HoHa	&No		&Wilcoxon		&0.567 	 & No \\ \hline
\multicolumn{5}{|c|}{Evaluations for MMDP}	\\ \hline
HoSi/HeHa vs HeSi/HeHa	&Yes	&T-Test			&0.231  & No \\ \hline
HoSi/HoHa vs HeSi/HoHa	&No		&Wilcoxon		&0.958  & No \\ \hline
\multicolumn{5}{|c|}{Time for OneMax} \\ \hline
HoSi/HeHa vs HeSi/HeHa	& Yes	& T-Test		&  9\e{-15} & Yes \\ \hline
HoSi/HoHa vs HeSi/HoHa	& No	& Wilcoxon		& 	1\e{-6}		& Yes \\ \hline
\multicolumn{5}{|c|}{Evaluations for OneMax}	\\ \hline
HoSi/HeHa vs HeSi/HeHa	& No	& Wilcoxon 		&	0.14 		& No\\ \hline
HoSi/HoHa vs HeSi/HoHa	& No	& T-Test		&	2*\e{-27}	& Yes \\ \hline
\end{tabular}
\label{tab:significance}
\end{table*}

%\begin{table}
%\centering
%\caption{Frequency of Special Characters}
%\begin{tabular}{|c|c|l|} \hline
%Non-English or Math&Frequency&Comments\\ \hline
%\O & 1 in 1,000& For Swedish names\\ \hline
%$\pi$ & 1 in 5& Common in math\\ \hline
%\$ & 4 in 5 & Used in business\\ \hline
%$\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
%\hline\end{tabular}
%\end{table}


%\begin{figure}
%\centering
%\epsfig{file=fly.eps}
%\caption{A sample black and white graphic (.eps format).}
%\end{figure}
%
%\begin{figure}
%\centering
%\epsfig{file=fly.eps, height=1in, width=1in}
%\caption{A sample black and white graphic (.eps format)
%that has been resized with the \texttt{epsfig} command.}
%\end{figure}

%\begin{figure*}
%\centering
%\epsfig{file=flies.eps}
%\caption{A sample black and white graphic (.eps format)
%that needs to span two columns of text.}
%\end{figure*}


\section{Conclusions}
New trends, such as Cloud Computing or Service Oriented Architecture are providing BLABLA. This work shows a preliminary study about adapting the population size of an EA to computational power of different nodes in an heterogeneous cluster. Results show that adapting the population size decrease the execution time significally in heterogeneous clusters, while changing this parameter in homogeneous clusters not always performs better. This is a promising start for adapting EAs to the computational power of each machines.

In future work a scalability study will be performed, with more computational nodes and larger problem instances. Also, other parameters such as migration rate or crossover probability will be adapted to the computational nodes. This studies will lead to automatic adaptation during runtime, whith different nodes entering or exiting in the topology during the algorithm execution or adapting to system load.


%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This work has been supported in part by FPU research grant AP2009-2942 and projects AmIVital (CENIT2007-1010), EvOrq (P08-TIC-03903), UGR PR-PP2011-5 and TIN2011-28627-C04-02.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.


%\bibliographystyle{abbrv} CAMBIAR!!!!!!
\bibliographystyle{plain}
\bibliography{heterogeneous}  % sigproc.bib is the name of the Bibliography in this case


\end{document}