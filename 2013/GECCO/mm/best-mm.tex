\documentclass{sig-alternate}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}        % standard LaTeX graphics tool
\usepackage{url}

%Sacado del paper de Fergu

\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{GECCO'13,} {July 6-10, 2013, Amsterdam, The Netherlands.}
    \CopyrightYear{2013}
    \crdata{TBA}
    \clubpenalty=10000
    \widowpenalty = 10000

\title{Improving evolutionary solutions to the game of MasterMind
  using an entropy-based scoring method}

%\subtitle{[Extended Abstract]
%\titlenote{A full version of this paper is available as
%\textit{Author's Guide to Preparing ACM SIG Proceedings Using
%\LaTeX$2_\epsilon$\ and BibTeX} at
%\texttt{www.acm.org/eaddress.htm}}}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.


\numberofauthors{2}
 \author{
 \alignauthor
 Kuthrapalli, Wollowitz, Hofstadter\\
        \affaddr{Caltech}\\
        \affaddr{Pasadena}\\
        \email{k,w,h@geekysit.com}
 \alignauthor
 Farrah-Fawler\\
 \affaddr{Neurobiology Institute}\\
 \affaddr{Los Angeles}\\
 \email{amy@almostcompletelylost.it}
 }

%\numberofauthors{2}
% \author{
% \alignauthor
% J.J. Merelo, Pedro Castillo, Antonio Mora\\
%        \affaddr{University of Granada}\\
%        \affaddr{Department of Computer Architecture and Technology, ETSIIT}\\
%        \affaddr{18071 - Granada}\\
%        \email{jmerelo,amorag,cfernandes@geneura.ugr.es}
% \alignauthor
% Anna I. Esparcia-Alcázar\\
% \affaddr{S2 Grupo}\\
% \email{aesparcia@s2grupo.es}
% }


%\numberofauthors{4} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%

%\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
%\alignauthor
%Jack\\
%       \affaddr{Lost island}\\
%       \affaddr{unknow}\\
%       \affaddr{Pacific Ocean}\\
%       \email{jack_the_doctor@lost.com}
% 2nd. author
%\alignauthor
%Sawyer\\
%       \affaddr{Lost island}\\
%       \affaddr{unknow}\\
%       \affaddr{Pacific Ocean}\\
%       \email{sawyer_tom@lost.com}
% 3rd. author
%\alignauthor 
%Lock\\
%       \affaddr{Lost island}\\
%       \affaddr{unknow}\\
%       \affaddr{Pacific Ocean}\\
%       \email{lock@lost.com}
% 4rd. author
%\alignauthor 
%Hurley\\
%       \affaddr{Lost island}\\
%       \affaddr{unknow}\\
%       \affaddr{Pacific Ocean}\\
%       \email{hugo@lost.com}
%}

%\and  % use '\and' if you need 'another row' of author names
% 4th. author
%\alignauthor Lawrence P. Leipuner\\
%       \affaddr{Brookhaven Laboratories}\\
%       \affaddr{Brookhaven National Lab}\\
%       \affaddr{P.O. Box 5000}\\
%       \email{lleipuner@researchlabs.org}
% 5th. author
%\alignauthor Sean Fogarty\\
%       \affaddr{NASA Ames Research Center}\\
%       \affaddr{Moffett Field}\\
%       \affaddr{California 94035}\\
%       \email{fogartys@amesres.org}
% 6th. author
%\alignauthor Charles Palmer\\
%       \affaddr{Palmer Research Laboratories}\\
%       \affaddr{8600 Datapoint Drive}\\
%       \affaddr{San Antonio, Texas 78229}\\
%       \email{cpalmer@prl.com}
%}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
%\additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
%email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
%(The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
%\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle

\begin{abstract}
Solving the MasterMind puzzle, that is, finding out a hidden
combination by using hints that tell you how close some strings are to
that one is a combinatorial optimization problem that becomes
increasingly difficult with string size and the number of symbols used
in it. Since it does not have an exact solution, heuristic methods
have been traditionally used to solve it; these methods scored each
combination using a heuristic function that depends on comparing all
possible solutions with each other. In this paper we first optimize
the implementation of previous evolutionary methods used for the game
of mastermind, obtaining up to a 40\% speed improvement over
them. Then we study the behavior of an entropy-based score, which has
previously been used but not checked exhaustively and compared with
previous solutions. The combination of these two strategies obtain
solutions to the game of Mastermind that are competitive, and in some
cases beat, the best solutions obtained so far. All data and programs
have also been published under an open source license. 
\end{abstract}

% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
\category{G.1.6}{Mathematics of Computing}{NUMERICAL ANALYSIS}[Optimization]


%sures, performance measures
\terms{Algorithms}

\keywords{games, evolutionary algorithms, optimization, puzzles}


%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   INTRODUCTION   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Introduction and State of the Art}
\label{sec:intro}
%

Mastermind \cite{wiki:mm,Knuth,Widenius,Montgomery} is a puzzle in which one player $A$ hides a combination of
$\kappa$ symbols and length $\ell$ that the other player $B$ has to
discover by playing combinations coded in the same alphabet and with the same
length.  The answers from player $A$ to every combination include the number of
symbols in the combination that are in the correct position (usually
represented in the actual board game as {\em black} pins) and the
number of symbols that have been guessed correctly but are in a
different position ({\em white} pins). Player $B$ then
makes a new guess and obtains another answer; this process continues until
the hidden one is played by $B$; $B$ then receives as score the number of guesses
made; obviously, higher {\em score} is worse. $A$ and $B$ then interchange their positions. Eventually,
the scores are tallied and the one with the smaller number of guesses
made wins.  In the actual board game, symbols in the alphabet take the
shape of colored pins; that is why we usually talk about {\em colors}
instead of symbols. Historically, the  game which is actually played
by humans \cite{wiki:mm} uses
$\kappa=6$ symbols (or colors) and length $\ell=4$, with {\em Super Mastermind} versions with up
to $\ell=5$ pegs and $\kappa=8$ different colors. 

Solving this kind of puzzle is an exciting endeavor, because  it is a game in which almost any
computer strategy can beat a human, which use a very different
strategy \cite{laughlin1982selection,hubalovsky2012modeling} to play it. But the interesting
part is that solutions to
Mastermind can be applied easily to other games such as MineSweeper
\cite{legendre2012minesweeper} or Hangman since the structure of the game is the
same: probing a part of the search space by making a guess and getting a response from
whoever holds the secret. But its applications are not reduced to
other puzzles or games; solutions to Mastermind have also been used in
the following applications:\begin{itemize}
\item Focardi  \cite{focardi2011guessing} describes a method  to break
  ATMs guessing PINs via making requests to the application
  programming interface of the so-called HSM (hardware security
  modules) which are in charge of encryption in several phases of ATM transactions.
\item Gagneur and coauthors \cite{gagneur2011selective} describe its application
in a procedure called {\em selective phenotyping}. Since it's
impossible to find out the phenotype of a single gene, the only way of
doing it is via phenotyping of several groups of genes that include
the one we are interested in. The procedure  used to find this groups
of combinations of genes is in fact identical to the solution of the
game of Mastermind.
\item Mastermind can be used as a testbed for search algorithms, as
  claims the title of a paper by O\'Geran et
  al. \cite{o1991mastermind}. Strategies developed for Mastermind can
  be applied to other search algorithms as well.
\item Querying player $B$ for how close is the played combination to
  the hidden one and getting an answer is an example of {\em
    information leakage} \cite{chen2011auditing}, since $A$ reveals some info about its
  structure which can be eventually used to find it when enough
  information is available. This technique has been used to find out
  information about particular DNA codes belonging to a particular
  person, in what has been named {\em Mastermind} attack on genomic
  data \cite{goodrich2009mastermind,goodrich2012mtdna}.
 \end{itemize}

Being able to come up with an effective solution that can be applied
to all these problems is a good enough reason, but the generalized
Mastermind problem is also interesting from a theoretical point of
view, with several studies pointing to the fact that it is NP-Hard problem
\cite{DBLP:journals/corr/abs-1111-6922}. The issue of finding bounds to
the number of guesses needed is still open, although Doerr and Winzen
have lately improved in previously found (and rather loose, \cite{Chvatal}) bounds
\cite{doerr2012playing,doerr2012bb}. However, experimental methods are
very far from those bounds, obtaining the solution in a much lower
number of guesses; they are valuable, however, to give a hint on the
scaling of the solution complexity with the number of symbols and the
length. 

In the absence of exact methods, heuristic solutions such as the one studied
in this paper are, for the time being, the best approaches to solve
this problem; they are also the ones that present a better scalability
and are able to solve the problem to the largest problem size. 
These solutions fall mainly into two different types: exhaustive
(which can only solve versions of the game with a small number of
symbols and length due to memory limitations) and
approximate, which do not use (or at least try not to do it in the
general case) the whole search space. Any of them 
\cite{o1991mastermind,francisstrategies:moo,Berghman20091880,nicso}
seek first  combinations that match the answers made to $B$, and
thus could possible be the hidden code. These combinations are called {\em
    eligible}, {\em possible} or {\em
  consistent}. Those solutions are guaranteed to reduce the search space at
least by one, but obviously every one will yield a different
response from $A$, with one being possible optimal (since the set is
bound to include the hidden combination). The problem is that knowing which one is the best is, a
priori, impossible, and in fact how well any eligible combination will
do can only be guessed. 

How do we measure, them, how well a certain combination is going to
behave? 
% Exhaustive methods
% \cite{Knuth,DBLP:journals/corr/abs-1207-1315} would eliminate all
% non-consistent 
% solutions and play a consistent one, while approximate methods
% would sample the set of consistent solutions and play one of
% them, 
By assigning a {\em score} to every eligible combination (or every
combination the method knows of) which
reflects usually how well it will be able to reduce the search space
once played, with the rationale that a scoring method that reduces
quickly the search space will eventually yield a single eligible
combination, which in the case of exhaustive search will be the hidden
code and in approximate methods will be at least a good
candidate. This score will have to be computed using the only
information available to the method: the (possibly partial) set of all
eligible combinations. This set, besides possibly (surely, in case of
exhaustive search) including the hidden combination, has all the
information available to the method on the hidden combination.

So, to compute these scores, every combination is
compared in turn with the rest of the combinations in the set; the
number of combinations that get every response (there is a limited
amount of possible responses, from no blacks/no whites to $\ell -1$
blacks through all combinations of $\ell-p$ blacks and $p$ whites) is noted. Eventually this results in a
series of {\em partitions} in which the set of consistent combinations
is divided by its {\em distance} (in terms of common positions and
colors) to every other.  So, a {\em partition} is a subset of the set
of eligible combinations. All combinations in the eliglble set are
then defined by a list of the number of combinations that would obtain
every possible answer, and are scored according to this list. However,
there will be combinations that will have exactly the same list of
values (and thus be in the same {\em partition}), they will obviously
have the same score since they {\em partition} the set of eligible
combinations in the same way. Whatever scoring function we choose,
there will be a non-empty set of combinations with
the best score; one of the combinations of this set is chosen
deterministically (using lexicographical order, for instance) or
randomly to be played. 

Please note that these are heuristic methods based on expected
outcome. On average, they will work as expected, but even combinations
with the same score will obtain a different result depending, of
course, on which is the actual secret combination. Finding the best
one for a particular size, or even a particular set of combinations,
is an open issue which leaves room for research such as the one
performed in this paper. 

These partitions are used to assign a score to every combination;
several scores have been proposed:\begin{itemize}
\item {\em Worst case} was proposed by Knuth \cite{Knuth} as the first rigorous
  strategy to play Mastermind; combinations are scored according to
  the size of the biggest partition; the bigger, the worse. The
  combination to play is extracted from the set of those with the
  smallest biggest combination. Ties are broken by using the first in
  lexicographical order. 
\item {\em Most parts}, proposed in \cite{Kooi200513}, takes into account only the
  number of non-zero partitions. This was the option used by authors
  such as Merelo et al. \cite{mm:cig} in the area of evolutionary
  algorithms. It is fast to compute but it is not clear what is the
  rationale behind it, other than the fact that unlikely combinations
  (such as those with a single symbol) usually have low scores,
  besides, this score is a first approximation of 
\item {\em Entropy}  which has been used in works such as \cite{Neuwirth,bestavros,mm:ppsn:2010}, computes
  the entropy of partitions, and tries to maximize it. Combinations
  with a high entropy also have a high amount of information, which is
  related to the fact that a guess must try and extract the maximum
  information from the hidden guess. 
\item {\em Expected size} used by \cite{Berghman20091880,irving} tries to
  minimize the expected size; this one is related to the Worst Case
  mentioned in the first item and follows the same rationale: by
  playing the combinations that minimize the expected (as opposed to
  worst, in the case of Knut) size, the set of eligible combinations
  will be cut down eventually to one. 
\end{itemize}

However, scores are heuristic, so, for the time being and there is no rigorous way of
choosing the best score. Experiments so far show that the best strategies are Most parts and
Entropy, with no distinct advantage, for all problem sizes, of any one
of them
over the others \cite{nicso}; and even so, the best results published
so far use a the Expected Size strategy \cite{Berghman20091880}. In fact,
combinations of them are possible, according to
\cite{DBLP:journals/corr/abs-1207-1315}, but have not, so far, been
proved in problems where a sample of the consistent set is used (as
opposed to the whole set); besides, combining the above mentioned
scores is, in fact, a score, and nothing bars somebody with coming up
with a score different from the set mentioned above with the
constraint that it will still use the same information contained in
the consistent set (or a subset thereof).. Most
strategies, however, concentrate on finding the right size for
minimization of the number of turns. The complexity of the solving
algorithm, however, increases quadratically with the set size, since
it involves comparing every combination with the rest, which
implies that the time needed to find the solution and also number of
evaluations increase too fast with the search space size, resulting in a bad
scaling behavior, so using bounds on the set size has a big impact on
the behavior of the algorithm. 

If any method wants to improve over the state of the art, it has got
to be compared with teh paper by Berghman et al. in
\cite{Berghman20091880}. They obtained a system that is able to
find the solution in an average number of moves that is, for all sizes
tested, better than any solution previously published; the number of evaluations
was not published, but time was; this last is difficult to compare
(since software and hardware environment is different) but it will
give at least an order of magnitude (sub-second, seconds, minutes)
with which to compare new methods. Besides being the best solutions
found so far, they were very fast. As a point of fact,  some
researchers have tried to break the  search space with a high
dimension barrier by searching for fast solutions: Khalifa and Yampolsky
\cite{khalifa2011ga} were able to solve the length 8, 12 colors
($\ell=8,\kappa=12$) problem in just 8 seconds, but with an average
number of guesses equal to 25 (vs 20.571 seconds and 8.366 average
number of guesses). This probes than there are other ways to solve the
problem if you are not looking for the best solution, but it is not
the venue we will be pursuing in this paper, where we will try to
beat, at least from the point of view of guesses played.  

We will do so by looking at the problems with this approach: there were many parameters that had to be set for
each size, starting with the first guess and the size of the
consistent set, as well as population size and other evolutionary
algorithm parameters; some parameters are studied, but mainly for the
smallest size, while others, like the size of the sample of the
eligible set or the initial combination, are just mentioned for sizes
bigger than baseline. Changing the eligible set size might lead to
better (and possibly slower) solutions. Besides, as mentioned above,
Expected Size does not obtain good values in exhaustive search
methods, so we will use Entropy to score solutions. And finally, we
will try to optimize our method by profiling the application to
identify bottlenecks and iron them out of the implementation.
The Entropy scoring method has
resulted in good results for the smaller sizes
\cite{DBLP:journals/corr/abs-1207-1315} and \cite{mm:evostar13} but
needs a certain amount of parameter seeking to obtain good results. We
will show that our results are competitive and in some cases better
than those considered state of the art and published by Berghman et
al. \cite{Berghman20091880}. This is a small improvement, but
significant, and since we cannot be sure in advance of what is the
optimal value, it is in fact enough to prove this improvement even if
it is a few percentage points.

The rest of the paper is organized as follows: next we outline the
evolutionary method used to play MasterMind in Section
\ref{sec:evo}. Improvements obtained via profiling are shown in
Section \ref{sec:prof} followed by the results of using Entropy as
scoring method in Section
\ref{sec:entropy}. Finally, we draw some conclusions in the final
Section \ref{sec:conc}.


\section{An evolutionary method for playing MasterMind}
\label{sec:evo}

This paper uses the
method called, simply, {\em Evo}
\cite{evostar,mm:ppsn:2010,mm:cig,DBLP:conf/evoW/GuervosCM11,DBLP:conf/cec/GuervosMC11}
(as in EvoMastermind). This
method, which was  released  as open
source code at CPAN (the Comprehensive Perl Archive Network, available
at a mirror near you)
(\url{http://search.cpan.org/dist/Algorithm-Mastermind/}), is an
evolutionary algorithm that has been optimized for speed and number of evaluations.
Evolutionary algorithms \cite{Zen,Michalewicz,eiben03} are a Nature-inspired search and
optimization method that, modeling natural evolution and its molecular
base, uses a  population of solutions encoded into a data structure
(usually a string, but currently any data structure is used) to find the 
optimal one. Candidate solutions are scored according to its closeness to the optimal
solution (called {\em fitness}) and the whole population evolved by
discarding solutions with the lowest fitness and making those with the
highest fitness reproduce via combination (crossover) and random
change (mutation). It is proved that these algorithms are able, given
enough time and resources, to find {\em good enough} and even
optimal solutions to several problems in engineering
\cite{gecco08:pgarcia} and other fields such as economic forecasting \cite{wcci:bankruptcy}. 

Evo, which is explained extensively in
\cite{DBLP:conf/cec/GuervosMC11}, iterates the evolutionary algorithm
until a prefixed amount of consistent combinations has been found; in
this paper and following \cite{merelo12:gameon} that number has been
fixed to ten.  It uses Most Parts \cite{Kooi200513} to
score consistent combinations, and the {\em distance to consistency}
for non-consistent ones, so that the fitness directs search towards
finding consistent solutions and then towards higher-scoring
solutions. If the number of consistent solutions is below the
threshold, different from and stays so for several generations (fixed
to three), the best combination is played; if no feasible combination
is found for a fixed amount of generations (fixed to 50) the
population resets. This is a last-ditch solution which leads to a high
number of evaluations and, in some cases, to an endless loop or resets
which shows that, for that particular configuration, the evolutionary
algorithm is unable to find a solution. These problems are in part
overcome via endgames \cite{goddard2003computer,DBLP:conf/cec/GuervosMC11}, which
streamline the search for solution via different techniques. 

If we keep the consistent set size fixed we still have some parameters
to set, mainly two related ones: population and tournament size; this
size indicates how many combinations will be compared with each other
before selecting a single one to go to the reproduction pool and
selective pressure increases with its value; with a value such as
eight the probability of a low-fitness combination to be selected is
very low, while with a value equal to 2 (the minimum) there is a
certain probability that those combinations with low rankings will be
selected if they {\em joust} in the tournament with each other. The
relationship among both quantities has been well established by B\"ack
and coworkers in \cite{Back94selectivepressure}.

\begin{table}[t!]
\centering 
\caption{Values for the Evo parameters that obtain the best
  result. Permutation, crossover and mutation are {\em priorities};
  they are normalized to one to convert them to application rates. In
  practice, crossover will be applied to 80\% and mutation and
  permutation to 10\% of the newly generated combinations each. \label{tab:params}}
\begin{tabular}{lc}
\hline
Parameter & Value \\
\hline \\
Crossover  & 8 \\
Mutation  & 1 \\
Permutation  & 1 \\
Replacement rate  & 0.75 \\ 
\hline
\end{tabular}
\end{table}

In this paper we have made several improvements over the published
algorithm. We have profiled the application to improve speed, which
has resulted also in a change of the operators used in the
experiments. Second, we have studied several parameter configurations
to improve at the same time the number of evaluations (which results
also in a speed improvement) and the number of games played. And,
finally, we have used a different scoring method over previous papers
in a attempt to beat, or at least equal, the already published
results. 
%%%%%%%%%%%%%%%%%%  Experiments  %%%%%%%%%%%%%%%%%%%
\section{Profiling for performance enhancement}
\label{sec:prof}

\section{Using Entropy for combination scoring in evolutionary MasterMind}
\label{sec:entropy}


% \begin{table*}[t!]
% \centering
% \caption{Comparison among approaches in this paper: BS, Evo
%   and Berghman et al. \cite{Berghman09}. \label{tab:comparison-guesses}}
% \subfigure[Mean number of guesses with standard deviation;
% the quantities in parentheses indicate population and consistent set
% size (in the case of Evo++). The horizontal line
% indicates significant differences using Wilcoxon paired test. There
% is also significant difference for  $P=6,N=9$ between the two
% versions of Evo++, but not in the other case.\label{tab:moves}]{
% % Era 80 el tamaño de conjunto consistente que se usaba? Siempre es el
% % mismo? No se dice en ningún lado - JJ
% \begin{tabular}{lcc}

%                     &$P=5, N=8$ & $P=6,N=9$ \\
% \hline
% Berghman et al. &                                           & 6.475  \\
% \textsc{Evo++ (EN) }   & (1000,200) $ 5.555 \pm 0.011$ & (2000,200)
% $6.373 \pm 0.011$ \\
% \textsc{BS}  & $5.518 \pm  0.009$ &  $6.382 \pm 0.011 $ \\
% \hline
% \textsc{Evo++ (MP) }   & (1000,80) $ 5.602 \pm 0.012$ & (2000,200)
% $6.436 \pm 0.012$ \\

% \hline
% \end{tabular}
% }

% \subfigure[Mean number of evaluations with standard deviation;
% differences are always significant.\label{tab:evals}]{
% \begin{tabular}{lcc}

%                     &$P=5, N=8$ & $P=6,N=9$ \\
% \hline
% \textsc{Evo++ (EN) }   &  $ 26098 \pm 144$ & $67521 \pm 384$ \\
% \textsc{BS}  & $40619 \pm  115 $ &  $45478 \pm 168 $ \\
% \textsc{Evo++ (MP) }   & $20120 \pm 114$ & $68860 \pm 406$ \\

% \hline
% \end{tabular}
% }
% \end{table*}

\section{Conclusions}
\label{sec:conc}

Very beautiful work


%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}

Hidden for double-blind revision.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.


%\bibliographystyle{abbrv}
\bibliographystyle{plain}
\bibliography{GA-general,geneura,mastermind}  % sigproc.bib is the name of the Bibliography in this case


\end{document}