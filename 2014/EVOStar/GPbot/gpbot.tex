\documentclass[runningheads]{llncs}
\usepackage{amssymb}
\setcounter{tocdepth}{3}
\usepackage{graphicx,epsfig}
\usepackage{algorithmic}
\usepackage{listings}
\usepackage{rotating}
\usepackage{subfig}
\usepackage{algorithmic}

%%%%

\usepackage{color}
\usepackage{alltt}
\usepackage{verbatim}
\usepackage{url}
\usepackage[latin1]{inputenc}
%\usepackage[spanish]{babel}

%%

\usepackage{url}
\urldef{\mailsa}\path|pgarcia@atc.ugr.es|



\newcommand{\keywords}[1]{\par\addvspace\baselineskip
\noindent\keywordname\enspace\ignorespaces#1}

\lstset{
basicstyle=\ttfamily, %\scriptsize, QUITAR LA COMA DE TTFAMILY SI DESCOMENTAS
language=c++,
frame=single,
stringstyle=\ttfamily,
showstringspaces=false
}

\begin{document}
 %\pagestyle{empty} %ESTO QUITA LOS NUMEROS DE PAGINA
\mainmatter  % start of an individual contribution



% first the title is needed
\title{Difference of tree maximum depth in Genetic Programming to
  generate competitive agents for RTS games}
% Ein? No entiendo nada. ¿Quieres vender la diferencia de profundidad
% máxima?  - JJ

% a short form should be given in case it is too long for the running head
\titlerunning{Difference of tree maximum depth in GP to generate competitive agents for RTS games}
\author{P. Garc\'ia-S\'anchez, A. Fern\'andez-Ares, A. M. Mora,
  P. A. Castillo and J.J. Merelo}

%Doble ciego!!!!! - JJ
 
%

\authorrunning{P. Garc\'ia-S\'anchez et al.}

% (feature abused for this document to repeat the title also on left hand pages)
% the affiliations are given next; don't give your e-mail address
% unless you accept that it will be published

\institute{Dept. of Computer Architecture and Technology and CITIC-UGR, University of Granada, Spain 
\mailsa}




%\toctitle{BLABLABLA}
%ES ANONIMO????
% SÍ! - JJ
%\tocauthor{Authors' Instructions}
\maketitle


\begin{abstract}

This work presents the results obtained from comparing ... Results
show that 

% Por eso es por lo que tenéis que escribir el abstract antes que
% nada; para afinar el título y tener claro qué es lo qeu queréis
% probar. 

\end{abstract}


% En el GPBot tienes que hacer énfasis en que las estrategias probadas
% hasta ahora en este juego son tan buenas como la estrategia original
% que parametrizan; GPBot te permite no sólo conseguir estrategias
% mejores, sino descubrirlas. En los resultados tienes que hacer
% énfasis no sólo en lo obtenido, sino también en qué significan las
% estrategias, cómo juegan; tendrás que ponerlas a jugar a ver qué pasa.


\section{Introduction}
\noindent 

Real Time Simulators (RTS) are a type of videogame that... 



In this work we use Genetic Programming to obtain agents that play
Planet Wars game. We try to solve the next questions: % Breve
                                % explicación de GP, no es un congreso
                                % exclusivo de eso y no es tan
                                % conocido como GA en general - JJ

\begin{itemize}
\item Can a tree-generated behaviour of an agent defeat a hand-coded one whose parameters have been also optimized?
\item Can this agent beats a more complicated oponent that is adapted to the environment?
\item How does the maximum depth affects the results?
\end{itemize}

The rest of the work is structured as follows: after the state of the art, the description of our agent is presented in Section \ref{sec:agent}. Then, the experimental setup conduced with the EA are showed (Section \ref{sec:experiments}). Finally, results, conclusions and future works are discussed.


%%%%%%%%%%%%%%%%%%%%%%%%SEC SOA
\section{State of the art}
\label{sec:soa}

RTS games  (see \cite{Lara2013surey} for a survey). %surey o survey ?
                                %- JJ

Among other techniques, evolutionary Algorithms have been widely used in computational intelligence in RTS games \cite{Lara2013surey}. For example, for parameter optimization \cite{}, learning \cite{Kenneth2005neuroevolution} or content generation \cite{Mahlmann2012MapGeneration}. 

One of the most used games for study computational intelligence in RTS
is {\em Planet Wars}
\cite{Lara2013mapgenerator,Mora2012Genebot,FernandezAres2012adaptive}
% Recordad doble ciego - JJ
 because it is a simple RTS that defines a ... %esto no corresponde al
                                %estado del arte, sino a la
                                %introducción - JJ
 Although it has been described in previous works, we summarize saying that the objective of the player is to conquer enemy and neutral planets in a space-like simulator. Each player has planets that produce ships depending of a growth-rate and the player must send this ships to other planets (literally, crashing towards the planet) to conquer them. A player win if is the owner of all the planets. As requirements, each second a decission has to be made (turn), and no memory about the previous turns must be used. Figure \ref{fig:planets} show a screen capture of the game.

We have experimented with this game in previous works. For example, in
\cite{Mora2012Genebot} a hand-coded strategy was optimized using a
genetic algorithm for the strategy rates and percentages. The
hard-coded tree had a depth of 3 levels. % ein????? - JJ
  Results showed a good performance confronting with other bots
  provided by the Google AI Challenge. In our next work
  \cite{FernandezAres2012adaptive} we improved this agent optimizing
  in different types of maps and selecting the set of optimized
  parameters depending of the map where the game was taking place,
  using a tree of 5 levels. These results outperformed the previous
  version of the bot with 87\% of victories. % DOBLE CIEGO!!!! - jj

In this paper we use Genetic Programming to create the decission tree,
instead OF using our own gaming experience to model it, and compare
this agent with the two presented before. Genetic Programming has also
used in other kind of games, such as First Person Shoothers (FPS)
\cite{Esparcia2013GPunreal}. % POR FAVOR, meted a Paloma a bordo para
                             % que revise el inglés - JJ
                             % 


\section{Proposed Agent}
\label{sec:agent}


The proposed agent receives a tree to be executed. The generated tree
is a binary tree of expressions formed by two different types of nodes:

\begin{itemize}
\item {\em Decission}: a logical expression formed by a variable, a less than operator ($<$), and a number between 0 and 1.
\item {\em Action}: the leaves of the the tree. Each decission calls an method that indicates to which planet send a percentage of available ships (from 0 to 1) from the planet that executes the tree.
\end{itemize}

The different variables for the decissions are:

\begin{itemize}
\item {\em myShipsEnemyRatio}: Ratio between the player's ships and enemy's ships.
\item {\em myShipsLandedFlyingRatio}: Ratio between the player's landed and flying ships.
\item {\em myPlanetEnemyRatio}: Ratio between the number of player's planets and the enemy's ones.
\item {\em myPlanetsTotalRatio}: Ration between the number of player's planet and total planets (neutrals and enemy included)-
\item {\em actualMyShipsRatio}: Ratio between the number of ships in the specific planet that evaluates the tree and player's total ships.
\item {\em actualLandedFlyingRatio}: Ratio between the number of ships landed and flying from the specific planet that evaluates the tree and player's total ships.
\end{itemize}

The decission list is:
% ¿De dónde habéis sacado esto? También tienen una cierta estrategia
% presupuesta: que hay que elegir objetivos, por ejemplo - JJ
\begin{itemize}
\item {\em Attack Nearest (Neutral|Enemy|NotMy) Planet}: The objective is the nearest planet.
\item {\em Attack Weakest (Neutral|Enemy|NotMy) Planet}: The objective is the planet with less ships.
\item {\em Attack Wealthest (Neutral|Enemy|NotMy) Planet}: The objective is the planet with higher lower rate.
\item {\em Attack Beneficious (Neutral|Enemy|NotMy) Planet}: The objective is the planet more beneficious, that is the one with growth rate divided by the number of ships.
\item {\em Attack Quickest (Neutral|Enemy|NotMy) Planet}: The objective is the planet with higher facility to conquest: the lowest product between the distance from the planet that executes the tree and the number of the ships in the objective planet.
\item {\em Attack (Neutral|Enemy|NotMy) Base}: The objective is the planet with more ships (that is, the base).
\item {\em  Attack Random Planet}.
\item {\em Reinforce Nearest Planet}: Reinforce the nearest player's planet to the planet that executes the tree.
\item {\em Reinforce Base}: Reinforce the player's planet with higher number of ships.
\item {\em Reinforce Wealthest Planet}: Reinforce the player's planet with higher grown rate.
\item {\em Do nothing}.


\end{itemize}

An example of a possible tree is shown in Figure \ref{fig:java}.

\begin{figure}[tb] 
\begin{center}
\begin{lstlisting}
if(myShipsLandedFlyingRatio<0.796)
	if(actualMyShipsRatio<0.201)
		attackWeakestNeutralPlanet(0.481);
	else
		attackNearestEnemyPlanet(0.913);
else
	attackNearestEnemyPlanet(0.819);
\end{lstlisting}
\end{center}
\caption{Example of a generated Java tree.}
\label{fig:java}
\end{figure}

In each turn, the loop presented in Figure \ref{fig:pseudo} is executed.
\begin{figure}[htb]
\begin{algorithmic}
\STATE tree $\gets$ ReadTree()

\COMMENT {In each turn}
\LOOP
	
	\STATE calculateGlobalPlanets()
	\COMMENT{{\em for example Base, Enemy Base...}}
	\STATE calculateGlobalRatios ()
	\COMMENT {{\em for example myPlanetEnemyRatio, myShipsEnemyRatio...}}
		\FOR{each Planet: p}
			\STATE calculateLocalPlanets (p)
			\COMMENT{{\em for example NearestNeutralPlanet to planet p}}
			\STATE calculateLocalRatios (p)
			\COMMENT{{\em for example actualMyShipsRatio}}
			\STATE executeTree(p,tree)
			\COMMENT{{\em Send a percentage of the ships to another planet}}
		\ENDFOR
\ENDLOOP
\end{algorithmic}
\caption{Pseudocode of the proposed agent. The tree is fixed during all the agent's execution}
\label{fig:pseudo}
\end{figure}




\section{Experimental Setup}

To generate the tree we have used a Genetic Programming Algorithm with the parameters.

The fitness used is 

The selected bot to confront is {\em GeneBot}, proposed in our previous work \cite{Mora2012Genebot}. This bot was trained using a GA to optimize the 8 parameters that conforms a set of hand-made rules.

The used framework is OSGiLiath, a service-oriented evolutionary framework. The generated tree is compiled in real-time and injected in the agent's code using Java CAssist library. All the source code used is available under a LGPL V3 License in \url{http://www.osgiliath.org}.

\section{Results}

\section{Conclusions}
\label{sec:conclusion}

\bibliographystyle{splncs}
\bibliography{gpbot}

\end{document}

