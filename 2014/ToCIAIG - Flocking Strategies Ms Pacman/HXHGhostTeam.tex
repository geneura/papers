\documentclass[journal]{IEEEtran}
% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


\usepackage{ifpdf}
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  \usepackage[dvips]{graphicx}
  \DeclareGraphicsExtensions{.eps}
\fi
\graphicspath{{./pics/}}

\usepackage{algorithm}
\usepackage{cite}
\usepackage[cmex10]{amsmath}
\interdisplaylinepenalty=2500
\usepackage{amsfonts}
\usepackage{algorithmic}
\usepackage{array}
\usepackage{dblfloatfix}
\usepackage{subfig}
\usepackage{rotating}

\usepackage{url}
\urldef{\mailsa}\path|federico.liberatore@urjc.es|
\urldef{\mailsb}\path|{amorag, pacv, jmerelo}@geneura.ugr.es|

\begin{document}

\title{Comparing Heterogeneous and Homogeneous Flocking Strategies for the Ghost Team in the Game of Ms.\  Pac-Man}

\author{Federico Liberatore*, Antonio M. Mora, Pedro A. Castillo, Juan J. Merelo
\thanks{Manuscript submitted for review on \today.}%
\thanks{This work has been supported in part by CANUBE (CEI2013-P-14) and ANYSELF (TIN2011-28627-C04-02), awarded by the Spanish Ministry of Science and Innovation, and PYR-2014-17 included in GENIL - CEI BIOTIC (Granada). Liberatore's research was financed by the Government of Spain (TIN2012-32482). All the supports are gratefully acknowledged.}%
\thanks{Departamento de Arquitectura y Tecnolog\'ia de Computadores,
CITIC-UGR, ETSIIT,
University of Granada, Spain.}%
\thanks{E-mail addresses: \mailsa, \mailsb}%
\thanks{*Corresponding author.}}

\markboth{IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES,~Vol.~XX, No.~YY, MMMM YYYY}%
{Liberatore \MakeLowercase{\textit{et al.}}: Heterogeneous VS Homogeneous Flocking Team Learning in the Game of Ms.\  Pac-Man.}
\maketitle

\begin{abstract}
In the last year, thanks to the Ms.\  Pac-Man vs Ghosts competition, the
game of Ms.\  Pac-Man has gained increasing attention from academics in
the field of Computational Intelligence. In this work, we contribute
to this research stream by presenting a simple Lexicographic Genetic
Algorithm for the optimization of Flocking Strategy-based ghost
controllers. Flocking Strategies are a paradigm for intelligent agents
characterized by showing emergent behavior, and for having very little
computational and memory requirements, making it \textbf{well suited} for
commercial applications and mobile devices. In particular, we study
empirically the effect of optimizing homogeneous and heterogeneous
teams. The computational analysis shows that the Flocking
Strategy-based controllers generated by the proposed Lexicographic
Genetic Algorithm outperform other ghost controllers
included in the competition framework and presented in the
literature. 
\end{abstract}
\begin{IEEEkeywords}
Flocking Strategies, Genetic Algorithms, Lexicographic Optimization, Team Learning, Ms.\  Pac-Man.
\end{IEEEkeywords}

\section{Introduction}
\label{sec:Introduction}

\IEEEPARstart{I}{n} the last decade the game of Ms.\  Pac-Man has been recognized by the scientific community as an ideal testbed for computational intelligence methods, receiving an increasing interest from academics. This success is largely due to the Ms.\  Pac-Man vs Ghosts competition \cite{Lucas2009,MsPacManVSGhost2011}, running since 2009, where participants can submit controllers for either Ms.\  Pac-Man or the Ghost Team. A good number of the controllers proposed made use of Computational Intelligence techniques, such as Neural Networks (NNs) \cite{Rojas1996}, Genetic Algorithms (GAs) \cite{Goldberg1988}, Monte Carlo Tree Search (MCTS) \cite{Browne2012}, and Minimax algorithms \cite{Osborne1994}.

Recently, a GA for the design of controllers for the Ghost Team based on Flocking Strategies (FSs) has been proposed \cite{Liberatore2014}. FSs are sets of behavior rules (not related with Evolutionary Strategies) that determine the next move of an agent as a force resulting from the interaction of the agents in the game. Controllers based on FSs have very little computational and memory requirements and, therefore, are \textbf{well suited} for commercial applications and mobile devices, differently from MCTS, Minimax, and other search-based algorithms that rely on high computing power. The fitness function of the GA proposed by \cite{Liberatore2014} tested the candidate solutions against two basic Ms.\  Pac-Man controllers. The authors showed that the methodology was capable of modeling complex behaviors and generating effective and challenging agents. Nevertheless, considering only two basic Ms.\  Pac-Man controllers results in Ghosts controllers capable of reacting only to simple strategies. For this reason, in this work we increase the number of Ms.\  Pac-Man controllers included in the fitness function and we now evaluate the candidate solutions in the GA against eight Ms.\  Pac-Man controllers with different levels of complexity. This requires a complete redesign of the GA, to equate between global optimization and performance balance. Also, in this work we explore the paradigms of homogeneous and heterogeneous team learning. The performances of the controllers resulting from these two approaches are compared and empirical conclusions are drawn based on extensive experiments. \textbf{In order to support the conclusions reached, ANOVA statistical tests \cite{Fisher25,Fisher36} have been applied. ANOVA allows us to determine whether a change in the results of every metric is due to a change in a factor or to a random effect.  In this case, the factors to consider are the possible approaches (model). After applying ANOVA, if the test shows significative differences, post-hoc tests have been applied to find which factors are causing these differences. Tukey’s Honestly Significant Difference (HSD) \cite{Dickinson1971} has been used for this purpose.}

The rest of the paper is organized as follows. In the next section we describe the game of Ms.\  Pac-Man and present the most relevant contributions in the literature. Next, we illustrate the structure of the FSs applied to the game of Ms.\  Pac-Man and how to optimize their definition using a GA. The results of the computational experiments are reported and commented in Section \ref{sec:Experiments}. Finally, in Section \ref{sec:Conclusions} we draw some conclusions and highlight future opportunities to be pursuit in this line of research.

\section{Background}
\label{sec:Background}
In this section, the relevant background is provided. First, we present the game of Ms.\  Pac-Man and its characteristics. Next, a review of the works in the field of research is given.

\subsection{The game of Ms.\  Pac-Man}
\label{subsec:GameMsPacMan}
The game of Ms.\  Pac-Man is one of the many variants of the famous
Pac-Man game, released in 1981. Ms.\  Pac-Man  extends the mechanics of
the original with several features, the most interesting being
different ghosts' behavioral patterns and the inclusion of a random
movement to prevent the use of patterns to clear each round.

The game has been chosen for the Ms.\  Pac-Man vs Ghosts competition, an AI competition where participants can submit controllers for both Ms.\  Pac-Man and the Ghost Team. The controllers have directly opposing objectives. In fact, the objective of Ms.\  Pac-Man is to maximize the final score, while the objective of the Ghost Team is to minimize it. The version of the game implemented for the competitions differs slightly from the original one. A thorough description of the game rules can be found in \cite{MsPacManVSGhost2011}. For the purposes of this work, relevant restrictions for the Ghost Team are briefly listed in the following:
\begin{itemize}
  \item A ghost can never stop and, when it is in a corridor, it can only move forward.
  \item A ghost can choose its direction only at a junction. Specifically, a ghost can only move into a corridor different from the one it is coming from. As a result, a ghost cannot turn back on itself.
  \item Every time a ghost is at a junction the controller has to provide a direction (i.e., UP, DOWN, LEFT, or RIGHT) from the set of feasible directions, i.e., those directions corresponding to corridors different from the one the ghost is coming from. If no direction or an unfeasible direction is returned by the controller, the game framework chooses one randomly from the set of feasible directions.
  \item \textbf{On every time step, there is a small chance (set in the framework implementation to 0.15\%) that all the ghost must obligatorily reverse their direction.}
  \item After 4000 game ticks, a level is considered completed and the game moves on to the next level.
\end{itemize}

\subsection{State of the Art}
Most of the contributions in the literature focused on implementing and analyzing controllers for Ms.\  Pac-Man. In the last decade a number of Evolutionary Algorithms (EAs) have been proposed to address different aspects of the game of Ms.\  Pac-Man. One of the first works in the subject is the paper by Gallagher \cite{Gallagher03} that optimized rule-based \textbf{finite state machines} through population-based incremental learning to devise an adaptive Pac-Man agent. More recently, Galvan-Lopez \cite{Galvan-Lopez10} explored and compared the performance of two types of Grammatical Evolution (GE) mappings to generate controllers for Ms.\  Pac-Man. Alhejali and Lucas \cite{Alhejali10} applied \textbf{a }Genetic Programming (GP) to evolve a diverse set of behaviors using different versions of the game. The resulting controller proved to be competitive with the best reactive controllers reported at the time. In a subsequent article \cite{AlhejaliLucas11}, the same authors extended their work by applying a ``training camp framework'' to the GP, where a set of specialized behaviors is evolved according to specific training scenarios. A different approach is presented by Brandstetter and Ahmadi \cite{Brandstetter12} who proposed a set of GP-based controllers that rely exclusively on information retrieval terminals rather than action-issuing terminals. Also, their methodology evaluates each direction individually rather than simply taking a single collection of state features as input for each time step. Thawonmas \cite{Thawonmas10} applied a GA to optimize the parameters of the Ms.\  Pac-Man controller ICE Pambush 3, winner of the IEEE CEC 2009 Ms.\  Pac-Man competition. A number of authors made use of EAs to design NN-based controllers \cite{Lucas05,Burrow09,Keunhyun10}. Beside EA and GA, a wide range of other techniques have been applied, such as  Ant Colonies \cite{Emilio2010}, Monte Carlo methodologies \cite{Tong2010,Tong2011}, Monte Carlo Tree Search (MCTS) \cite{Samothrakis2011, Ikehata2011}, and Reinforcement Learning \cite{Bom2013}. Alhejali and Lucas \cite{Alhejali2013} applied genetic algorithm to enhance the performances of a Ms.\  Pac-Man agent created using MCTS, showing an impressive 18\% increase on the average score. Another hybrid approach is proposed by Schrum and Miikkulainen \cite{Schrum2014} that combines modular NNs with GAs. Each module of the NN specializes in a particular policy and the GA discovers these policies and defines when to use them. According to the authors, this methodology outperforms traditional NNs.

In the last years, a number of works specializing on the Ghost Team have been proposed. Nguyen and Thawonmas \cite{Nguyen2011,Nguyen2013} presented a controller based on MCTS where the behavior of Ms.\  Pac-Man is simulated. Their controller won the Ms.\  Pac-Man Versus Ghost Team Competition held in 2011. Svensson and Johansson \cite{Svensson2012} exploited the behavior emerging capabilities of Influence Maps. A significant number of works made use of EAs methodologies. Jia-Yue \emph{et al.} \cite{Jia-Yue11} applied NN-based controllers evolved through GAs. Gagné and Congdon \cite{Gagne2012} evolved \textbf{a} rule-based intelligent agent for the ghost team. Tamura and Torii \cite{Tamura2013} designed artificial ghost agents using GE. Cardona \textit{et al.} \cite{Cardona13} explored competitive co-evolution techniques to generate at the same time optimal Ms.\  Pac-Man and Ghost Team controllers. A different line of research is pursued by Sombat \textit{et al.} \cite{Sombat2012} that analyzed Ms.\  Pac-Man matches to classify Ghost Team controllers according to their enjoyability and, therefore, understand the attribute that a NPC should posses for players to be engaged. Similarly, Hasan and Khondker \cite{Hasan2013} explored the user friendliness of ghost controllers. In their research, they implemented a NN controller to assess the level of challenge that better suits the player.

Finally, evolved FSs were proposed for the first time by Liberatore \emph{et al.} \cite{Liberatore2014}.  Their structure is briefly presented in the following section, along with some new results regarding their computational complexity and two new focuses based on team learning paradigms.

\section{Models and Methods}
\label{sec:ModelsMethods}
This section is devoted to explaining the structure of the Ghost Team agents proposed, based on FSs. The paradigms of homogeneous and heterogeneous team learning are also presented and applied. 

\subsection{Flocking Strategies for the Ghost Team}
Swarm intelligence (SI) is the term used to describe the type of coordinated intelligence that arises from the collective behavior of decentralized, self-organized systems, either natural or artificial \cite{BeniWang89}. SI techniques have been widely used in many different fields \cite{Blum2008}.

Flocking refers to a SI technique proposed by Reynolds \cite{Reynolds87} for the coordinated movement of multiple AI agents. Originally, flocking algorithms were developed to mimic lifelike behaviors of groups of beings such as herds of animals, flocks of birds, swarms of insects, and schools of fishes. A flocking system typically consists of a population of simple agents (called boids) interacting locally with one another depending on the distance between them. The agents follow very simple steering behaviors:

\begin{itemize}
	\item \textit{Separation} makes the agent steer away from close flock mates.
	\item \textit{Alignment} makes the agent steer toward the average heading of the flock.
	\item \textit{Cohesion} makes the agent steer toward the average position of distant flock mates.
\end{itemize} 

Despite the lack of a centralized control structure dictating how
individual agents should behave, the interactions between such agents
lead to the emergence of  \textbf{``intelligent"} global behavior, unknown to the
individual agents \cite{SpectorEtAl03}. Given this desirable property,
the easiness of implementation, and the reduced computational cost,
flocking algorithms have been extensively applied to videogames
\cite{Scutt02}.

\begin{figure}[!t]
  \label{fig:Neigh_interaction}
  \centering
  \includegraphics[scale=0.5]{"neigh_inter"}
  \caption{Representation of the neighborhoods surrounding a ghost and of the interactions with other actors. The interaction of the ghost with other actors depends on the area they fall in. In this example, the ghost is attracted to Ms.\ Pac-Man and is repelled by the powepill. The movement of the ghost is determined by the sum of all the forces it is subjected to.}
\end{figure}

Fig. \ref{fig:Neigh_interaction} illustrates a simplified representation of the functioning of the FSs for the Ghost Team presented in the following. Each ghost is surrounded by concentric areas called neighborhoods. The neighborhoods are associated to a certain magnitude. If an actor (i.e., element of the game such as Ms.\ Pac-Man or other ghosts) is located inside a neighborhood, a certain force is applied to the ghost. The magnitude of the force depends on the neighborhood the actor falls in. The final behavior of the ghost results from the sum of all the forces it is subjected to. Its important to notice that the reaction of a ghost depends on its distance to the actors, and not on the actors movement. For example, if Ms.\ Pac-Man stays still, the ghosts will react according to the rules specified in the FS. A logical response would be moving toward her, unless a powepill is nearby. In the following, the elements comprising a FS for the Ghost Team are formally illustrated.

\subsubsection{Sets and Attributes}
\begin{itemize}
  \item $M=\{$UP, DOWN, LEFT, RIGHT$\}$, Set of moves, indexed by $m$. Subset $\overline{M}\subset M$ includes only the feasible moves, according to the restrictions on the ghosts' movement (please, refer to Section \ref{subsec:GameMsPacMan}).
  \item $G=\{$BLINKY, PINKY, INKY, SUE$\}$, Set of ghosts, indexed by $g$.
  \item $S=\{$HUNTER, HUNTED, FLASH$\}$, Set of ghosts' states, indexed by $s$. When in state HUNTER, a ghost is dangerous and kills Ms.\  Pac-Man when it touches her. HUNTED defines the state of a vulnerable ghost; in the game this is represented by the ghost turning deep blue. Vulnerable ghosts FLASH white to signal that they are about to become dangerous again.
  \item $A=\{$PACMAN, POWERPILL, HUNTER, HUNTED, FLASH$\}$, Set of types of actors, indexed by $a$. POWERPILL represents one of the four big pellets that, when eaten by Ms.\  Pac-Man, make the ghosts vulnerable. HUNTER, HUNTED, and FLASH refers to ghosts in that state. $\overline{A}$ is the set of actors currently in the game.
  \item $N \in \mathbb{N}$, A positive natural number representing the number of neighborhoods, indexed by\textbf{ $n  \in \{1, \ldots, N\}$}. Neighborhoods are areas centered on the current ghost. More specifically, the first neighborhood is a circle in Euclidean space, and each subsequent region is a ring. The interaction between the current ghost and an actor depends on which neighborhood the latter falls in, as explained in the following.
  \item $\mathbf{v}_g$ and $\mathbf{v}_a$, Two dimensional Euclidean vectors representing the position on the map of a ghost and an actor, respectively, in $(x,y)$ coordinate system. We define $dist(g,a)$ as the Euclidean distance between two position vectors.
\end{itemize}

\subsubsection{Representation}
A FS can be represented as a pair $(\boldsymbol\delta, \boldsymbol\alpha)$, explained in the following:
\begin{itemize}
  \item $\boldsymbol\delta \in \mathbb{R}_{>0}^N$, A vector of N real positive numbers. Each element $\delta_n$ is associated to one neighborhood and represents its maximum radius. Specifically, an actor $a$ falls into a neighborhood $n$ when its Euclidean distance to the current ghost $g$ is $\delta_{n-1} < dist(g,a) \leq \delta_n$. We assume that $\delta_0 = 0$, $\delta_N = \infty$, and $\delta_{n-1} < \delta_n < \delta_{n+1}$, i.e., each entry must be greater that its predecessor and lower than its successor.
  \item $\boldsymbol\alpha \in \mathcal{M}_{|S| \times |A| \times N}(\mathbb{R})$, A three dimensional matrix with real entries. The first dimension is associated to the state of the current ghost, the second to the type of the actor considered, and the third to the neighborhood where the actor falls in. Each element $\alpha_{s,a,n}$ represents the magnitude of the steering force on the current ghost resulting from the interaction with the actor. \textbf{A negative magnitude corresponds to the behavior of separation, while a positive magnitude corresponds to the behavior of cohesion.}
\end{itemize}

\subsubsection{Algorithm}
Every time a ghost is at a junction the game needs to calculate its next move. In a FS, the final behavior of the ghost is determined by the sum of all the behaviors resulting from the interactions with the other actors in the game. A controller based on FSs provides the next move by following these steps shown in Algorithm \ref{alg:FS_Controller}. For each actor $a$ in the game, the algorithm executes the following operations. First, it determines the neighborhood $n$ where the actor belongs. This is done by checking the distance between the ghost and the actor against the vector of radii, $\boldsymbol\delta$. Next, the steering force $\mathbf{f}^a$ is computed. The steering force is a two dimensional vector and is calculated as the product between the normalized positional difference vector between $g$ and $a$, and the appropriate magnitude, $\alpha_{s,a,n}$. Once all the steering forces have been calculated, the total steering force $\mathbf{f}$ is computed as their sum. The entries of this two dimensional vector are converted into a ranking for the moves: the first entry, corresponding to the x-axis, determines the rank for LEFT and RIGHT, while the second entry, corresponding to the y-axis, determines the rank for UP and DOWN. Finally, the algorithm returns the feasible move having maximum rank.

\begin{algorithm}[!t]
\begin{algorithmic}
\STATE $s\gets$ status of the current ghost $g$;
\FORALL{$a \in \overline{A}$}
	\STATE $n\gets n^\prime \ s.t.\ \delta_{n^\prime-1} < dist(g,a) \leq \delta_{n^\prime}$; \COMMENT{Determine the neighborhood.}
	\STATE $\mathbf{f}^a \gets \alpha_{s,a,n} \cdot \frac{\mathbf{v}_a - \mathbf{v}_g}{|dist(g,a)|}$; \COMMENT{Compute the steering force resulting from the interaction with the actor.}
\ENDFOR
\STATE $\mathbf{f} \gets \sum_{a \in \overline{A}} \mathbf{f}^a$; \COMMENT{Calculate the total steering force.}
\STATE \COMMENT{Translate the total steering force in a ranking for the next ghost direction as follows:}
\STATE $r_\text{UP} \gets - f_2$;
\STATE $r_\text{DOWN} \gets f_2$;
\STATE $r_\text{LEFT} \gets - f_1$;
\STATE $r_\text{RIGHT} \gets f_1$;
\RETURN $\arg\max_{m \in \overline{M}} r_m$; \COMMENT{Return the feasible direction (see restrictions in Section \ref{subsec:GameMsPacMan}) having maximum rank.}
\end{algorithmic}
\caption{Flocking Strategy-based Ghost Controller.}
\label{alg:FS_Controller} 
\end{algorithm}

The computational complexity of the algorithm is $O(|\overline{A}|N)$. $|\overline{A}|$ is the number of actors in the game, having a maximum value of eight, i.e., Ms.\  Pac-Man, three ghosts, and four power pills. Also the memory occupation is limited, as a FS can be represented with only $(N + |S| \times |A| \times N) = 16 \times N$ floats. Given the low computational and memory requirements, controllers based on FSs are particularly suited for commercial games, where the computational time allocated to AI operations is minimal, and machines having limited capabilities, such as portable and handheld devices.

\subsection{Team Learning}
A FS could be manually designed by an expert with decent results. Nevertheless, given the number of parameters and the inherent complexity of the game, it is desirable to automatize the definition of an effective strategy by means of an optimization algorithm. As the ghosts chase Ms.\  Pac-Man as a team, we look at team learning methodologies. In team learning \cite{Panait2005} the only learner involved is the team itself. This is different from multi-agent learning, where the single agents are trained separately. One of the main advantages of team learning is that it is possible to apply standard single-agent machine learning techniques. Moreover, it is not necessary to consider inter-agent credit assignment, i.e., identifying the contribution of each agent to the performance of the team.

Team learning can be divided into two main groups: homogeneous and
heterogeneous team learning. Homogeneous learners develop a single
agent behavior which is used by every agent on the team. Heterogeneous
learners can develop a unique behavior for each agent. Although it
generally leads to better solutions through agent specialization, it
is characterized by a larger state space that can complicate the learning process. It is also
 important to notice that agents can act heterogeneously even in
 homogeneous team learning, when the final behavior differs based on
 the agent's initial conditions. 

In this work, we explore the capabilities of homogeneous and heterogeneous FS for the Ghost Team. Specifically, we optimize the design of the FSs by means of a simple Lexicographic Genetic Algorithm (LGA). In the following section, the algorithm is presented.

\subsection{A Lexicographic Genetic Algorithm for Flocking Strategies}
Following out previous work \cite{Liberatore2014} we apply a basic LGA for the design of effective and resilient ghost controllers based on FSs. The main characteristics of the optimization algorithm are illustrated in the following.

\subsubsection{Individuals' Representation}
In this algorithm, an individual in the population (or a candidate solution) is represented by the FSs that compose it. In the case of homogeneous team learning, only one FS, $(\boldsymbol\delta, \boldsymbol\alpha)$, is necessary as all the ghosts will follow the same behavior. On the other hand, in heterogeneous team learning each ghost $g$ has an associated FS, $(\boldsymbol\delta^g,  \boldsymbol\alpha^g)$. Overall, in the heterogeneous team learning case, an individual is represented by four different FSs. Although the data structures for the heterogeneous case are four times bigger than the homogeneous ones, their total memory occupation is still very limited. In summary, an individual in the GA is represented as follows:

\begin{itemize}
  \item $(\boldsymbol\delta, \boldsymbol\alpha)$, for homogeneous team learning.
  \item $(\boldsymbol\delta^g, \boldsymbol\alpha^g)\: \forall g \in G$, for heterogeneous team learning.
\end{itemize}

We preserve the real encoding and the structure of the vector and of the matrix in the individuals' chromosomes.

\subsubsection{Initial Population}
The initial population is generated randomly as in Liberatore \emph{et al.} \cite{Liberatore2014}. More in detail, the entries of $\boldsymbol\delta$ follow a uniform distribution, while the elements of $\boldsymbol\alpha$ have a truncated normal distribution:

\begin{small}
\begin{equation}
	\label{eq:init_radius}
	\forall n \in \{1, \ldots, N\}, \: \delta_n \sim U(\delta_{n-1},\infty)
\end{equation}
\begin{equation}
	\label{eq:init_magnitude}
	\forall s \in S, a \in A,  n \in \{1, \ldots, N\}, \: \alpha_{s,a,n} \sim N(0,1/3), \alpha_{s,a,n} \in [-1,1]
\end{equation}
\end{small}

The parameters of the normal distribution have been set so as to generate most of the magnitudes close to zero and assign similar probabilities to the appearance of cohesion, separation, and no interaction behaviors. This has been done so as to have an initial population as heterogeneous as possible. For this reason, the normal distribution chosen has mean equal to zero (i.e., it is centered on the “no interaction” behavior) and standard deviation equal to 1/3, so as to assign approximately 1/3 of the probability to the occurrence of each behavior.

\subsubsection{Fitness Function}
To generate agents that perform well against a wide range of Ms.\  Pac-Man strategies, we calculate the fitness value of each individual by testing it against eight Ms.\  Pac-Man agents. Let $P=\{$NearestPillPM, StarterPM, InfluenceMapPM, MCTSPM, MixMaxPM, StarterExPM, ICEPFeatSpooks, ICEP-IDDFS$\}$, indexed by $p$, be the set of Ms.\  Pac-Man agents:

\begin{itemize}
  \item NearestPillPM, Basic controller included in the competition framework that moves Ms.\  Pac-Man to the closest pill, regardless of the state and position of the ghosts.
  \item StarterPM, Simple state machine based controller included in the competition framework.
  \item InfluenceMapPM, Influence Map-based controller \cite{Svensson2012}.
  \item MCTSPM, Enhanced MCTS controller \cite{Pepels2012}.
  \item MixMaxPM, Controller implementing a variation of the Minimax algorithm \cite{Cardona13}.
  \item StarterExPM, Another controller that combines the StarterPM and the MixMaxPM, giving a challenge factor between the two \cite{Cardona13}.
  \item ICEPFeatSpooks, Modified version of Spooks. Spooks was the winning Ms.\  Pac-Man entry for the CIG 2011 competition.
  \item ICEP-IDDFS, Very strong controller based on iterative deepening depth-first search, by Shirakawa, Nakamura and Thawonmas. As of this date, this controller ranks first in the Ms.\  Pac-Man vs Ghosts competition.
\end{itemize}

All the controllers not included in the competition framework were obtained by contacting their respective authors. The objective of the proposed GA is to design controllers that are efficient against a wide range of Ms.\  Pac-Man strategies, instead of focusing on just countering one or a few of them. Therefore, we would like to optimize the performance of our individuals against all the considered Ms.\  Pac-Man controllers. This objective can be expressed as:

\begin{equation}
\label{eq:minAllScores}
	\min \: \text{score}_p, \: \forall p \in P
\end{equation}

where $\text{score}_p$ represents the final score of the Ms.\  Pac-Man controller $p$. Equation \eqref{eq:minAllScores} is a multi-objective function (one objective for each Ms.\  Pac-Man controller) and it is not implementable as is. In fact, minimizing the performance of all the considered Ms.\  Pac-Man controllers might not be possible, as there could be trade-offs between them, i.e., increasing the effectivity of the Ghost Team against one Ms.\  Pac-Man controller might result in a loss of performance against another one. Therefore, the most realistic objective would be optimizing the FSs to obtain Ghost Team controllers whose performances are as balanced as possible:

\begin{equation}
\label{eq:minMaxScore}
	\min \: F_1 \: where \: F_1 = \max_{p \in P} \text{score}_p
\end{equation}

$F_1$ represents the highest score obtained by one of the Ms. Pac-Man controllers. Therefore, this value measures the worst performance of the Ghost Team controller. Equation \eqref{eq:minMaxScore} is concerned with finding a balance between the final scores of all the Ms.\  Pac-Man controllers. By minimizing the worst performance we can ensure both good performance and balance across all the Ms. Pac-Man controllers. Another benefit of this formulation is that it minimizes the effect of noise present in this problem (and in videogames in general) \cite{Mora12}. In fact, due to the stochastic elements of the game, the same FS could perform very well sometimes and quite bad some others. By choosing the worst (highest) score we reduce the effect of the noise introduced by these stochastic effects.

Although implementable, objective functions in the $\min \max$ form usually present a wide number of multiple optima\footnote{Multiple optima are different solutions having the same objective function value.} and produce solutions that are not efficient\footnote{A solution is efficient, or non-dominated, if none of the objective functions can be improved in value without degrading some of the other objective values.}. Therefore, to get an efficient one we consider a secondary objective function that optimizes for global performance.

\begin{equation}
\label{eq:minSquareScore}
	\min \: F_2 \: where \: F_2 = \sum_{p \in P} \text{score}_p^2
\end{equation}

$F_2$ is the sum of the squared scores obtained by the Ms. Pac-Man controllers. The squared term has been introduced to penalize high scores. Given the characteristics of the problem we propose a lexicographic objective function:

\begin{equation}
\label{eq:lexicographic}
	\text{Lex} \: \min [F_1,F_2]
\end{equation}

The lexicographic objective function proposed ensures that the performance of the Ghost controller is as optimized as possible, while keeping the worst performance to a minimum. In Lexicographic Optimization \cite{Dylan2010} the objectives can be ranked in the order of importance and they are not comparable directly, as in this case. \textbf{The lexicographic ordering makes $F_1$ more important than $F_2$}, i.e., we favor balance over global optimality. As a result, each individual in the population has an associated fitness vector, $\mathbf{F}=(F_1,F_2)$, which allows for a total order relation:

\begin{equation}
\label{eq:ordering}
	\mathbf{F}^A \succ \mathbf{F}^B \iff (F_1^A < F_1^B) \lor ((F_1^A = F_1^B) \land (F_2^A < F_2^B))
\end{equation}

where $\mathbf{F}^A$ and $\mathbf{F}^B$ are the fitness vectors associated to individuals A and B, respectively, and $\mathbf{F}^A \succ \mathbf{F}^B$ means that $\mathbf{F}^A$ is better than $\mathbf{F}^B$.

Once all the population individuals' fitness vectors have been calculated, we assign a rank-based fitness value. This is done by sorting the population according to the dominance criteria and then calculating a fitness value for each individual depending only on its position in the rank:

\begin{equation}
\label{eq:rankFitness}
	\text{Fitness}(\text{rank}) = \frac{\text{POP} - \text{rank}}{\text{POP}}
\end{equation}

where POP is the number of individuals in the population and rank is the position of an individual in this population, e.g., the least fit individual has $\text{rank} = \text{POP}$ while the fittest individual has $\text{rank} = 1$.

\subsubsection{Selection}
Individuals are selected by roulette wheel selection according to the rank-based fitness.

\subsubsection{Cross-Over}
In the proposed GA, two parents generate one child. The child's chromosome is created by random recombination of the parents' chromosomes. The entries of the neighborhood radius vector $\boldsymbol\delta$ and of the magnitude matrix $\boldsymbol\alpha$ in the chromosome of the child are evaluated individually. Each entry takes its value from one parent or the other according to a mixing probability.

In the case of heterogeneous team learning we apply restrictive
breeding, as Luke and Spector \cite{Luke1996} suggested that it works
better than having no restrictions. Restrictive breeding means that
that agents could only breed with like agents from other
teams. Applied to the context of this work, we allow crossover only
between the FSs corresponding to the same ghost; e.g., BLINKY breeds
only with BLINKY and PINKY only with PINKY, for instance.

\subsubsection{Mutation}
Mutation occurs with fixed probability. When a mutation happens, the current parameter is re-initialized to a random value, according to Equations \eqref{eq:init_radius} and \eqref{eq:init_magnitude}.

\section{Experiments}
\label{sec:Experiments}
The algorithms presented in this paper have been implemented in Java within the framework provided for the Ms.\  Pac-Man vs Ghosts competition. The final program ran on an Intel(R) Core(TM) i5-2500K @ 3.3GHz with four cores and 4GB of RAM. Each experiment ran on a single core. In order to ensure comparability, the same standard configuration of parameters for the LGA has been used for all the experiments:

\begin{itemize}
  \item Population = 50.
  \item Elitism = 1.
  \item Mutation probability = 0.01.
  \item Crossover mixing probability = 0.6.
\end{itemize}

\textbf{The GA is stopped when the best solution has not improved for 10 consecutive generations}, to ensure that a certain degree of convergence has been reached \cite{Karma2003, Safe2004}. Preliminary systematic experiments were made and results that improved on the solutions obtained in our previous work \cite{Liberatore2014} were achieved when using these parameters. In any event, the LGA can be run for any feasible configuration of the parameters.  We also changed the default configuration of the competition framework in the following way:

\begin{itemize}
  \item The event that forces the ghosts to obligatorily reverse their direction has been removed so as to ensure consistency in the evaluation of the candidate solutions' fitness\footnote{The FSs are completely deterministic and the seed used to initialize the pseudo-random number generator of the MCTSPM controller has been fixed to a determined value.}.
  \item The maximum duration of a game has been set to 4000 ticks, to reduce the computational time employed by the GA.
\end{itemize}

Overall, the following experiments have been done:

\begin{itemize}
  \item Comparison of the performance of the Ghost Team controllers obtained with different values of the parameter $N$ (i.e., the number of neighborhoods considered in the Flocking Rules) and team learning strategies.
  \item \textbf{Comparison with other ghosts controllers from the literature using the default configuration of the competition framework.}
\end{itemize}

\subsection{Performance Test}
The first experiment performed regards the comparison of the performance of the Ghost Team controllers obtained with different team learning strategies and different values of the parameter $N$. In principle, the best controllers should be obtained when heterogeneous team learning is applied and when high values of $N$ are used, as the solution space is bigger. Nevertheless, as the solution space increases, the actual performance of the LGA could get worse.

\textbf{In this set of experiments }we considered all the values of $N$ ranging from one to five. For each value we executed the LGA \textbf{30 times}.

\begin{table*} [!t]
\caption{Performance of the controllers for the Ghost Team obtained by the LGA using different numbers of neighborhoods. Each row is associated to a different number of neighborhoods, displayed in the first column. The second column presents the average computational time along with the obtained standard deviation. The third column shows the average number of generations across the \textbf{30 runs} and the corresponding standard deviation. The fourth column illustrates the fitness value $F_1$ of the best controller found in \textbf{30 runs}. Finally, the last column reports the average fitness value over \textbf{30 runs }and the corresponding standard deviation.}
\label{tab:summary}
\centering
\subfloat[Homogeneous team learning.]{
\begin{tabular}{|c|c|c|c|c|}
\hline 
$N$ & Avg. CPU Time (s) & Avg. Num. Generations & Best $F_1$ & Avg. $F_1$  \\
\hline
1	&	122248.47	$\pm$	55565.07	&	34.9	$\pm$	16.05	&	6080	&	8103.33	$\pm$	976.19	\\
\hline
2	&	112533.03	$\pm$	62606.83	&	32.37	$\pm$	18.17	&	5270	&	7636	$\pm$	1116.85	\\
\hline
3	&	107573.97	$\pm$	74309.52	&	30.63	$\pm$	21.06	&	4640	&	7874.33	$\pm$	1394.74	\\
\hline
4	&	113032.9	$\pm$	71085.52	&	31.97	$\pm$	19.95	&	4600	&	7043.1	$\pm$	1458.74	\\
\hline
5	&	129127	$\pm$	96368.21	&	36.67	$\pm$	27.2	&	5600	&	7658.67	$\pm$	1113.14	\\
\hline 
\end{tabular}
\label{tab:summary_HOM}
}
\hfil
\subfloat[Heterogeneous team learning.]{
\begin{tabular}{|c|c|c|c|c|}
\hline 
$N$ & Avg. CPU Time (s) & Avg. Num. Generations & Best $F_1$ & Avg. $F_1$  \\
\hline
1	&	102465.43	$\pm$	52588.54	&	30.1	$\pm$	15.74	&	6440	&	8666.33	$\pm$	884.29	\\
\hline
2	&	84105.77	$\pm$	31118.72	&	24.53	$\pm$	9.32	&	8150	&	9185.33	$\pm$	496.71	\\
\hline
3	&	90595.17	$\pm$	49189.03	&	26.57	$\pm$	14.89	&	7660	&	9262.33	$\pm$	616.98	\\
\hline
4	&	79240.8	$\pm$	45669.3	&	22.97	$\pm$	13.55	&	7870	&	9208.33	$\pm$	484.77	\\
\hline
5	&	100183.7	$\pm$	67116.26	&	29.37	$\pm$	20.14	&	7700	&	9204.33	$\pm$	586.4	\\
\hline 
\end{tabular}
\label{tab:summary_HET}
}
\end{table*}

Table \ref{tab:summary} shows the performance of the evolved controllers over \textbf{30 runs }of the LGA with $N=1,\ldots,5$ when applying homogeneous and heterogeneous team learning (Tables \ref{tab:summary_HOM} and \ref{tab:summary_HET}, respectively). Each row is associated to a different number of neighborhoods, displayed in the first column. The second column presents the average computational time along with the obtained standard deviation. The third column shows the average number of generations across the \textbf{30 runs }and the corresponding standard deviation. The following column illustrates the fitness value $F_1$ of the best controller found in the \textbf{30 runs}. A higher $F_1$ value corresponds to a lower ghosts' performance, and the other way round. Finally, the last column reports the average fitness value over the \textbf{30 runs }and the corresponding standard deviation. By observing the tables some conclusions can be drawn.
Concerning the computational time, we can see that a single run takes
quite a significant amount of time to complete (more than \textbf{28 hours}
on average). The reason for that is that the most advanced
Ms.\  Pac-Man controllers make use of all the allowed maximum
computational time for each game tick (40 ms). According to Table \ref{tab:summary} there does not seem to be a significant difference between the homogeneous and heterogeneous team learning strategies in terms of computational time.
\textbf{For the homogeneous team learning case the best controller and the best average fitness were obtained when $N=4$. On the other hand, for the heterogeneous team learning case the best controller and the best average fitness were found when $N=1$. }In both cases, no clear trend can be identified in the best and average fitness. 

\textbf{In order to support the conclusions reached in the analysis of previous experiments, statistical tests have been conducted for all the instances and approaches.  Firstly, ANOVA tests \cite{Fisher25,Fisher36} have been applied for evaluating every one of the metrics and indicators, considering each one of the approaches (model) as factors. The R tool has been used to obtain the ANOVA tables, which show, for each factor, the degrees of freedom(df), the value of the statistical F (F value) and its associated P value. If the output P is smaller than 0.05, then the factor effect is statistically significant at a 95\% confidence level. In the present study this would indicate that using different approaches give significative differences on the metric results. Post-hoc tests might be used to determine which approaches are significantly different from which other.  In that sense, one of the most widely used post-hoc test is Tukey’s Honestly Significant Difference test \cite{Dickinson1971}. Tukey HSD is a versatile, easily calculated technique that might be used after ANOVA and allows determining exactly where the significant differences are. However, it can only be used when ANOVA has found a significant effect. Otherwise, if the F value for a factor turns out non-significant, the further analysis is not needed.}

\textbf{In this statistical analysis we consider a group for each combination of team strategy (i.e., homogeneous or heterogeneous) and value of the parameter $N$. Each group is comprised of 30 observations. The results of our statistical tests are reported in the following. An analysis of variance showed that the computational time is not affected by the group, $F(9,290) = 1.85$, $p = 0.06$. On the other hand, an analysis of variance showed that the solution value is affected by the group, $F(9,290) = 27.94$, $p < 2e-16$.  Post hoc analyses using the Tukey HSD method indicated that the fitness value is significantly better for the homogeneous strategies than for the heterogeneous strategies, when $N = 2, \ldots, 5$ (for the average and the standard deviation of the fitness values please refer to Tables \ref{tab:summary_HOM} and \ref{tab:summary_HET}). The p-values are provided in the following:}

\begin{itemize}
\item $N=1$, $p = 0.6811462$.
\item $N=2$, $p = 0.0000183$.
\item $N=3$, $p = 0.0002246$.
\item $N=4$, $p = 0.0000000$.
\item $N=5$, $p = 0.0000001$.
\end{itemize}

\textbf{Regarding the effect of increasing the number of neighborhoods, no clear conclusion can be drawn. In fact, post hoc analyses using the Tukey HSD method indicated significant differences in the fitness value only in the homogeneous case for the following values of $N$ (for the average and the standard deviation of the fitness values please refer to Table \ref{tab:summary_HOM}):}

\begin{itemize}
\item $N=1$ and $N=4$, $p = 0.0354767$.
\item $N=1$ and $N=5$, $p = 0$.
\item $N=2$ and $N=5$, $p = 0.$.
\item $N=3$ and $N=4$, $p = 0.02531989$.
\item $N=3$ and $N=5$, $p = 0$.
\item $N=4$ and $N=5$, $p = 0$.
\end{itemize}

\subsection{Comparison with Other Controllers}
To understand the goodness of the ghost controllers generated by the LGA we compare the performance of the best controller found by the LGA to that of other controllers taken from the competition framework and the literature. All the controllers not included in the competition framework were obtained by contacting their respective authors. \textbf{In this set of experiments, the fitness values for the Ghost controllers have been calculated by applying the same conditions enforced in the competition:
\begin{itemize}
\item On every time step, there is a small chance (0.15\%) that all the ghost must obligatorily reverse their direction.
\item A game ends after 24000 game ticks.
\end{itemize}}

\textbf{Given the presence of the global random reverse event, every controller has been run 100 times. Table \ref{tab:summary_others} shows the average and the standard deviations of the $F_1$ fitness scores obtained by the controllers.}

\begin{table} [!t]
\caption{Comparison of the performance of the best Ghost Team controllers found by the LGA and other controllers from the competition framework and the literature. Each row is associated with a Ghost Team controller, displayed in the first column. The second column presents the average fitness value $F_1$ obtained by each controller. The third column shows the fitness value $F_1$ standard deviation. For the sake of comparison, the controllers are sorted in decreasing order of performance.}
\label{tab:summary_others}
\centering
\begin{tabular}{|c|c|c|}
\hline 
Controller & Avg. $F_1$ & $F_1$ St. Dev.\tabularnewline
\hline  
Memetix & 5743.9 & 1331.96\tabularnewline
\hline 
EIISolver & 12333.8 & 3363.13\tabularnewline
\hline 
LGA & 31135.65 & 5951.95\tabularnewline
\hline 
Legacy2TheReckoning & 77565.4 & 6019.36\tabularnewline
\hline 
Legacy & 78215.8 & 5855.50\tabularnewline
\hline 
StarterGhosts & 82450.8 & 6847.75\tabularnewline
\hline 
InfluenceMapGhosts \cite{Svensson2012} & 89241 & 7044.92\tabularnewline
\hline 
AggressiveGhosts & 128151.8 & 7571.26\tabularnewline
\hline 
\end{tabular}
\end{table}

\textbf{An analysis of variance showed that there are significant differences between the controllers performance, $F(7,792) = 5284$, $p <2e-16$. Post hoc analyses using the Tukey HSD method indicated that all the differences are significant, except for the groups Legacy and Legacy2TheReckoning that have almost identical performance, $p = 0.99375$.
EIISolver and Memetix won, respectively, the first and the second place in the CIG 2012 competition \cite{CompetitionURL}. As expected, these two controllers produced the best results. More specifically, Memetix obtained an average fitness of 5743.9, while the average fitness of EIISolver is more than twice this value.
The best controller identified by the LGA comes in third position. However, its average fitness is almost three times that of EIISolver and more than 5 times that of Memetix. A way to improve the performance of the Ghost Team devised by the LGA would be extending the fitness evaluation method by performing long runs of the game (24000 game ticks instead of 4000) and including the random direction reverse event. This is left for future research. It is also important to notice that both Memetix and EIISolver heavily rely on computational power, and therefore could not be effectively run on low-power devices. On the other hand, FS-based controllers are extremely efficient in terms of memory and computational time and could be included in videogames devised for portable and handheld devices.}

\section{Conclusions}
\label{sec:Conclusions}
In this article, we extended the research on the controller for the Ghost Team by proposing a basic LGA for the effective design of ghosts agents. We analyzed the complexity of a FS controller in terms of memory and computational effort, showing that they are both very small. Therefore, FSs find natural application in all the contexts where both the computational time and the memory consumption are critical, such as commercial games and handheld devices.

We took a step forward from the work in Liberatore \emph{et al.} \cite{Liberatore2014} by including eight Ms.\  Pac-Man controllers having different degrees of complexity in the fitness function. This required a redefinition of the fitness function. We proposed a lexicographic function that assigns high priority to balance and low priority to global performance. We showed empirically that the resulting Lexicographic Genetic Algorithm is capable of generating effective and challenging ghost controllers, having better performance than other controllers included in the competition framework or presented in the literature.

There is still a lot to be investigated to ascertain the real capabilities of the FSs. Some possible future lines of research are highlighted in the following.

As showed in the experiments, a single run of the LGA takes a significant amount of computational time. Strategies for its reduction should be explored. An initial step could be doing a profiling of the program. Also, the sensitivity of the performance of the LGA to the parameters used should be analyzed.

The proposed LGA provided satisfactory results for the homogeneous team learning case. Nevertheless, in the heterogeneous team learning case, no satisfactory solutions were obtained. A deeper convergence analysis could be the topic of a future research. Also, possible approaches that need to be investigated are: first, to warm-start the heterogeneous team GA by using good homogeneous teams and, second, to implement mutation operators that make large changes to the canditate solution, such as replacing the behavior of one ghost with a copy of the behavior of other ghost.  Optimization methodologies other than GAs could be investigated. Covariance Matrix Adaptation Evolution Strategies (CMA-ES) and Particle Swarm Optimization (PSO) might be sensible choices, as no assumption on the objective function or on the problem are made.

One of the main drawbacks of the fitness function adopted in this work is the amount of time required to evaluate the performance of one individual against eight different Ms.\  Pac-Man controllers. This is mostly due to the time consumption of the controllers based on minimax algorithm and other exploratory methods. Therefore, it could be interesting to co-evolve two distinct populations of ghosts and Ms.\  Pac-Man controllers based on FSs. This would speed up the time taken to compute the fitness of the individuals, allowing for more iterations in the optimization process. Potentially, this could lead to finding better controllers for the Ghost Team.

\textbf{Finally, using distance metrics other than the Euclidean distance (e.g., shortest path distance) in the FS could lead to better controllers.}

We hope that this work will be a useful source of ideas for future research on computational intelligence algorithms in games and will contribute further in the development and solution of more complex problems.

\section*{Acknowledgment}
Liberatore would like to thanks the GeNeura research group at
University of Granada for their kind hospitality during his visit.

\bibliographystyle{IEEEtran}
\bibliography{GhostsGA}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

%\begin{IEEEbiography}{Michael Shell}
%Biography text here.
%\end{IEEEbiography}

% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

%\begin{IEEEbiographynophoto}{Jane Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}

\end{document}


