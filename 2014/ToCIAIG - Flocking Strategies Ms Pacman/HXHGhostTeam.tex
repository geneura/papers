\documentclass[journal]{IEEEtran}
% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


\usepackage{ifpdf}
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  \usepackage[dvips]{graphicx}
  \DeclareGraphicsExtensions{.eps}
\fi
\graphicspath{{./pics/}}

\usepackage{cite}
\usepackage[cmex10]{amsmath}
\interdisplaylinepenalty=2500
\usepackage{amsfonts}
\usepackage{algorithmic}
\usepackage{array}
\usepackage{dblfloatfix}
\usepackage{subfig}
\usepackage{rotating}

\usepackage{url}
\urldef{\mailsa}\path|federico.liberatore@urjc.es|
\urldef{\mailsb}\path|{amorag, pacv, jmerelo}@geneura.ugr.es|

\begin{document}

\title{Comparing Heterogeneous and Homogeneous Flocking Strategies for the Ghost Team in the Game of Ms. Pac-Man}

\author{Federico Liberatore*, Antonio M. Mora, Pedro A. Castillo, Juan J. Merelo
\thanks{Manuscript submitted for review on \today.}%
\thanks{This work has been supported in part by CANUBE (CEI2013-P-14) and ANYSELF (TIN2011-28627-C04-02), awarded by the Spanish Ministry of Science and Innovation. Liberatore's research was financed by the Government of Spain (TIN2012-32482). All the supports are gratefully acknowledged.}%
\thanks{Departamento de Arquitectura y Tecnología de Computadores,
CITIC-UGR, ETSIIT,
University of Granada, Spain.}%
\thanks{E-mail addresses: \mailsa, \mailsb}%
\thanks{*Corresponding author.}}

\markboth{IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES,~Vol.~XX, No.~YY, MMMM YYYY}%
{Liberatore \MakeLowercase{\textit{et al.}}: Heterogeneous VS Homogeneous Flocking Team Learning in the Game of Ms. Pac-Man.}
\maketitle

\begin{abstract}
In the last year, thanks to the Ms. Pac-Man vs Ghosts competition, the
game of Ms. Pac-Man has gained increasing attention from academics in
the field of Computational Intelligence. In this work, we contribute
to this research stream by presenting a simple Multi-Criteria Genetic
Algorithm for the optimization of Flocking Strategy-based ghost
controllers. Flocking Strategies are a paradigm for intelligent agents
characterized by showing emergent behavior, and for having very little
computational and memory requirements, making it extremely suited for
commercial applications and mobile devices. In particular, we study
empirically the effect of optimizing homogeneous and heterogeneous
teams. The computational analysis shows that the Flocking
Strategy-based controllers generated by the proposed Multi-Criteria
Genetic Algorithm are robust and outperform other ghost controllers
included in the competition framework and presented in the
literature. 
\end{abstract}
\begin{IEEEkeywords}
Flocking Strategies, Genetic Algorithms, Multi-criteria Decision Making, Team Learning, Ms. Pac-Man.
\end{IEEEkeywords}

\section{Introduction}
\label{sec:Introduction}

\IEEEPARstart{I}{n} this paper, we illustrate a methodology to generate Flocking Strategies (FSs) for the Ghost Team in the game of Ms. Pac-Man, within the framework of team learning. The paradigms of homogeneous and heterogeneous team learning are applied. The performances of the controllers resulting from these two approaches are compared and empirical conclusions are drawn based on extensive experiments.

In the last decade the game of Ms. Pac-Man has been recognized by the scientific community as an ideal testbed for computational intelligence methods, receiving an increasing interest from academics. This success is largely due to the Ms. Pac-Man vs Ghosts competition \cite{Lucas2009,MsPacManVSGhost2011}, running since 2009, where participants can submit controllers for either Ms. Pac-Man or the Ghost Team. Recently, a Genetic Algorithm (GA) for the design of controllers for the Ghost Team based on FSs have been proposed \cite{Liberatore2014}. The fitness function of the GA tested the candidate solutions against two basic Ms. Pac-Man controllers. Nevertheless, the authors showed that the methodology was capable of modeling complex behaviors and generating effective and challenging agents.

In this work we expand on this line of research in a number of ways. First, we test the candidate solutions in the GA against eight Ms. Pac-Man controllers with different levels of complexity. Second, given the high number of controllers included, we redesigned the objective function to equate between global optimization and performance balance, drawing from Multi-Criteria Decision Making (MCDM) theory. Third, we apply and study empirically two team learning strategies, namely, homogeneous and heterogeneous team learning. This represents the main contribution of the paper.

The rest of the paper is organized as follows. In the next section we describe the game of Ms. Pac-Man and present the most relevant contributions in the literature. Next, we illustrate the structure of the FSs applied to the game of Ms. Pac-Man and how to optimize their definition using a GA. The results of the computational experiments are reported and commented in Section \ref{sec:Experiments}. Finally, in Section \ref{sec:Conclusions} we some draw some conclusions and highlight future opportunities to be pursuit in this line of research.

\section{Background}
\label{sec:Background}
In this section, the relevant background is provided. First, we present the game of Ms. Pac-Man and its characteristic. Next, a review of the works in the field of research is given.

\subsection{The game of Ms. Pac-Man}
\label{subsec:GameMsPacMan}
The game of Ms. Pac-man is one of the many variants of the famous
Pac-Man game, released in 1981. Ms. Pac-man  extends the mechanics of
the original with several features, the most interesting being
different ghosts' behavioral patterns and the inclusion of a random
movement to prevent the use of patterns to clear each round.

The game has been chosen for the Ms. Pac-Man vs Ghosts competition, an AI competition where participants can submit controllers for both Ms. Pac-Man and the Ghost Team. The controllers have directly opposing objectives. In fact, Ms. Pac-Man agents' aim is to maximize the final score, while Ghost Team controllers' aim is to minimize it. The version of the game implemented for the competitions differs slightly from the original one. A thorough description of the game rules can be found in \cite{MsPacManVSGhost2011}. For the purposes of this work, the restrictions for the Ghost Team relevant to this work are briefly enlisted in the following:
\begin{itemize}
  \item A ghost can never stop and, when it is in a corridor, it can only move forward.
  \item A ghost can choose its direction only at a junction. Specifically, a ghost can only move into a corridor different from the one it is coming from. As a result, a ghost cannot turn back on itself.
  \item Every time a ghost is at a junction the controller has to provide a direction (i.e., UP, DOWN, LEFT, or RIGHT) from the set of feasible directions, i.e., those directions corresponding to corridors different from the one the ghost is coming from. If no direction or an unfeasible direction is returned by the controller, the game framework chooses one randomly from the set of feasible directions.
  \item At every tick of the game all the ghosts obligatorily reverse their direction according to a small random probability, set in the framework implementation to 0.005.
  \item After 2000 game ticks, a level is considered completed: Ms. Pac-Man is rewarded with the points of the remaining pills and the game moves on to the next level.
\end{itemize}

\subsection{State of the Art}
Most of the contributions in the literature focused on implementing and analyzing controllers for Ms. Pac-Man. In the last decade a number of Evolutionary Algorithms (EAs) have been proposed to address different aspects of the game of Ms. Pac-Man. One of the first works in the subject is the paper by Gallagher \cite{Gallagher03} that optimized rule-based fine state machines through population-based incremental learning to devise an adaptive Pac-Man agent. More recently, Galvan-Lopez \cite{Galvan-Lopez10} explored and compared the performance of two types of Grammatical Evolution (GE) mappings to generate controllers for Ms. Pac-Man. Alhejali and Lucas \cite{Alhejali10} applied Genetic Programming (GP) to evolve a diverse set of behaviors using different versions of the game. The resulting controller proved to be competitive with the best reactive controllers reported at the time. In a subsequent article \cite{AlhejaliLucas11}, the same authors extended their work by applying a ``training camp framework'' to the GP, where a set of specialized behaviors is evolved according to specific training scenarios. A different approach is presented by Brandstetter and Ahmadi \cite{Brandstetter12} that proposed a GP-based controllers that relies exclusively on information retrieval terminals rather than action-issuing terminals.  Thawonmas \cite{Thawonmas10} applied a GA to optimize the parameters of the Ms. Pac-Man controller ICE Pambush 3, winner of the IEEE CEC 2009 Ms. Pac-Man competition. A number of authors made use of EAs to design neural network-based controllers \cite{Lucas05,Burrow09,Keunhyun10}. Beside EA and GA, a wide range of other techniques have been applied, such as  Ant Colonies \cite{Emilio2010}, Monte Carlo methodologies \cite{Tong2010,Tong2011}, Monte Carlo Tree Search (MCTS) \cite{Samothrakis2011, Ikehata2011}, and Reinforcement Learning \cite{Bom2013}. Finally, Alhejali and Lucas \cite{Alhejali2013} applied genetic algorithm to enhance the performances of a Ms. Pac-Man agent created using MCTS, showing an impressive 18\% increase on the average score. 

In the last years, a number of works specializing on the Ghost Team have been proposed. Nguyen and Thawonmas \cite{Nguyen2011,Nguyen2013} presented a controller based on MCTS where the behavior of Ms. Pac-Man is simulated. Their controller won the Ms. Pac-Man Versus Ghost Team Competition held in 2011. Svensson and Johansson \cite{Svensson2012} exploited the behavior emerging capabilities of Influence Maps. A significant number of works made use of EAs methodologies. Jia-Yue \emph{et al.} \cite{Jia-Yue11} applied Neural Network-based controllers evolved through GAs. Gagné and Congdon \cite{Gagne2012} evolved rule-based intelligent agent for the ghost team. Tamura and Torii \cite{Tamura2013} designed artificial ghost agents using GE. Cardona \textit{et al.} \cite{Cardona13} explored competitive co-evolution techniques to generate at the same time optimal Ms. Pac-Man and Ghost Team controllers. A different line of research is pursued by Sombat \textit{et al.} \cite{Sombat2012} that analyzed Ms. Pac-Man matches to classify Ghost Team controllers according to their enjoyability and, therefore, understand the attribute that a NPC should posses for players to be engaged. Similarly, Hasan and Khondker \cite{Hasan2013} explored the user friendliness of ghost controllers. In their research, they implemented a Neural Network controller to assess the level of challenge that better suits the player.

Finally, evolved FSs were proposed for the first time by Liberatore \emph{et al.} \cite{Liberatore2014}.  Their structure is briefly presented in the following section, along with some new results regarding their computational complexity and two new focuses based on team learning paradigms.

\section{Models and Methods}
\label{sec:ModelsMethods}
This section is devoted to explaining the structure of the Ghost Team agents proposed, based on FSs. The paradigms of homogeneous and heterogeneous team learning are also presented and applied. 

\subsection{Flocking Strategies for the Ghost Team}
Swarm intelligence (SI) is the term used to describe the type of coordinated intelligence that arises from the collective behavior of decentralized, self-organized systems, either natural or artificial \cite{BeniWang89}. SI techniques have been widely used in many fields including medicine, robotics, defense, astronomy, optimization, telecommunication, art, cinematography, and videogames.

Flocking refers to a SI technique proposed by Reynolds \cite{Reynolds87} for the coordinated movement of multiple AI agents. Originally, flocking algorithms have been developed to mimic lifelike behaviors of groups of beings such as herds of animals, flocks of birds, swarms of insects, and schools of fishes. A flocking system typically consists of a population of simple agents (or boids) interacting locally with one another depending on the distance between them. The agents follow very simple steering behaviors:

\begin{itemize}
	\item \textit{Separation} makes the agent steer away from close flock mates.
	\item \textit{Alignment} makes the agent steer toward the average heading of the flock.
	\item \textit{Cohesion} makes the agent steer toward the average position of distant flock mates.
\end{itemize} 

Despite the lack of a centralized control structure dictating how
individual agents should behave, the interactions between such agents
lead to the emergence of "intelligent" global behavior, unknown to the
individual agents \cite{SpectorEtAl03}. Given this desirable property,
the easiness of implementation, and the reduced computational cost,
flocking algorithms have been extensively applied to videogames
\cite{Scutt02} and many other fields, such as cinematography, art or medicine.

In the following, the elements comprising a FS are illustrated.

\subsubsection{Sets and Attributes}
\begin{itemize}
  \item $M=\{$UP, DOWN, LEFT, RIGHT$\}$, Set of moves, indexed by $m$. Subset $\overline{M}\subset M$ includes only the feasible moves, according to the restrictions on the ghosts' movement (please, refer to Section \ref{subsec:GameMsPacMan}).
  \item $G=\{$BLINKY, PINKY, INKY, SUE$\}$, Set of ghosts, indexed by $g$.
  \item $S=\{$HUNTER, HUNTED, FLASH$\}$, Set of ghosts' states, indexed by $s$. When in state HUNTER, a ghost is dangerous and kills Ms. Pac-Man when it touches her. HUNTED defines the state of a vulnerable ghost; in the game this is represented by the ghost turning deep blue. Vulnerable ghosts FLASH white to signal that they are about to become dangerous again.
  \item $A=\{$PACMAN, POWERPILL, HUNTER, HUNTED, FLASH$\}$, Set of actors, indexed by $a$. POWERPILL represents one of the four big pellets that, when eaten by Ms. Pac-Man, make the ghosts vulnerable. HUNTER, HUNTED, and FLASH refers to ghosts in that state. $\overline{A}$ is the set of actors currently in the game.
  \item $N \in \mathbb{N}$, A positive natural number representing the number neighborhoods, indexed by $n = 1, \ldots, N$. Neighborhoods are toroidal concentric areas centered on the current ghost. The interaction between the current ghost and an actor depends on which neighborhood the latter falls in, as explained in the following.
  \item $\mathbf{v}_g$ and $\mathbf{v}_a$, Two dimensional Euclidean vectors representing the position on the map of a ghost and an actor, respectively, in $(x,y)$ coordinate system. We define $dist(g,a)$ as the Euclidean distance between two position vectors.
\end{itemize}

\subsubsection{Representation}
A FS can be represented as a pair $(\boldsymbol\delta, A)$, explained in the following:
\begin{itemize}
  \item $\boldsymbol\delta \in \mathbb{R}_{>0}^N$, A vector of N real positive numbers. Each element $\delta_n$ is associated to one neighborhood and represents its maximum radius. Specifically, an actor $a$ falls into a neighborhood $n$ when its Euclidean distance to the current ghost $g$ is $\delta_{n-1} < dist(g,a) \leq \delta_n$. Without loss of generalization we assume that $\delta_0 = 0$, $\delta_N = \infty$, and $\delta_{n-1} < \delta_n < \delta_{n+1}$, i.e., each entry must be greater that its predecessor and lower than its successor.
  \item $\boldsymbol\alpha \in \mathcal{M}_{|S| \times |A| \times N}(\mathbb{R})$, A three dimensional matrix with real entries. The first dimension is associated to the state of the current ghost, the second to the actor considered, and the third to the neighborhood where the actor falls in. Each element $\alpha_{s,a,n}$ represents the magnitude of the steering force on the current ghost resulting from the interaction with the actor. Without loss of generalization, we consider that a negative magnitude corresponds to the behavior of separation, while a positive magnitude corresponds to the behavior of cohesion.
\end{itemize}

\subsubsection{Algorithm}
Every time a ghost is at a junction the game needs to calculate its next move. In a FS, the final behavior of the ghost is determined by the sum of all the behaviors resulting from the interactions with the other actors in the game. A controller based on FSs provides the next move by following these steps shown in Algorithm \ref{alg:FS_Controller}. For each actor $a$ in the game, the algorithm executes the following operations. First, it determines the neighborhood $n$ where the actor belongs. This is done by checking the distance between the ghost and the actor against the vector of radiuses, $\boldsymbol\delta$. Next, the steering force $\mathbf{f}^a$ is computed. The steering force is a two dimensional vector and is calculated as the product between the normalized positional difference vector between $g$ and $a$, and the appropriate magnitude, $\alpha_{s,a,n}$. Once all the steering forces have been calculated, the total steering force $\mathbf{f}$ is computed as their sum. The entries of this two dimensional vector are converted into a ranking for the moves: the first entry, corresponding to the x-axis, determines the rank for LEFT and RIGHT, while the second entry, corresponding to the y-axis, determines the rank for UP and DOWN. Finally, the algorithm returns the feasible move having maximum rank.

%Federico: The IEEE Style forbids using algorithm floating environments and suggests using figure. Don't really understand why since it's messier this way... :-S
\begin{figure}[!t]
\begin{algorithmic}
\STATE $s\gets$ status of the current ghost $g$;
\FORALL{$a \in \overline{A}$}
	\STATE $n\gets n^\prime | \delta_{n^\prime-1} < dist(g,a) \leq \delta_{n^\prime}$; \COMMENT{Determine the neighborhood.}
	\STATE $\mathbf{f}^a \gets \alpha_{s,a,n} \cdot \frac{\mathbf{v}_a - \mathbf{v}_g}{|dist(g,a)|}$; \COMMENT{Compute the steering force resulting from the interaction with the actor.}
\ENDFOR
\STATE $\mathbf{f} \gets \sum_{a \in \overline{A}} \mathbf{f}^a$; \COMMENT{Calculate the total steering force.}
\STATE \COMMENT{Translate the total steering force in a ranking for the next ghost direction as follows:}
\STATE $r_\text{UP} \gets - f_2$;
\STATE $r_\text{DOWN} \gets f_2$;
\STATE $r_\text{LEFT} \gets - f_1$;
\STATE $r_\text{RIGHT} \gets f_1$;
\RETURN $\arg\max_{m \in \overline{M}} r_m$; \COMMENT{Return the feasible direction (see restrictions in Section \ref{subsec:GameMsPacMan}) having maximum rank.}
\end{algorithmic}
\caption{Flocking Strategy-based Ghost Controller.}
\label{alg:FS_Controller} 
\end{figure}

The computational complexity of the algorithm is $O(|\overline{A}|N)$. $|\overline{A}|$ is the number of actors in the game, having a maximum value of eight, i.e., Ms. Pac-Man, three ghosts, and four power pills. Also the memory occupation is limited, as a FS can be represented with only $(N + |S| \times |A| \times N) = 16 \times N$ floats. Given the low computational and memory requirements, controllers based on FSs are particularly suited for commercial games, where the computational time allocated to AI operations is minimal, and machines having limited capabilities, such as portable and handheld devices.

\subsection{Team Learning}
A FS could be manually designed by an expert with decent results. Nevertheless, given the number of parameters and the inherent complexity of the game, it is desirable to automatize the definition of an effective strategy by means of an optimization algorithm. As the ghosts chase Ms. Pac-Man as a team, we look at team learning methodologies. In team learning \cite{Panait2005} the only learner involved is the team itself. This is different from multi-agent learning, where the single agents are trained separately. One of the main advantages of team learning is that it is possible to apply standard single-agent machine learning techniques. Moreover, it is not necessary to consider inter-agent credit assignment, i.e., identifying the contribution of each agent to the performance of the team.

Team learning can be divided into two main groups: homogeneous and
heterogeneous team learning. Homogeneous learners develop a single
agent behavior which is used by every agent on the team. Heterogeneous
learners can develop a unique behavior for each agent. Although it
generally leads to better solutions through agent specialization, it
is characterized by a larger state space that can complicate the learning process . It is also
 important to notice that agents can act heterogeneously even in
 homogeneous team learning, when the final behavior differs based on
 the agent's initial conditions. 

In this work, we explore the capabilities of homogeneous and heterogeneous FS for the Ghost Team. Specifically, we optimize the design of the FSs by means of a simple Multi-Criteria Genetic Algorithm (MCGA). In the following section, the algorithm is presented.

\subsection{A Multi-Criteria Genetic Algorithm for Flocking Strategies}
Following the work by Liberatore \emph{et al.} \cite{Liberatore2014} we apply a basic MCGA for the design of effective and resilient ghost controllers based on FSs. The main characteristics of the optimization algorithm are illustrated in the following.

\subsubsection{Individuals' Representation}
In this algorithm, an individual in the population (or a candidate solution) is represented by the FSs that compose it. In the case of homogeneous team learning, only one FS, $(\boldsymbol\delta, A)$, is necessary as all the ghosts will follow the same behavior. On the other hand, in heterogeneous team learning each ghost $g$ has an associated FS, $(\boldsymbol\delta^g, A^g)$. Although the data structures for the heterogeneous case are four times bigger than the homogeneous ones, their total memory occupation is still very limited. In summary, an individual in the GA is represented as follows:

\begin{itemize}
  \item $(\boldsymbol\delta, \boldsymbol\alpha)$, for homogeneous team learning.
  \item $(\boldsymbol\delta^g, \boldsymbol\alpha^g)\: \forall g \in G$, for heterogeneous team learning.
\end{itemize}

We preserve the real encoding and the structure of the vector and of the matrix in the individuals' chromosomes.

\subsubsection{Initial Population}
The initial population is generated randomly as in Liberatore \emph{et al.} \cite{Liberatore2014}. More in detail, the entries of $\boldsymbol\delta$ follow a uniform distribution, while the elements of $\boldsymbol\alpha$ have a truncated normal distribution:

\begin{small}
\begin{equation}
	\label{eq:init_radius}
	\forall n = 1, \ldots, N, \: \delta_n \sim U(\delta_n,\infty)
\end{equation}
\begin{equation}
	\label{eq:init_magnitude}
	\forall s \in S, a \in A,  n = 1, \ldots, N, \: \alpha_{s,a,n} \sim N(0,1/3), \alpha_{s,a,n} \in [-1,1]
\end{equation}
\end{small}

The parameters of the normal distribution have been set so as to generate most of the magnitudes close to zero and assign similar probabilities to the appearance of cohesion, separation, and no interaction behaviors.

\subsubsection{Fitness Function}
To generate agents that perform well against a wide range of Ms. Pac-Man strategies, we calculate the fitness value of each individual by testing it against eight Ms. Pac-Man agents. Let $P=\{$NearestPillPM, StarterPM, InfluenceMapPM, MCTSPM, MixMaxPM, StarterExPM, ICEPFeatSpooks, ICEP-IDDFS$\}$, indexed by $p$, be the set of Ms. Pac-Man agents:

\begin{itemize}
  \item NearestPillPM, Basic controller included in the competition framework that moves Ms. Pac-Man to the closest pill, regardless of the state and position of the ghosts.
  \item StarterPM, Simple state machine based controller included in the competition framework.
  \item InfluenceMapPM, Influence Map-based controller \cite{Svensson2012}.
  \item MCTSPM, Enhanced MCTS controller \cite{Pepels2012}.
  \item MixMaxPM, Controller implementing a variation of the Minimax algorithm \cite{Cardona13}.
  \item StarterExPM, Another controller that combines the StarterPM and the MixMaxPM, giving a challenge factor between the two \cite{Cardona13}.
  \item ICEPFeatSpooks, Modified version of Spooks. Spooks was the winning Ms. Pac-Man entry for the CIG 2011 competition.
  \item ICEP-IDDFS, Very strong controller based on iterative deepening depth-first search, by Shirakawa, Nakamura and Thawonmas. As of this date, this controller ranks first in the Ms. Pac-Man vs Ghosts competition.
\end{itemize}

The objective of the proposed GA is to design controllers that are efficient against a wide range of Ms. Pac-Man strategies, instead of focusing on just countering one or a few of them. Therefore, we would like to optimize the performance of our individuals against all the considered Ms. Pac-Man controllers. This objective can be expressed as:

\begin{equation}
\label{eq:minAllScores}
	\min \: \text{score}_p, \: \forall p \in P
\end{equation}

where $\text{score}_p$ represents the final score of the Ms. Pac-Man controller $p$. Equation \eqref{eq:minAllScores} is a multi-objective function (one objective for each Ms. Pac-Man controller) and it is not implementable as is. In fact, minimizing the performance of all the considered Ms. Pac-Man controllers might not be possible, as there could be trade-offs between them, i.e., increasing the effectivity of the Ghost Team against one Ms. Pac-Man controller might result in a loss of performance against another one. Therefore, the most realistic objective would be optimizing the FSs to obtain Ghost Team controllers whose performances are as balanced as possible:

\begin{equation}
\label{eq:minMaxScore}
	\min \: F_1 = \max_{p \in P} \text{score}_p
\end{equation}

Equation \eqref{eq:minMaxScore} is concerned with finding a balance between the final scores of all the Ms. Pac-Man. Another benefit of this formulation is that it minimizes the effect of noise present in this problem (and in videogames in general) \cite{Mora12}. In fact, due to the stochastic elements of the game, the same FS could perform very well sometimes and quite bad some others. By choosing the worst (highest) score we reduce the effect of the noise introduced by there stochastic effects.

Although implementable, objective functions in the $\min \max$ form usually present a wide number of multiple optima\footnote{Multiple optima are different solutions having the same objective function value.} and produce solutions that are not efficient\footnote{A solution is efficient, or non-dominated, if none of the objective functions can be improved in value without degrading some of the other objective values.}. Therefore, to get an efficient one we consider a secondary objective function that optimizes for global performance.

\begin{equation}
\label{eq:minSquareScore}
	\min \: F_2 = \sum_{p \in P} \text{score}_p^2
\end{equation}

The squared term has been introduced to penalize high scores. Given the characteristics of the problem we propose a lexicographic objective function:

\begin{equation}
\label{eq:lexicographic}
	\text{Lex} \: \min [F_1,F_2]
\end{equation}

In Lexicographic Optimization \cite{Dylan2010} the objectives can be ranked in the order of importance and they are not comparable directly, as in this case. In fact we can assume, without loss of generality, that $F_1$ is more important than $F_2$, i.e., we favor balance over global optimality. As a result, each individual in the population has an associated fitness vector, $\mathbf{F}=(F_1,F_2)$, which allows for a total order relation:

\begin{equation}
\label{eq:ordering}
	\mathbf{F}^A \succ \mathbf{F}^B \iff (F_1^A < F_1^B) \lor ((F_1^A = F_1^B) \land (F_2^A < F_2^B))
\end{equation}

where $\mathbf{F}^A$ and $\mathbf{F}^A$ are the fitness vectors associated to individuals A and B, respectively, and $\mathbf{F}^A \succ \mathbf{F}^B$ means that $\mathbf{F}^A$ is better than $\mathbf{F}^B$. Once all the population individuals' fitness vectors have been calculated, we assign a rank-based fitness value. This is done by sorting the population according to the fitness vectors and calculating a fitness value for each individual depending only on its position in the rank:

\begin{equation}
\label{eq:rankFitness}
	\text{Fitness}(\text{rank}) = \frac{\text{POP} - \text{rank}}{\text{POP}}
\end{equation}

where POP is the number of individuals in the population and rank is the position of an individual in this population, e.g., the least fit individual has $\text{rank} = \text{POP}$ while the fittest individual has $\text{rank} = 1$.

\subsubsection{Selection}
Individuals are selected by roulette wheel selection according to the rank-based fitness.

\subsubsection{Cross-Over}
In the proposed GA, two parents generate one child. The child's chromosome is created by random recombination of the parents' chromosomes. The entries of the neighborhood radius vector $\boldsymbol\delta$ and of the magnitude matrix $\boldsymbol\alpha$ in the chromosome of the child are evaluated individually. Each entry takes its value from one parent or the other according to a mixing probability.

In the case of heterogeneous team learning we apply restrictive
breeding, as Luke and Spector \cite{Luke1996} suggested that it works
better than having no restrictions. Restrictive breeding means that
that agents could only breed with like agents from other
teams. Applied to the context of this work, we allow cross-over only
between the FSs corresponding to the same ghost; e.g., BLINKY breeds
only with BLINKY and PINKY only with PINKY, for instance.

\subsubsection{Mutation}
Mutation occurs with fixed probability. When a mutation happens, the current parameter is re-initialized to a random value, according to Equations \eqref{eq:init_radius} and \eqref{eq:init_magnitude}.

\section{Experiments}
\label{sec:Experiments}
The algorithms presented in this paper have been implemented in Java within the framework provided for the Ms. Pac-Man vs Ghosts competition. The final program run on an Intel(R) Core(TM) i5-2500K @ 3.3GHz with four cores and 4GB of RAM. Each experiment run on a single core. In order to ensure comparability, the same configuration of parameters for the MCGA has been used for all the experiments:

\begin{itemize}
  \item Population = 50.
  \item Generations = 50.
  \item Elitism = 1.
  \item Mutation probability = 0.01.
  \item Cross-over mixing probability = 0.6.
\end{itemize}

%Federico: Quiero una frase que diga que los parametros han sido elegidos haciendo algunos experimentos y viendo que mas o menos producian buenos resultados. Antonio, te sabes alguna?
In any event, the MCGA can be run for any feasible configuration of the parameters. We also changed the default configuration of the competition framework in the following way:

\begin{itemize}
  \item The event that forces the ghosts to obligatorily reverse their direction has been removed to ensure consistency in the evaluation of the candidate solutions' fitness.
  \item The maximum duration of a game has been set to 4000 seconds, to reduce the computational time employed by the GA while still giving an ample margin for evaluating an individual's performance.
\end{itemize}

Overall, the following experiments have been done:

\begin{itemize}
  \item Comparison of the performance of the Ghost Team controllers obtained with different values of the parameter $N$ (i.e., the number of neighborhoods considered in the Flocking Rules).
  \item Analysis of the robustness of the FS based controllers in the face of the reverse direction random event.
  \item Comparison with other ghosts controllers from the literature.
\end{itemize}

\subsection{Performance Test}
The first experiment performed regards the comparison of the performance of the Ghost Team controllers obtained with different team learning strategies and different values of the parameter $N$. In principle, the best controllers should be obtained when heterogeneous team learning is applied and when high values of $N$ are used, as the solution space is bigger. Nevertheless, as the solution space increases, the actual performance of the MCGA could get worse. We considered all the values of $N$ ranging from one to five. For each value we executed the MCGA 10 times. Detailed information regarding each run is give in Tables \ref{tab:results_homogeneous} and \ref{tab:results_heterogeneous} in the Appendix.

\begin{table*} [!t]
\caption{Performance of the controllers for the Ghost Team obtained by the GA using different numbers of neighborhoods.}
\label{tab:summary}
\centering
\subfloat[Homogeneous team learning.]{
\begin{tabular}{|c|c|c|c|}
\hline 
$N$ & Mean CPU Time (s) & Best $F_1$ & Average $F_1$  \\
\hline
1 & 95692.2 $\pm$ 2252.57 & 7480 & 8017.5$\pm$ 460.66 \\
\hline
2 & 96333.3 $\pm$ 1714.56 & 5271 & 6625.7 $\pm$ 934.1 \\
\hline
3 & 96569.1 $\pm$ 993.27 & 5660 & 6615 $\pm$ 639.43 \\
\hline
4 & 97678.8 $\pm$ 1246.94 & 5029 & 5947.4 $\pm$ 874.93 \\
\hline
5 & 96982.3 $\pm$ 680.98 & 4530 & 6583.8 $\pm$ 1226.04 \\
\hline 
\end{tabular}
\label{tab:summary_HOM}
}
\hfil
\subfloat[Heterogeneous team learning.]{
\begin{tabular}{|c|c|c|c|}
\hline 
$N$ & Mean CPU Time (s) & Best $F_1$ & Average $F_1$  \\
\hline
1 & 93383 $\pm$ 823.72 & 6790 & 8176.1 $\pm$ 810.13 \\
\hline
2 & 93387.2 $\pm$ 1772.01 & 7949 & 8722.5 $\pm$ 429.11 \\
\hline
3 & 94904.1 $\pm$ 512.24 & 7411 & 8666.5 $\pm$ 729.87 \\
\hline
4 & 93936 $\pm$ 1158.36 & 7830 & 8270.7 $\pm$ 419.7 \\
\hline
5 & 94717.7 $\pm$ 1155.32 & 8279 & 8689.4 $\pm$ 237.52 \\
\hline 
\end{tabular}
\label{tab:summary_HET}
}
\end{table*}

Table \ref{tab:summary} shows the performance of the evolved controllers over 10 runs of the MCGA with $N=1,\ldots,5$ when applying homogeneous and heterogeneous team learning (Tables \ref{tab:summary_HOM} and \ref{tab:summary_HET}, respectively). Each row is associated to a different number of neighborhoods, displayed in the first column. The second column presents the average computational time; the standard deviation is also reported after the plus-minus sign. Next, the third column illustrates the fitness value $F_1$ of the best controller found. A higher $F_1$ value corresponds to a lower ghosts' performance, and the other way round. Finally, the last column reports the average fitness value over the 10 runs and the corresponding standard deviation. By observing the tables some conclusions can be drawn.

Concerning the computational time, we can see that a single run takes
quite a significant amount of time to complete (26 hours
approximately). The reason for that is that the most advanced
Ms. Pac-Man controllers make use of all the allowed maximum
computational time for each game tick (40 ms). 

For the homogeneous team learning case the best controller is obtained
when $N=5$. Also, the scores have a decreasing trend, confirming our
supposition that higher values of $N$ should result in better
performances. However, for the heterogeneous team learning experiments
the results are quite different: the performance of the best controller found do not follow any trend,
while the averages have no substantial difference. Also, the heterogeneous team controllers
perform worse than the corresponding homogeneous team ones. This is probably due to
the increased solution space that makes it impossible for the MCGA to
converge to a good solution within the determined number of
generations. %Aquí deberíais poner aparte de la tabla un gráfico y
             %también añadir un test de significación estadística como
             %el Wilcoxon. En tiempos no parece que haya diferencias
             %significativas según el número de vecindades, y en el
             %fitness en al caso del aprendizaje heterogéneo tampoco,
             %almenos entre 2 y 3, por ejemplo, en ambos
             %casos. Deberíasi analizarlo y comentarlo. 

\begin{figure*}[!t]
  \caption{Average $F_1$ score of the best ghost controller of each generation for $N=1,\ldots,5$ (for interpretation of the references to color in this figure legend, the reader is referred to the web version of this article).}
  \label{fig:GA_trend}
  \centering
  \subfloat[Homogeneous team learning]{\includegraphics[scale=0.5]{"homogeneous_trend"} \label{fig:GA_trend_homogeneous}}
  \subfloat[Heterogeneous team learning]{\includegraphics[scale=0.5]{"heterogeneous_trend"} \label{fig:GA_trend_heterogeneous}}
\end{figure*}

Figure \ref{fig:GA_trend} illustrates the average $F_1$ score of the best ghost controller of each generation, for the homogeneous (on the left) and the heterogeneous team (on the right) cases. From the chart we can see that all the heterogeneous team have a similar behavior: after a small decrease they tend to reach a plateau. On the other hand, we can observe a greater variance in the trends of the homogeneous team, with different steepness depending on the value taken by $N$.

\subsection{Robustness Analysis}

The proposed MCGA evaluates the candidate solutions without considering the event that forces the ghosts to obligatorily reverse their direction. We now analyze the robustness of the FS based controllers generated by the MCGA in the face of this random event. We expect them to be quite robust, as the FSs choose the next move only according to the relative distance to the other agents and without considering any internal state.

To understand the robustness of the ghosts controller devised we consider the best controller found by the MCGA and we run 30 games with the probability of the ghost direction reverse event set to the default value. We can use the results of this experiment to analyze the variability in the performance of the controller.

\begin{table}[!t]
\caption{Analysis of the robustness for the best ghost controller generated by the GA.}
\label{tab:summary_robust}
\centering
\begin{tabular}{|c|c|c|}
\hline
 & $F_1$ & $F_2$ \\
\hline
Avg.	&	16261.67	&	912,799,343.33	\\
\hline
St. Dev	&	2521.11	&	219,969,266.43	\\
\hline
CV	&	0.16	&	0.24	\\
\hline
\end{tabular}
\end{table}

Table \ref{tab:summary_robust} presents the average, the standard deviation, and the coefficient of variation\footnote{The coefficient of variation is defined as the ratio of the standard deviation to the mean.} (CV) for objectives $F_1$ and $F_2$, calculated over the 30 runs. For both objectives the CV takes low values, inferior to 0.30, suggesting that the variation in the performance of the controller is low. Thus, we can claim that the ghost controller generated by the proposed GA is robust. The complete results of the robustness analysis are reported in Table \ref{tab:results_robust}, in the Appendix.

\subsection{Comparison with Other Controllers}
To understand the goodness of the ghost controllers generated by the MCGA we compare their performance to that of other controllers taken from the competition framework and the literature. Table \ref{tab:summary_others} shows the $F_1$ scores obtained (the detailed results of this experiment are illustrated in Table \ref{tab:results_ghosts} in the Appendix).

\begin{table} [!t]
\caption{Performance of the other Ghost Team controllers from the competition framework and the literature.}
\label{tab:summary_others}
\centering
\begin{tabular}{|c|c|}
\hline 
Controller & $F_1$ \\
\hline
StarterGhosts & 17410 \\
\hline
Legacy2TheReckoning & 17550 \\
\hline
InfluenceMapGhosts \cite{Svensson2012} & 21500 \\
\hline
Legacy & 24260 \\
\hline
AggressiveGhosts & 32070 \\
\hline
\end{tabular}
\end{table}

According to these results, StarterGhost and Legacy2TheReckoning (two controllers included in the competition framework) obtained the best results. Nevertheless, their score are twice those of the best evolved FSs found (Table \ref{tab:summary}), approximately. These results support the claim that FSs are a viable option for the definition of intelligent controllers.

\section{Conclusions}
\label{sec:Conclusions}
In this article, we extended the research on the controller for the Ghost Team by proposing a basic MCGA for the effective design of ghosts agents. We analyzed the complexity of a FS controller in terms of memory and computational effort, showing that they are both very small. Therefore, FSs find natural application in all the contexts where both the computational time and the memory consumption are critical, such as commercial games and handheld devices.

We took a step forward from the work in Liberatore \emph{et al.} \cite{Liberatore2014} by including eight Ms. Pac-Man controllers having different degrees of complexity in the fitness function. This required a redefinition of the fitness function. We proposed a lexicographic function that assigns high priority to balance and low priority to global performance. We showed empirically that the resulting Multi-Criteria Genetic Algorithm is capable of generating effective and challenging ghost controllers, having better performance than that of other controllers included in the competition framework or presented in the literature.

There is still a lot to be investigated to ascertain the real capabilities of the FSs. Some possible future lines of research are highlighted in the following.

As showed in the experiments, a single run of the MCGA takes a significant amount of computational time. Strategies for its reduction should be explored. An initial step could be doing a profiling of the program.

The proposed MCGA provided satisfactory results for the homogeneous team learning case. Nevertheless, in the heterogeneous team learning case, the extended solution space did not allow it to converge to a satisfactory solution. Optimization methodologies other than GAs could be investigated. Covariance Matrix Adaptation Evolution Strategies (CMA-ES) and Particle Swarm Optimization (PSO) might be sensible choices, as no assumption on the objective function or on the problem are made.

One of the main drawbacks of the fitness function adopted in this work is the amount of time required to evaluate the performance of one individual against eight different Ms. Pac-Man controllers. This is mostly due to the time consumption of the controllers based on minimax algorithm and other exploratory methods. Therefore, it could be interesting to co-evolve two distinct populations of ghosts and Ms. Pac-Man controllers based on FSs. This would speed up the time taken to compute the fitness of the individuals, allowing for more iterations in the optimization process. Potentially, this could lead to finding better controllers for the Ghost Team.

We hope that this work will be a useful source of ideas for future research on computational intelligence algorithms in games and will contribute further in the development and solution of more complex problems.

\appendices
\section{}
\label{sec:CompleteResults}
Tables \ref{tab:results_homogeneous} and \ref{tab:results_heterogeneous} illustrate the results relative to all the experiments performed. In the tables, the columns present the following information: 

\begin{itemize}
  \item $N$, Number of neighborhoods.
  \item CPU time, Computational time expressed in seconds.
  \item NearestPill - ICEP-IDDFS, Final score achieved by each Ms. Pac-Man controller.
  \item $F_1$ and $F_2$, maximum score (Equation \eqref{eq:minMaxScore}) and sum of squared scores (Equation \eqref{eq:minSquareScore}), respectively.
\end{itemize}

Table \ref{tab:results_robust} reports the complete results of the robustness analysis. The first 30 rows correspond to the run. In the last three rows can be found the average, the standard deviation, and the coefficient of variance (CV) for each column, respectively. Except for the first two Ms. Pac-Man controllers, the CV is always less than 0.30, suggesting that the variation in the performance of the controller is low. Thus, we can claim that the ghost controller generated by the proposed GA is robust.

The results relative to the ghosts controllers from other authors are displayed in Table \ref{tab:results_ghosts}.

\begin{sidewaystable*}[h]
\caption{Homogeneous team learning results.}
\label{tab:results_homogeneous}
\centering
\footnotesize
\begin{tabular}{|cc|cccccccc|cc|}
\hline																							
$N$	&	CPU Time (s)	&	NearestPillPM	&	StarterPM	&	InfluenceMapPM	&	MCTSPM	&	MixMaxPM	&	StarterExPM	&	ICEPFeatSpooks	&	ICEP-IDDFS	&	$F_1$	&	$F_2$	\\
\hline																							
1	&	95355	&	4310	&	5870	&	3650	&	4460	&	6470	&	7480	&	6210	&	6040	&	7480	&	259104100	\\
1	&	95343	&	4329	&	5892	&	3665	&	4442	&	6471	&	7480	&	6194	&	6071	&	7480	&	259666412	\\
1	&	98400	&	3390	&	7530	&	6420	&	7060	&	5660	&	7760	&	6510	&	6440	&	7760	&	335359900	\\
1	&	98393	&	3422	&	7545	&	6419	&	7047	&	5659	&	7768	&	6510	&	6440	&	7768	&	335720684	\\
1	&	92298	&	3580	&	5670	&	6550	&	7000	&	5470	&	5670	&	7410	&	7900	&	7900	&	316255700	\\
1	&	92288	&	3556	&	5660	&	6562	&	6974	&	5497	&	5668	&	7419	&	7910	&	7910	&	316330150	\\
1	&	97494	&	3055	&	7493	&	8137	&	3914	&	5682	&	8167	&	7157	&	7154	&	8167	&	348395617	\\
1	&	97501	&	3040	&	7510	&	8140	&	3910	&	5680	&	8170	&	7150	&	7140	&	8170	&	348302800	\\
1	&	94922	&	3810	&	3900	&	8770	&	4560	&	5620	&	8610	&	4580	&	7790	&	8770	&	314809600	\\
1	&	94928	&	3816	&	3907	&	8770	&	4534	&	5610	&	8618	&	4587	&	7799	&	8770	&	314903555	\\
\hline																							
2	&	97122	&	1375	&	2647	&	5144	&	5083	&	5271	&	3171	&	5140	&	3496	&	5271	&	137675157	\\
2	&	97130	&	1360	&	2660	&	5170	&	5100	&	5280	&	3180	&	5130	&	3480	&	5280	&	138082200	\\
2	&	98579	&	1546	&	2579	&	5480	&	5963	&	5753	&	3174	&	5109	&	3460	&	5963	&	155873892	\\
2	&	98596	&	1560	&	2590	&	5480	&	5970	&	5780	&	3180	&	5120	&	3480	&	5970	&	156658600	\\
2	&	93606	&	4030	&	3320	&	4580	&	5720	&	5860	&	4120	&	6420	&	6940	&	6940	&	221652100	\\
2	&	93618	&	4013	&	3304	&	4584	&	5677	&	5856	&	4138	&	6440	&	6949	&	6949	&	221439951	\\
2	&	96336	&	1354	&	2573	&	3138	&	5643	&	3381	&	3195	&	6051	&	7207	&	7207	&	160338774	\\
2	&	96352	&	1360	&	2590	&	3160	&	5620	&	3370	&	3180	&	6060	&	7210	&	7210	&	160304700	\\
2	&	95986	&	3230	&	7672	&	5784	&	5794	&	5068	&	7261	&	6245	&	7717	&	7717	&	313276435	\\
2	&	96008	&	3240	&	7650	&	5780	&	5770	&	5080	&	7250	&	6230	&	7750	&	7750	&	312965700	\\
\hline																							
3	&	96948	&	2240	&	2660	&	3810	&	4980	&	5660	&	2670	&	5490	&	3190	&	5660	&	130890400	\\
3	&	96945	&	2239	&	2639	&	3783	&	4994	&	5673	&	2663	&	5477	&	3195	&	5673	&	130708619	\\
3	&	97785	&	6230	&	5560	&	3610	&	6050	&	4950	&	5980	&	5400	&	6440	&	6440	&	250257600	\\
3	&	97785	&	6209	&	5551	&	3655	&	6034	&	4926	&	5975	&	5373	&	6469	&	6469	&	249816654	\\
3	&	95165	&	2590	&	5860	&	3280	&	6500	&	5800	&	4630	&	6520	&	6020	&	6520	&	227883800	\\
3	&	95179	&	2608	&	5926	&	3232	&	6496	&	5813	&	4625	&	6544	&	6048	&	6544	&	229146814	\\
3	&	95819	&	2935	&	5056	&	3189	&	6895	&	3378	&	3167	&	5773	&	5105	&	6895	&	172717434	\\
3	&	95821	&	2970	&	5110	&	3160	&	6900	&	3370	&	3180	&	5770	&	5120	&	6900	&	173505200	\\
3	&	97121	&	3156	&	7340	&	5374	&	6173	&	6070	&	7509	&	5685	&	7030	&	7509	&	305791847	\\
3	&	97123	&	3150	&	7310	&	5390	&	6220	&	6080	&	7540	&	5740	&	7040	&	7540	&	307426300	\\
\hline																							
4	&	96545	&	2861	&	2617	&	4503	&	4896	&	5029	&	2689	&	4909	&	3140	&	5029	&	125761278	\\
4	&	96575	&	2850	&	2660	&	4580	&	4920	&	5090	&	2670	&	4920	&	3190	&	5090	&	127800400	\\
4	&	97336	&	2802	&	2685	&	5160	&	4461	&	4635	&	2664	&	3433	&	3207	&	5160	&	112237009	\\
4	&	97337	&	2820	&	2660	&	5210	&	4500	&	4640	&	2670	&	3470	&	3190	&	5210	&	113297600	\\
4	&	97714	&	1357	&	2624	&	5183	&	5158	&	5762	&	3174	&	5667	&	3433	&	5762	&	149370576	\\
4	&	97728	&	1360	&	2660	&	5180	&	5210	&	5780	&	3180	&	5680	&	3480	&	5780	&	150795300	\\
4	&	99905	&	3111	&	3682	&	5423	&	5907	&	6132	&	6259	&	5339	&	6417	&	6417	&	233996338	\\
4	&	99911	&	3170	&	3720	&	5440	&	5850	&	6160	&	6300	&	5360	&	6440	&	6440	&	235542200	\\
4	&	96872	&	3940	&	6740	&	6340	&	4930	&	4870	&	5270	&	6250	&	7280	&	7280	&	269002400	\\
4	&	96865	&	3925	&	6691	&	6279	&	4899	&	4896	&	5257	&	6219	&	7306	&	7306	&	267261610	\\
\hline																							
5	&	97552	&	3420	&	2660	&	3130	&	4230	&	3590	&	2670	&	4200	&	4530	&	4530	&	104639700	\\
5	&	97542	&	3462	&	2700	&	3047	&	4240	&	3603	&	2647	&	4156	&	4600	&	4600	&	126117807	\\
5	&	97545	&	6205	&	3755	&	3600	&	6034	&	4110	&	4342	&	4955	&	6196	&	6205	&	200658711	\\
5	&	97548	&	6200	&	3810	&	3590	&	6000	&	4130	&	4350	&	4970	&	6280	&	6280	&	201962900	\\
5	&	97095	&	3772	&	4724	&	3803	&	6372	&	4004	&	6813	&	6492	&	6373	&	6813	&	236819531	\\
5	&	97079	&	3810	&	4750	&	3800	&	6380	&	4120	&	6850	&	6550	&	6400	&	6850	&	239982400	\\
5	&	95784	&	3040	&	4320	&	5650	&	5190	&	7260	&	5570	&	5800	&	6740	&	7260	&	249562700	\\
5	&	95783	&	3024	&	4282	&	5627	&	5172	&	7276	&	5620	&	5807	&	6689	&	7276	&	248881359	\\
5	&	96934	&	3430	&	4400	&	6390	&	5820	&	5680	&	7610	&	6210	&	8010	&	8010	&	298728100	\\
5	&	96961	&	3442	&	4398	&	6299	&	5725	&	5696	&	7587	&	6231	&	8014	&	8014	&	296699336	\\
\hline																							
Avg.	&	96651.14	&	3234.08	&	4562.24	&	5042	&	5547.54	&	5254.02	&	5187.42	&	5721.24	&	5898.9	&	6757.88	&	225887559	\\
St. Dev.	&	1572.09	&	1214.2	&	1789.59	&	1512.27	&	866.7	&	954.16	&	2027.59	&	893.29	&	1655.72	&	1078.34	&	74700267.29	\\
\hline																							

\end{tabular}
\end{sidewaystable*}

\begin{sidewaystable*}[h]
\caption{Heterogeneous team learning results.}
\label{tab:results_heterogeneous}
\centering
\footnotesize
\begin{tabular}{|cc|cccccccc|cc|}
\hline																							
$N$	&	CPU Time (s)	&	NearestPillPM	&	StarterPM	&	InfluenceMapPM	&	MCTSPM	&	MixMaxPM	&	StarterExPM	&	ICEPFeatSpooks	&	ICEP-IDDFS	&	$F_1$	&	$F_2$	\\
\hline																							
1	&	93968	&	2950	&	3820	&	4220	&	5860	&	5680	&	5160	&	6720	&	6790	&	6790	&	225593400	\\
1	&	93998	&	2963	&	3795	&	4230	&	5836	&	5671	&	5195	&	6729	&	6794	&	6794	&	225719333	\\
1	&	93141	&	4780	&	2920	&	3610	&	5910	&	7960	&	6840	&	6980	&	7240	&	7960	&	290620200	\\
1	&	93160	&	4740	&	2928	&	3622	&	5921	&	8007	&	6829	&	6956	&	7241	&	8007	&	290783216	\\
1	&	92747	&	2723	&	8063	&	6753	&	6773	&	5395	&	7467	&	6523	&	8368	&	8368	&	361338303	\\
1	&	92764	&	2720	&	8110	&	6780	&	6780	&	5360	&	7480	&	6530	&	8380	&	8380	&	362652600	\\
1	&	94568	&	7360	&	5660	&	5690	&	6360	&	5000	&	8550	&	6030	&	8790	&	8790	&	370758400	\\
1	&	94561	&	7362	&	5677	&	5704	&	6336	&	5011	&	8546	&	6029	&	8798	&	8798	&	371005767	\\
1	&	92463	&	3140	&	5060	&	3190	&	6380	&	8700	&	8270	&	8800	&	8930	&	8930	&	387611500	\\
1	&	92460	&	3153	&	5052	&	3197	&	6390	&	8719	&	8266	&	8807	&	8944	&	8944	&	388423124	\\
\hline																							
2	&	95338	&	3162	&	5589	&	6714	&	5634	&	7949	&	5132	&	6163	&	7509	&	7949	&	301946592	\\
2	&	95339	&	3150	&	5590	&	6720	&	5640	&	7970	&	5140	&	6120	&	7500	&	7970	&	301783500	\\
2	&	93851	&	4693	&	5787	&	5538	&	6358	&	8072	&	8681	&	5705	&	8337	&	8681	&	369176765	\\
2	&	93860	&	4700	&	5810	&	5540	&	6360	&	8050	&	8720	&	5720	&	8360	&	8720	&	370436200	\\
2	&	93750	&	5020	&	6860	&	8820	&	6040	&	6640	&	5780	&	6120	&	7490	&	8820	&	357586500	\\
2	&	93734	&	5027	&	6862	&	8823	&	6014	&	6626	&	5785	&	6105	&	7498	&	8823	&	357232428	\\
2	&	93755	&	3090	&	4820	&	8620	&	6580	&	7180	&	8220	&	6380	&	9050	&	9050	&	392109000	\\
2	&	90244	&	2190	&	3685	&	8027	&	6862	&	7714	&	6374	&	7329	&	9054	&	9054	&	365717927	\\
2	&	93746	&	3098	&	4836	&	8587	&	6585	&	7152	&	8225	&	6403	&	9078	&	9078	&	392293516	\\
2	&	90255	&	2170	&	3690	&	8020	&	6920	&	7740	&	6380	&	7360	&	9080	&	9080	&	367759800	\\
\hline																							
3	&	95570	&	2886	&	5696	&	4379	&	6292	&	5707	&	3119	&	7411	&	6883	&	7411	&	244134937	\\
3	&	95560	&	2890	&	5750	&	4430	&	6310	&	5680	&	3140	&	7420	&	6910	&	7420	&	245782100	\\
3	&	94521	&	3642	&	6389	&	5160	&	5852	&	5583	&	8440	&	7190	&	8173	&	8440	&	335852507	\\
3	&	94524	&	3670	&	6380	&	5190	&	5870	&	5680	&	8450	&	7220	&	8210	&	8450	&	338763700	\\
3	&	94337	&	3200	&	4050	&	4970	&	6720	&	7170	&	4520	&	8940	&	7870	&	8940	&	310201600	\\
3	&	94355	&	3155	&	4023	&	4964	&	6706	&	7179	&	4505	&	8976	&	7858	&	8976	&	309900092	\\
3	&	94701	&	3370	&	5840	&	6040	&	7700	&	5720	&	8900	&	9240	&	7350	&	9240	&	392562600	\\
3	&	94682	&	3392	&	5841	&	6013	&	7648	&	5711	&	8884	&	9251	&	7295	&	9251	&	390610021	\\
3	&	95399	&	6073	&	8997	&	9257	&	6764	&	5336	&	9124	&	6453	&	6675	&	9257	&	447188189	\\
3	&	95392	&	6070	&	9010	&	9280	&	6780	&	5350	&	9130	&	6440	&	6680	&	9280	&	448187200	\\
\hline																							
4	&	91797	&	3570	&	5820	&	5970	&	5750	&	7450	&	6880	&	7190	&	7830	&	7830	&	331162600	\\
4	&	91774	&	3544	&	5771	&	5963	&	5736	&	7436	&	6820	&	7188	&	7835	&	7835	&	329184507	\\
4	&	94379	&	3998	&	7978	&	4098	&	7478	&	6446	&	6356	&	6064	&	7633	&	7978	&	329331013	\\
4	&	94355	&	3970	&	8020	&	4100	&	7500	&	6480	&	6420	&	6070	&	7630	&	8020	&	331409900	\\
4	&	94111	&	7115	&	4734	&	5949	&	5765	&	7869	&	7135	&	7011	&	8032	&	8032	&	368156338	\\
4	&	94108	&	7110	&	4740	&	5980	&	5790	&	7930	&	7120	&	7040	&	8040	&	8040	&	370086700	\\
4	&	94689	&	5151	&	5867	&	7058	&	5891	&	7064	&	7561	&	8477	&	8623	&	8623	&	398758210	\\
4	&	94664	&	5170	&	5930	&	7070	&	5920	&	7060	&	7540	&	8500	&	8640	&	8640	&	400519900	\\
4	&	94744	&	3150	&	5100	&	4670	&	8650	&	7450	&	8840	&	7360	&	7380	&	8840	&	374846000	\\
4	&	94739	&	3110	&	5083	&	4654	&	8668	&	7490	&	8869	&	7289	&	7383	&	8869	&	374700400	\\
\hline																							
5	&	96101	&	3426	&	4757	&	3224	&	6565	&	6479	&	8279	&	5368	&	7891	&	8279	&	289462513	\\
5	&	96079	&	3490	&	4740	&	3240	&	6610	&	6520	&	8300	&	5380	&	7910	&	8300	&	291750300	\\
5	&	92973	&	1545	&	2823	&	4043	&	7699	&	7171	&	8649	&	6194	&	7845	&	8649	&	312114907	\\
5	&	95227	&	4544	&	8396	&	8668	&	6372	&	5618	&	8555	&	7288	&	8150	&	8668	&	431164753	\\
5	&	93006	&	1580	&	2890	&	4070	&	7790	&	7190	&	8680	&	6180	&	7870	&	8680	&	315265300	\\
5	&	95196	&	4570	&	8420	&	8710	&	6350	&	5640	&	8540	&	7320	&	8190	&	8710	&	433367600	\\
5	&	93988	&	2871	&	4127	&	8865	&	7108	&	7827	&	8831	&	7379	&	8717	&	8865	&	424070879	\\
5	&	93981	&	2890	&	4160	&	8860	&	7110	&	7880	&	8880	&	7360	&	8720	&	8880	&	425866200	\\
5	&	95324	&	3554	&	6476	&	3949	&	7072	&	6636	&	7866	&	8913	&	7495	&	8913	&	361704323	\\
5	&	95302	&	3540	&	6470	&	3960	&	7180	&	6630	&	7880	&	8950	&	7500	&	8950	&	364030300	\\
\hline																							
Avg.	&	94065.6	&	3888.74	&	5577.84	&	5903.78	&	6583.7	&	6799.56	&	7345.06	&	7091.42	&	7928.98	&	8505.04	&	351413673.2	\\
St. Dev.	&	1289.92	&	1401.11	&	1608.1	&	1909	&	734.93	&	1040.89	&	1576.42	&	1066.21	&	691.34	&	591.71	&	54014249.39	\\
\hline																							
\end{tabular}
\end{sidewaystable*}

\begin{sidewaystable*}[h]
\caption{Robustness analysis results.}
\label{tab:results_robust}
\centering
\footnotesize
\begin{tabular}{|c|cccccccc|cc|}
\hline
Run	&	NearestPillPM	&	StarterPM	&	InfluenceMapPM	&	MCTSPM	&	MixMaxPM	&	StarterExPM	&	ICEPFeatSpooks	&	ICEP-IDDFS	&	$F_1$	&	$F_2$	\\
\hline
1	&	3170	&	12480	&	11220	&	6260	&	8580	&	19170	&	11600	&	13310	&	19170	&	1,083,696,700	\\
2	&	12300	&	6210	&	11580	&	11300	&	9840	&	16900	&	9530	&	14500	&	16900	&	1,135,147,000	\\
3	&	3290	&	5610	&	17260	&	10320	&	13980	&	16380	&	8440	&	16070	&	17260	&	1,239,929,500	\\
4	&	3370	&	5570	&	9650	&	9090	&	7940	&	16900	&	7580	&	11930	&	16900	&	766,567,300	\\
5	&	3310	&	6430	&	10240	&	6670	&	7380	&	13530	&	6880	&	9330	&	13530	&	573,556,100	\\
6	&	4060	&	11300	&	10910	&	5700	&	9910	&	11500	&	6980	&	11610	&	11610	&	709,662,300	\\
7	&	6470	&	9840	&	12300	&	5570	&	5760	&	15350	&	9680	&	12050	&	15350	&	828,706,400	\\
8	&	2920	&	6370	&	13940	&	11030	&	10640	&	18660	&	7580	&	15560	&	18660	&	1,126,063,000	\\
9	&	6940	&	9150	&	9560	&	6580	&	7210	&	14880	&	7400	&	11250	&	14880	&	721,297,100	\\
10	&	2990	&	5920	&	8750	&	6660	&	8130	&	15740	&	7340	&	15660	&	15740	&	777,860,300	\\
11	&	3080	&	13410	&	9550	&	8220	&	6450	&	17900	&	7860	&	11580	&	17900	&	905,973,900	\\
12	&	3170	&	8670	&	11290	&	6760	&	6230	&	11420	&	7440	&	10140	&	11420	&	585,782,000	\\
13	&	9940	&	7140	&	13870	&	7150	&	8280	&	13850	&	7440	&	10740	&	13870	&	824,364,700	\\
14	&	2100	&	9780	&	15190	&	8690	&	5750	&	13130	&	8820	&	9620	&	15190	&	782,106,800	\\
15	&	7770	&	16990	&	10380	&	9170	&	9030	&	13480	&	6000	&	13710	&	16990	&	1,028,081,700	\\
16	&	4980	&	9200	&	6090	&	6460	&	5750	&	17180	&	8570	&	15870	&	17180	&	841,776,800	\\
17	&	6250	&	16730	&	16200	&	6130	&	5090	&	18660	&	8150	&	8340	&	18660	&	1,129,054,100	\\
18	&	3090	&	4430	&	8540	&	6520	&	7450	&	15610	&	8270	&	9360	&	15610	&	599,792,100	\\
19	&	2920	&	7030	&	15330	&	8750	&	6520	&	15360	&	11920	&	17090	&	17090	&	1,082,113,200	\\
20	&	3460	&	4460	&	13090	&	7500	&	7680	&	18530	&	10160	&	11110	&	18530	&	888,462,300	\\
21	&	4990	&	4460	&	16190	&	6100	&	8840	&	21080	&	9240	&	13280	&	21080	&	1,128,365,800	\\
22	&	2660	&	14640	&	10950	&	7380	&	6560	&	15700	&	11710	&	11640	&	15700	&	957,909,400	\\
23	&	2890	&	12660	&	16230	&	9520	&	9980	&	19260	&	8620	&	11300	&	19260	&	1,195,213,400	\\
24	&	12290	&	6160	&	15010	&	6370	&	6560	&	15000	&	4630	&	11050	&	15010	&	866,439,700	\\
25	&	2660	&	13910	&	9680	&	7780	&	10590	&	15380	&	8850	&	11320	&	15380	&	909,951,900	\\
26	&	2570	&	7450	&	7990	&	8260	&	8650	&	11150	&	6670	&	11340	&	11340	&	566,404,600	\\
27	&	3610	&	9660	&	10180	&	9030	&	13680	&	15600	&	13660	&	17940	&	17940	&	1,230,462,600	\\
28	&	3570	&	13070	&	8990	&	6770	&	10110	&	10580	&	10000	&	11390	&	13070	&	754,103,400	\\
29	&	3080	&	4650	&	10380	&	7440	&	5710	&	15060	&	7570	&	16160	&	16160	&	772,065,100	\\
30	&	4200	&	18550	&	13970	&	6450	&	7990	&	20470	&	6510	&	15790	&	20470	&	1,373,071,100	\\
\hline
Avg.	&	4603.33	&	9397.67	&	11817.00	&	7654.33	&	8209.00	&	15780.33	&	8503.33	&	12668.00	&	16261.67	&	912799343.33	\\
St. Dev	&	2739.98	&	4100.41	&	2895.88	&	1556.44	&	2201.58	&	2732.91	&	1928.96	&	2575.10	&	2521.11	&	219969266.43	\\
CV	&	0.60	&	0.44	&	0.25	&	0.20	&	0.27	&	0.17	&	0.23	&	0.20	&	0.16	&	0.24	\\
\hline
\end{tabular}
\end{sidewaystable*}

\begin{sidewaystable*}[h]
\caption{Ghosts controllers results.}
\label{tab:results_ghosts}
\centering
\footnotesize
\begin{tabular}{|c|cccccccc|cc|}
\hline
Ghosts Controller & NearestPillPM & StarterPM & InfluenceMapPM & MCTSPM & MixMaxPM & StarterExPM & ICEPFeatSpooks & ICEP-IDDFS & $F_1$ & $F_2$	\\
\hline
StarterGhosts	&	2020	&	3200	&	7170	&	4490	&	13350	&	15770	&	15410	&	17410	&	17410	&	1,053,381,000	\\
Legacy2TheReckoning	&	1570	&	4650	&	11430	&	9900	&	12040	&	7460	&	13660	&	17550	&	17550	&	947,953,600	\\
InfluenceMapGhosts	\cite{Svensson2012} &	2920	&	6450	&	3660	&	9020	&	16920	&	14010	&	9950	&	21500	&	21500	&	1,188,703,900	\\
Legacy	&	3670	&	7670	&	9450	&	8180	&	16190	&	16650	&	9820	&	24260	&	24260	&	1,452,831,300	\\
AggressiveGhosts	&	2000	&	5390	&	6850	&	12260	&	13860	&	14280	&	16690	&	32070	&	32070	&	1,933,341,200	\\
\hline
\end{tabular}
\end{sidewaystable*}

\section*{Acknowledgment}
Liberatore would like to thanks the GeNeura research group at
University of Granada for their kind hospitality during his visit.

\bibliographystyle{IEEEtran}
\bibliography{GhostsGA}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

%\begin{IEEEbiography}{Michael Shell}
%Biography text here.
%\end{IEEEbiography}

% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

%\begin{IEEEbiographynophoto}{Jane Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}

\end{document}


