\documentclass[journal]{IEEEtran}
% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


\usepackage{ifpdf}
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  \usepackage[dvips]{graphicx}
  \DeclareGraphicsExtensions{.eps}
\fi
\graphicspath{{./pics/}}

\usepackage{cite}
\usepackage[cmex10]{amsmath}
\interdisplaylinepenalty=2500
\usepackage{amsfonts}
\usepackage{algorithmic}
\usepackage{array}
\usepackage{dblfloatfix}
\usepackage{subfig}
\usepackage{rotating}

\usepackage{url}
\urldef{\mailsa}\path|federico.liberatore@urjc.es|
\urldef{\mailsb}\path|{amorag, pacv, jmerelo}@geneura.ugr.es|

\begin{document}

\title{Comparing Heterogeneous and Homogeneous Flocking Strategies for the Ghost Team in the Game of Ms.\  Pac-Man}

\author{Federico Liberatore*, Antonio M. Mora, Pedro A. Castillo, Juan J. Merelo
\thanks{Manuscript submitted for review on \today.}%
\thanks{This work has been supported in part by CANUBE (CEI2013-P-14) and ANYSELF (TIN2011-28627-C04-02), awarded by the Spanish Ministry of Science and Innovation. Liberatore's research was financed by the Government of Spain (TIN2012-32482). All the supports are gratefully acknowledged.}%
\thanks{Departamento de Arquitectura y Tecnología de Computadores,
CITIC-UGR, ETSIIT,
University of Granada, Spain.}%
\thanks{E-mail addresses: \mailsa, \mailsb}%
\thanks{*Corresponding author.}}

\markboth{IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI IN GAMES,~Vol.~XX, No.~YY, MMMM YYYY}%
{Liberatore \MakeLowercase{\textit{et al.}}: Heterogeneous VS Homogeneous Flocking Team Learning in the Game of Ms.\  Pac-Man.}
\maketitle

\begin{abstract}
In the last year, thanks to the Ms.\  Pac-Man vs Ghosts competition, the
game of Ms.\  Pac-Man has gained increasing attention from academics in
the field of Computational Intelligence. In this work, we contribute
to this research stream by presenting a simple Multi-Criteria Genetic
Algorithm for the optimization of Flocking Strategy-based ghost
controllers. Flocking Strategies are a paradigm for intelligent agents
characterized by showing emergent behavior, and for having very little
computational and memory requirements, making it extremely suited for
commercial applications and mobile devices. In particular, we study
empirically the effect of optimizing homogeneous and heterogeneous
teams. The computational analysis shows that the Flocking
Strategy-based controllers generated by the proposed Multi-Criteria
Genetic Algorithm outperform other ghost controllers
included in the competition framework and presented in the
literature. 
\end{abstract}
\begin{IEEEkeywords}
Flocking Strategies, Genetic Algorithms, Multi-criteria Decision Making, Team Learning, Ms.\  Pac-Man.
\end{IEEEkeywords}

\section{Introduction}
\label{sec:Introduction}

\IEEEPARstart{I}{n} the last decade the game of Ms.\  Pac-Man has been recognized by the scientific community as an ideal testbed for computational intelligence methods, receiving an increasing interest from academics. This success is largely due to the Ms.\  Pac-Man vs Ghosts competition \cite{Lucas2009,MsPacManVSGhost2011}, running since 2009, where participants can submit controllers for either Ms.\  Pac-Man or the Ghost Team. A good number of the controllers proposed made use of Computational Intelligence techniques, such as Neural Networks (NNs) \cite{Rojas1996}, Genetic Algorithms (GAs) \cite{Goldberg1988}, \textbf{Monte Carlo} Tree Search (MCTS) \cite{Browne2012}, and Minimax algorithms \cite{Osborne1994}.

Recently, a GA for the design of controllers for the Ghost Team based on Flocking Strategies (FSs)\footnote{\textbf{FS should not be confused with Evolutionary Strategies.}} has been proposed \cite{Liberatore2014}. FSs are sets of behavior rules that determine the next move of an agent as a force resulting from the interaction of the agents in the game. Controllers based on FSs have very little computational and memory requirements and, therefore, are extremely suited for commercial applications and mobile devices, differently from MCTS, Minimax, and other search-based algorithms that rely on high computing power. The fitness function of the GA proposed by \cite{Liberatore2014} tested the candidate solutions against two basic Ms.\  Pac-Man controllers. The authors showed that the methodology was capable of modeling complex behaviors and generating effective and challenging agents. Nevertheless, considering only two basic Ms.\  Pac-Man controllers results in Ghosts controllers capable of reacting only to simple strategies. For this reason, in this work we increase the number of Ms.\  Pac-Man controllers included in the fitness function and we now evaluate the candidate solutions in the GA against eight Ms.\  Pac-Man controllers with different levels of complexity. This requires a complete redesign of the fitness function, to equate between global optimization and performance balance. To do so, we draw from Multi-Criteria Decision Making (MCDM) theory, that includes techniques to explicitly consider multiple criteria in decision-making environments. In this context, the criteria correspond to the performance of several Ms.\  Pac-Man controllers.  Also, in this work we explore the paradigms of homogeneous and heterogeneous team learning. The performances of the controllers resulting from these two approaches are compared and empirical conclusions are drawn based on extensive experiments. 

The rest of the paper is organized as follows. In the next section we describe the game of Ms.\  Pac-Man and present the most relevant contributions in the literature. Next, we illustrate the structure of the FSs applied to the game of Ms.\  Pac-Man and how to optimize their definition using a GA. The results of the computational experiments are reported and commented in Section \ref{sec:Experiments}. Finally, in Section \ref{sec:Conclusions} \textbf{we draw} some conclusions and highlight future opportunities to be pursuit in this line of research.

\section{Background}
\label{sec:Background}
In this section, the relevant background is provided. First, we present the game of Ms.\  Pac-Man and its \textbf{characteristics}. Next, a review of the works in the field of research is given.

\subsection{The game of Ms.\  Pac-Man}
\label{subsec:GameMsPacMan}
The game of Ms.\  Pac-Man is one of the many variants of the famous
Pac-Man game, released in 1981. Ms.\  Pac-Man  extends the mechanics of
the original with several features, the most interesting being
different ghosts' behavioral patterns and the inclusion of a random
movement to prevent the use of patterns to clear each round.

The game has been chosen for the Ms.\  Pac-Man vs Ghosts competition, an AI competition where participants can submit controllers for both Ms.\  Pac-Man and the Ghost Team. The controllers have directly opposing objectives.\textbf{In fact, the objective of Ms.\  Pac-Man is to maximize the final score, while the objective of the Ghost Team is to minimize it.} The version of the game implemented for the competitions differs slightly from the original one. A thorough description of the game rules can be found in \cite{MsPacManVSGhost2011}. For the purposes of this work, the restrictions for the Ghost Team relevant to this work are briefly \textbf{listed} in the following:
\begin{itemize}
  \item A ghost can never stop and, when it is in a corridor, it can only move forward.
  \item A ghost can choose its direction only at a junction. Specifically, a ghost can only move into a corridor different from the one it is coming from. As a result, a ghost cannot turn back on itself.
  \item Every time a ghost is at a junction the controller has to provide a direction (i.e., UP, DOWN, LEFT, or RIGHT) from the set of feasible directions, i.e., those directions corresponding to corridors different from the one the ghost is coming from. If no direction or an unfeasible direction is returned by the controller, the game framework chooses one randomly from the set of feasible directions.
  \item At every tick of the game all the ghosts obligatorily reverse their direction according to a small random probability, set in the framework implementation to 0.005.
  \item \textbf{After 4000 game ticks, a level is considered completed and the game moves on to the next level.}
\end{itemize}

\subsection{State of the Art}
Most of the contributions in the literature focused on implementing and analyzing controllers for Ms.\  Pac-Man. In the last decade a number of Evolutionary Algorithms (EAs) have been proposed to address different aspects of the game of Ms.\  Pac-Man. One of the first works in the subject is the paper by Gallagher \cite{Gallagher03} that optimized rule-based fine state machines through population-based incremental learning to devise an adaptive Pac-Man agent. More recently, Galvan-Lopez \cite{Galvan-Lopez10} explored and compared the performance of two types of Grammatical Evolution (GE) mappings to generate controllers for Ms.\  Pac-Man. Alhejali and Lucas \cite{Alhejali10} applied Genetic Programming (GP) to evolve a diverse set of behaviors using different versions of the game. The resulting controller proved to be competitive with the best reactive controllers reported at the time. In a subsequent article \cite{AlhejaliLucas11}, the same authors extended their work by applying a ``training camp framework'' to the GP, where a set of specialized behaviors is evolved according to specific training scenarios. A different approach is presented by Brandstetter and Ahmadi \cite{Brandstetter12} \textbf{who proposed a GP-based controllers that rely exclusively on information retrieval terminals rather than action-issuing terminals. Also, their methodology evaluates each direction individually rather than simply taking a single collection of state features as input for each time step.} Thawonmas \cite{Thawonmas10} applied a GA to optimize the parameters of the Ms.\  Pac-Man controller ICE Pambush 3, winner of the IEEE CEC 2009 Ms.\  Pac-Man competition. A number of authors made use of EAs to design NN-based controllers \cite{Lucas05,Burrow09,Keunhyun10}. Beside EA and GA, a wide range of other techniques have been applied, such as  Ant Colonies \cite{Emilio2010}, Monte Carlo methodologies \cite{Tong2010,Tong2011}, Monte Carlo Tree Search (MCTS) \cite{Samothrakis2011, Ikehata2011}, and Reinforcement Learning \cite{Bom2013}. Alhejali and Lucas \cite{Alhejali2013} applied genetic algorithm to enhance the performances of a Ms.\  Pac-Man agent created using MCTS, showing an impressive 18\% increase on the average score. \textbf{Another hybrid approach is proposed by Schrum and Miikkulainen \cite{Schrum2014} that combines modular NNs with GAs. Each module of the NN specializes in a particular policy and the GA discovers these policies and defines when to use them. According to the authors, this methodology outperforms traditional NNs.}

In the last years, a number of works specializing on the Ghost Team have been proposed. Nguyen and Thawonmas \cite{Nguyen2011,Nguyen2013} presented a controller based on MCTS where the behavior of Ms.\  Pac-Man is simulated. Their controller won the Ms.\  Pac-Man Versus Ghost Team Competition held in 2011. Svensson and Johansson \cite{Svensson2012} exploited the behavior emerging capabilities of Influence Maps. A significant number of works made use of EAs methodologies. Jia-Yue \emph{et al.} \cite{Jia-Yue11} applied NN-based controllers evolved through GAs. Gagné and Congdon \cite{Gagne2012} evolved rule-based intelligent agent for the ghost team. Tamura and Torii \cite{Tamura2013} designed artificial ghost agents using GE. Cardona \textit{et al.} \cite{Cardona13} explored competitive co-evolution techniques to generate at the same time optimal Ms.\  Pac-Man and Ghost Team controllers. A different line of research is pursued by Sombat \textit{et al.} \cite{Sombat2012} that analyzed Ms.\  Pac-Man matches to classify Ghost Team controllers according to their enjoyability and, therefore, understand the attribute that a NPC should posses for players to be engaged. Similarly, Hasan and Khondker \cite{Hasan2013} explored the user friendliness of ghost controllers. In their research, they implemented a NN controller to assess the level of challenge that better suits the player.

Finally, evolved FSs were proposed for the first time by Liberatore \emph{et al.} \cite{Liberatore2014}.  Their structure is briefly presented in the following section, along with some new results regarding their computational complexity and two new focuses based on team learning paradigms.

\section{Models and Methods}
\label{sec:ModelsMethods}
This section is devoted to explaining the structure of the Ghost Team agents proposed, based on FSs. The paradigms of homogeneous and heterogeneous team learning are also presented and applied. 

\subsection{Flocking Strategies for the Ghost Team}
Swarm intelligence (SI) is the term used to describe the type of coordinated intelligence that arises from the collective behavior of decentralized, self-organized systems, either natural or artificial \cite{BeniWang89}. SI techniques have been widely used in many different fields \cite{Blum2008}.

Flocking refers to a SI technique proposed by Reynolds \cite{Reynolds87} for the coordinated movement of multiple AI agents. Originally, flocking algorithms \textbf{were} developed to mimic lifelike behaviors of groups of beings such as herds of animals, flocks of birds, swarms of insects, and schools of fishes. A flocking system typically consists of a population of simple agents (\textbf{called} boids) interacting locally with one another depending on the distance between them. The agents follow very simple steering behaviors:

\begin{itemize}
	\item \textit{Separation} makes the agent steer away from close flock mates.
	\item \textit{Alignment} makes the agent steer toward the average heading of the flock.
	\item \textit{Cohesion} makes the agent steer toward the average position of distant flock mates.
\end{itemize} 

Despite the lack of a centralized control structure dictating how
individual agents should behave, the interactions between such agents
lead to the emergence of "intelligent" global behavior, unknown to the
individual agents \cite{SpectorEtAl03}. Given this desirable property,
the easiness of implementation, and the reduced computational cost,
\textbf{flocking algorithms have been extensively applied to videogames}
\cite{Scutt02}.

\begin{figure}[!t]
  \caption{Representation of the neighborhoods surrounding a ghost and of the interactions with other actors. The interaction of the ghost with other actors depends on the area they fall in. In this example, the ghost is attracted to Ms.\ Pac-Man and is repelled by the powepill. The movement of the ghost is determined by the sum of all the forces it is subjected to.}
  \label{fig:Neigh_interaction}
  \centering
  \includegraphics[scale=0.5]{"neigh_inter"}
\end{figure}

\textbf{Figure \ref{fig:Neigh_interaction} illustrates a simplified representation of the functioning of the FSs for the Ghost Team presented in the following. Each ghost is surrounded by concentric areas called neighborhoods. The neighborhoods are associated to a certain magnitude. If an actor (i.e., element of the game such as Ms.\ Pac-Man or other ghosts) is located inside a neighborhood, a certain force is applied to the ghost. The magnitude of the force depends on the neighborhood the actor falls in. The final behavior of the ghost results from the sum of all the forces it is subjected to. In the following, the elements comprising a FS for the Ghost Team are formally illustrated.}

\subsubsection{Sets and Attributes}
\begin{itemize}
  \item $M=\{$UP, DOWN, LEFT, RIGHT$\}$, Set of moves, indexed by $m$. Subset $\overline{M}\subset M$ includes only the feasible moves, according to the restrictions on the ghosts' movement (please, refer to Section \ref{subsec:GameMsPacMan}).
  \item $G=\{$BLINKY, PINKY, INKY, SUE$\}$, Set of ghosts, indexed by $g$.
  \item $S=\{$HUNTER, HUNTED, FLASH$\}$, Set of ghosts' states, indexed by $s$. When in state HUNTER, a ghost is dangerous and kills Ms.\  Pac-Man when it touches her. HUNTED defines the state of a vulnerable ghost; in the game this is represented by the ghost turning deep blue. Vulnerable ghosts FLASH white to signal that they are about to become dangerous again.
  \item $A=\{$PACMAN, POWERPILL, HUNTER, HUNTED, FLASH$\}$, \textbf{Set of types of actors}, indexed by $a$. POWERPILL represents one of the four big pellets that, when eaten by Ms.\  Pac-Man, make the ghosts vulnerable. HUNTER, HUNTED, and FLASH refers to ghosts in that state. $\overline{A}$ is the set of actors currently in the game.
  \item $N \in \mathbb{N}$, A positive natural number representing the number \textbf{of} neighborhoods, indexed by $n = 1, \ldots, N$. \textbf{Neighborhoods are areas centered on the current ghost. More specifically, the first neighborhood is a circle in Euclidean space, and each subsequent region is a ring.} The interaction between the current ghost and an actor depends on which neighborhood the latter falls in, as explained in the following.
  \item $\mathbf{v}_g$ and $\mathbf{v}_a$, Two dimensional Euclidean vectors representing the position on the map of a ghost and an actor, respectively, in $(x,y)$ coordinate system. We define $dist(g,a)$ as the Euclidean distance between two position vectors.
\end{itemize}

\subsubsection{Representation}
A FS can be represented as a pair $(\boldsymbol\delta, \boldsymbol\alpha)$, explained in the following:
\begin{itemize}
  \item $\boldsymbol\delta \in \mathbb{R}_{>0}^N$, A vector of N real positive numbers. Each element $\delta_n$ is associated to one neighborhood and represents its maximum radius. Specifically, an actor $a$ falls into a neighborhood $n$ when its Euclidean distance to the current ghost $g$ is $\delta_{n-1} < dist(g,a) \leq \delta_n$. We assume that $\delta_0 = 0$, $\delta_N = \infty$, and $\delta_{n-1} < \delta_n < \delta_{n+1}$, i.e., each entry must be greater that its predecessor and lower than its successor.
  \item $\boldsymbol\alpha \in \mathcal{M}_{|S| \times |A| \times N}(\mathbb{R})$, A three dimensional matrix with real entries. The first dimension is associated to the state of the current ghost, the second to \textbf{the type of the} actor considered, and the third to the neighborhood where the actor falls in. Each element $\alpha_{s,a,n}$ represents the magnitude of the steering force on the current ghost resulting from the interaction with the actor. We consider that a negative magnitude corresponds to the behavior of separation, while a positive magnitude corresponds to the behavior of cohesion.
\end{itemize}

\subsubsection{Algorithm}
Every time a ghost is at a junction the game needs to calculate its next move. In a FS, the final behavior of the ghost is determined by the sum of all the behaviors resulting from the interactions with the other actors in the game. A controller based on FSs provides the next move by following these steps shown in Algorithm \ref{alg:FS_Controller}. For each actor $a$ in the game, the algorithm executes the following operations. First, it determines the neighborhood $n$ where the actor belongs. This is done by checking the distance between the ghost and the actor against the vector of \textbf{radii}, $\boldsymbol\delta$. Next, the steering force $\mathbf{f}^a$ is computed. The steering force is a two dimensional vector and is calculated as the product between the normalized positional difference vector between $g$ and $a$, and the appropriate magnitude, $\alpha_{s,a,n}$. Once all the steering forces have been calculated, the total steering force $\mathbf{f}$ is computed as their sum. The entries of this two dimensional vector are converted into a ranking for the moves: the first entry, corresponding to the x-axis, determines the rank for LEFT and RIGHT, while the second entry, corresponding to the y-axis, determines the rank for UP and DOWN. Finally, the algorithm returns the feasible move having maximum rank.

\begin{figure}[!t]
\begin{algorithmic}
\STATE $s\gets$ status of the current ghost $g$;
\FORALL{$a \in \overline{A}$}
	\STATE $n\gets n^\prime \ s.t.\ \delta_{n^\prime-1} < dist(g,a) \leq \delta_{n^\prime}$; \COMMENT{Determine the neighborhood.}
	\STATE $\mathbf{f}^a \gets \alpha_{s,a,n} \cdot \frac{\mathbf{v}_a - \mathbf{v}_g}{|dist(g,a)|}$; \COMMENT{Compute the steering force resulting from the interaction with the actor.}
\ENDFOR
\STATE $\mathbf{f} \gets \sum_{a \in \overline{A}} \mathbf{f}^a$; \COMMENT{Calculate the total steering force.}
\STATE \COMMENT{Translate the total steering force in a ranking for the next ghost direction as follows:}
\STATE $r_\text{UP} \gets - f_2$;
\STATE $r_\text{DOWN} \gets f_2$;
\STATE $r_\text{LEFT} \gets - f_1$;
\STATE $r_\text{RIGHT} \gets f_1$;
\RETURN $\arg\max_{m \in \overline{M}} r_m$; \COMMENT{Return the feasible direction (see restrictions in Section \ref{subsec:GameMsPacMan}) having maximum rank.}
\end{algorithmic}
\caption{Flocking Strategy-based Ghost Controller.}
\label{alg:FS_Controller} 
\end{figure}

The computational complexity of the algorithm is $O(|\overline{A}|N)$. $|\overline{A}|$ is the number of actors in the game, having a maximum value of eight, i.e., Ms.\  Pac-Man, three ghosts, and four power pills. Also the memory occupation is limited, as a FS can be represented with only $(N + |S| \times |A| \times N) = 16 \times N$ floats. Given the low computational and memory requirements, controllers based on FSs are particularly suited for commercial games, where the computational time allocated to AI operations is minimal, and machines having limited capabilities, such as portable and handheld devices.

\subsection{Team Learning}
A FS could be manually designed by an expert with decent results. Nevertheless, given the number of parameters and the inherent complexity of the game, it is desirable to automatize the definition of an effective strategy by means of an optimization algorithm. As the ghosts chase Ms.\  Pac-Man as a team, we look at team learning methodologies. In team learning \cite{Panait2005} the only learner involved is the team itself. This is different from multi-agent learning, where the single agents are trained separately. One of the main advantages of team learning is that it is possible to apply standard single-agent machine learning techniques. Moreover, it is not necessary to consider inter-agent credit assignment, i.e., identifying the contribution of each agent to the performance of the team.

Team learning can be divided into two main groups: homogeneous and
heterogeneous team learning. Homogeneous learners develop a single
agent behavior which is used by every agent on the team. Heterogeneous
learners can develop a unique behavior for each agent. Although it
generally leads to better solutions through agent specialization, it
is characterized by a larger state space that can complicate the learning \textbf{process.} It is also
 important to notice that agents can act heterogeneously even in
 homogeneous team learning, when the final behavior differs based on
 the agent's initial conditions. 

In this work, we explore the capabilities of homogeneous and heterogeneous FS for the Ghost Team. Specifically, we optimize the design of the FSs by means of a simple Multi-Criteria Genetic Algorithm (MCGA). In the following section, the algorithm is presented.

\subsection{A Multi-Criteria Genetic Algorithm for Flocking Strategies}
Following the work by Liberatore \emph{et al.} \cite{Liberatore2014} we apply a basic MCGA for the design of effective and resilient ghost controllers based on FSs. The main characteristics of the optimization algorithm are illustrated in the following.

\subsubsection{Individuals' Representation}
In this algorithm, an individual in the population (or a candidate solution) is represented by the FSs that compose it. In the case of homogeneous team learning, only one FS, $(\boldsymbol\delta, \boldsymbol\alpha)$, is necessary as all the ghosts will follow the same behavior. On the other hand, in heterogeneous team learning each ghost $g$ has an associated FS, $(\boldsymbol\delta^g,  \boldsymbol\alpha^g)$. \textbf{Overall, in the heterogeneous team learning case, an individual is represented by four different FSs.} Although the data structures for the heterogeneous case are four times bigger than the homogeneous ones, their total memory occupation is still very limited. In summary, an individual in the GA is represented as follows:

\begin{itemize}
  \item $(\boldsymbol\delta, \boldsymbol\alpha)$, for homogeneous team learning.
  \item $(\boldsymbol\delta^g, \boldsymbol\alpha^g)\: \forall g \in G$, for heterogeneous team learning.
\end{itemize}

We preserve the real encoding and the structure of the vector and of the matrix in the individuals' chromosomes.

\subsubsection{Initial Population}
The initial population is generated randomly as in Liberatore \emph{et al.} \cite{Liberatore2014}. More in detail, the entries of $\boldsymbol\delta$ follow a uniform distribution, while the elements of $\boldsymbol\alpha$ have a truncated normal distribution:

\begin{small}
\begin{equation}
	\label{eq:init_radius}
	\forall n \in \{1, \ldots, N\}, \: \delta_n \sim U(\delta_n,\infty)
\end{equation}
\begin{equation}
	\label{eq:init_magnitude}
	\forall s \in S, a \in A,  n \in \{1, \ldots, N\}, \: \alpha_{s,a,n} \sim N(0,1/3), \alpha_{s,a,n} \in [-1,1]
\end{equation}
\end{small}

The parameters of the normal distribution have been set so as to generate most of the magnitudes close to zero and assign similar probabilities to the appearance of cohesion, separation, and no interaction behaviors.

\subsubsection{Fitness Function}
To generate agents that perform well against a wide range of Ms.\  Pac-Man strategies, we calculate the fitness value of each individual by testing it against eight Ms.\  Pac-Man agents. Let $P=\{$NearestPillPM, StarterPM, InfluenceMapPM, MCTSPM, MixMaxPM, StarterExPM, ICEPFeatSpooks, ICEP-IDDFS$\}$, indexed by $p$, be the set of Ms.\  Pac-Man agents:

\begin{itemize}
  \item NearestPillPM, Basic controller included in the competition framework that moves Ms.\  Pac-Man to the closest pill, regardless of the state and position of the ghosts.
  \item StarterPM, Simple state machine based controller included in the competition framework.
  \item InfluenceMapPM, Influence Map-based controller \cite{Svensson2012}.
  \item MCTSPM, Enhanced MCTS controller \cite{Pepels2012}.
  \item MixMaxPM, Controller implementing a variation of the Minimax algorithm \cite{Cardona13}.
  \item StarterExPM, Another controller that combines the StarterPM and the MixMaxPM, giving a challenge factor between the two \cite{Cardona13}.
  \item ICEPFeatSpooks, Modified version of Spooks. Spooks was the winning Ms.\  Pac-Man entry for the CIG 2011 competition.
  \item ICEP-IDDFS, Very strong controller based on iterative deepening depth-first search, by Shirakawa, Nakamura and Thawonmas. As of this date, this controller ranks first in the Ms.\  Pac-Man vs Ghosts competition.
\end{itemize}

\textbf{All the controllers not included in the competition framework were obtained by contacting their respective authors.} The objective of the proposed GA is to design controllers that are efficient against a wide range of Ms.\  Pac-Man strategies, instead of focusing on just countering one or a few of them. Therefore, we would like to optimize the performance of our individuals against all the considered Ms.\  Pac-Man controllers. This objective can be expressed as:

\begin{equation}
\label{eq:minAllScores}
	\min \: \text{score}_p, \: \forall p \in P
\end{equation}

where $\text{score}_p$ represents the final score of the Ms.\  Pac-Man controller $p$. Equation \eqref{eq:minAllScores} is a multi-objective function (one objective for each Ms.\  Pac-Man controller) and it is not implementable as is. In fact, minimizing the performance of all the considered Ms.\  Pac-Man controllers might not be possible, as there could be trade-offs between them, i.e., increasing the effectivity of the Ghost Team against one Ms.\  Pac-Man controller might result in a loss of performance against another one. Therefore, the most realistic objective would be optimizing the FSs to obtain Ghost Team controllers whose performances are as balanced as possible:

\begin{equation}
\label{eq:minMaxScore}
	\min \: F_1 \: where \: F_1 = \max_{p \in P} \text{score}_p
\end{equation}

Equation \eqref{eq:minMaxScore} is concerned with finding a balance between the final scores of all the Ms.\  Pac-Man \textbf{controllers}. Another benefit of this formulation is that it minimizes the effect of noise present in this problem (and in videogames in general) \cite{Mora12}. In fact, due to the stochastic elements of the game, the same FS could perform very well sometimes and quite bad some others. By choosing the worst (highest) score we reduce the effect of the noise introduced by \textbf{these} stochastic effects.

Although implementable, objective functions in the $\min \max$ form usually present a wide number of multiple optima\footnote{Multiple optima are different solutions having the same objective function value.} and produce solutions that are not efficient\footnote{A solution is efficient, or non-dominated, if none of the objective functions can be improved in value without degrading some of the other objective values.}. Therefore, to get an efficient one we consider a secondary objective function that optimizes for global performance.

\begin{equation}
\label{eq:minSquareScore}
	\min \: F_2 \: where \: F_2 = \sum_{p \in P} \text{score}_p^2
\end{equation}

The squared term has been introduced to penalize high scores. Given the characteristics of the problem we propose a lexicographic objective function:

\begin{equation}
\label{eq:lexicographic}
	\text{Lex} \: \min [F_1,F_2]
\end{equation}

In Lexicographic Optimization \cite{Dylan2010} the objectives can be ranked in the order of importance and they are not comparable directly, as in this case. In fact we can assume, without loss of generality, that $F_1$ is more important than $F_2$, i.e., we favor balance over global optimality. As a result, each individual in the population has an associated fitness vector, $\mathbf{F}=(F_1,F_2)$, which allows for a total order relation:

\begin{equation}
\label{eq:ordering}
	\mathbf{F}^A \succ \mathbf{F}^B \iff (F_1^A < F_1^B) \lor ((F_1^A = F_1^B) \land (F_2^A < F_2^B))
\end{equation}

where $\mathbf{F}^A$ and $\mathbf{F}^A$ are the fitness vectors associated to individuals A and B, respectively, and $\mathbf{F}^A \succ \mathbf{F}^B$ means that $\mathbf{F}^A$ is better than $\mathbf{F}^B$.

Once all the population individuals' fitness vectors have been calculated, we assign a rank-based fitness value. This is done by sorting the population according to the \textbf{dominance criteria} and \textbf{then} calculating a fitness value for each individual depending only on its position in the rank:

\begin{equation}
\label{eq:rankFitness}
	\text{Fitness}(\text{rank}) = \frac{\text{POP} - \text{rank}}{\text{POP}}
\end{equation}

where POP is the number of individuals in the population and rank is the position of an individual in this population, e.g., the least fit individual has $\text{rank} = \text{POP}$ while the fittest individual has $\text{rank} = 1$.

\subsubsection{Selection}
Individuals are selected by roulette wheel selection according to the rank-based fitness.

\subsubsection{Cross-Over}
In the proposed GA, two parents generate one child. The child's chromosome is created by random recombination of the parents' chromosomes. The entries of the neighborhood radius vector $\boldsymbol\delta$ and of the magnitude matrix $\boldsymbol\alpha$ in the chromosome of the child are evaluated individually. Each entry takes its value from one parent or the other according to a mixing probability.

In the case of heterogeneous team learning we apply restrictive
breeding, as Luke and Spector \cite{Luke1996} suggested that it works
better than having no restrictions. Restrictive breeding means that
that agents could only breed with like agents from other
teams. Applied to the context of this work, we allow crossover only
between the FSs corresponding to the same ghost; e.g., BLINKY breeds
only with BLINKY and PINKY only with PINKY, for instance.

\subsubsection{Mutation}
Mutation occurs with fixed probability. When a mutation happens, the current parameter is re-initialized to a random value, according to Equations \eqref{eq:init_radius} and \eqref{eq:init_magnitude}.

\section{Experiments}
\label{sec:Experiments}
The algorithms presented in this paper have been implemented in Java within the framework provided for the Ms.\  Pac-Man vs Ghosts competition. The final program \textbf{ran} on an Intel(R) Core(TM) i5-2500K @ 3.3GHz with four cores and 4GB of RAM. Each experiment \textbf{ran} on a single core. In order to ensure comparability, the same \textbf{standard} configuration of parameters for the MCGA has been used for all the experiments:

\begin{itemize}
  \item Population = 50.
  \item Elitism = 1.
  \item Mutation probability = 0.01.
  \item Crossover mixing probability = 0.6.
\end{itemize}

\textbf{The GA is stopped when there the best solution is not updated for 10 consecutive generations, to ensure that a certain degree of convergence has been reached \cite{Karma2003, Safe2004}. Preliminary systematic experiments were made and good results were achieved when using these parameters.} In any event, the MCGA can be run for any feasible configuration of the parameters.  We also changed the default configuration of the competition framework in the following way:

\begin{itemize}
  \item \textbf{The event that forces the ghosts to obligatorily reverse their direction has been removed so as to ensure consistency in the evaluation of the candidate solutions' fitness\footnote{The FSs are completely deterministic and the seed used to initialize the pseudo-random number generator of the MCTSPM controller has been fixed to a determined value.}.}
  \item The maximum duration of a game has been set to 4000 \textbf{ticks}, to reduce the computational time employed by the GA while still giving an ample margin for evaluating an individual's performance.
\end{itemize}

Overall, the following experiments have been done:

\begin{itemize}
  \item Comparison of the performance of the Ghost Team controllers obtained with different values of the parameter $N$ (i.e., the number of neighborhoods considered in the Flocking Rules).
  \item Comparison with other ghosts controllers from the literature.
  \item \textbf{Analysis of the performance ¡of the FS based controllers in the face of the reverse direction random event.}
\end{itemize}

\subsection{Performance Test}
The first experiment performed regards the comparison of the performance of the Ghost Team controllers obtained with different team learning strategies and different values of the parameter $N$. In principle, the best controllers should be obtained when heterogeneous team learning is applied and when high values of $N$ are used, as the solution space is bigger. Nevertheless, as the solution space increases, the actual performance of the MCGA could get worse. We considered all the values of $N$ ranging from one to five. For each value we executed the MCGA 10 times. Detailed information regarding each run is give in Tables \ref{tab:results_homogeneous} and \ref{tab:results_heterogeneous} in the Appendix.

\begin{table*} [!t]
\caption{Performance of the controllers for the Ghost Team obtained by the GA using different numbers of neighborhoods.}
\label{tab:summary}
\centering
\subfloat[Homogeneous team learning.]{
\begin{tabular}{|c|c|c|c|c|}
\hline 
$N$ & Mean CPU Time (s) & Mean \# Gen. & Best $F_1$ & Mean $F_1$  \\
\hline
1 & 102472.3 $\pm$ 53033.13 & 29.5 $\pm$ 15.96 & 6080 & 7991 $\pm$ 1081.16  \\
\hline
2 & 102187.3 $\pm$ 55850.54 & 29.7 $\pm$ 16.646988383 & 6450 & 7797 $\pm$ 1069.34 \\
\hline
3 & 103967.7 $\pm$ 90992.18 & 29.7 $\pm$ 25.46 & 5450 & 8147 $\pm$ 1406.84 \\
\hline
4 & 81284.2 $\pm$ 52390.85  & 23.2 $\pm$ 15.23 & 5140 & 7699 $\pm$ 1421.64 \\
\hline
5 & 128204.6 $\pm$ 86563.31 & 36.5 $\pm$ 24.19 & 6250 & 7665 $\pm$ 1136.38 \\
\hline 
\end{tabular}
\label{tab:summary_HOM}
}
\hfil
\subfloat[Heterogeneous team learning.]{
\begin{tabular}{|c|c|c|c|c|}
\hline 
$N$ & Mean CPU Time (s) & Mean \# Gen. & Best $F_1$ & Average $F_1$  \\
\hline
1 & 97498.1 $\pm$ 62154.75 & 28.8 $\pm$ 18.47 & 7730 & 8901 $\pm$ 642.00 \\
\hline
2 & 81688.1 $\pm$ 36166.06 & 23.8 $\pm$ 10.51 & 8540 & 9278 $\pm$ 498.01 \\
\hline
3 & 112749.6 $\pm$ 63648.19 & 33.4 $\pm$ 19.12 & 7660 & 9169 $\pm$ 703.03 \\
\hline
4 & 90035.6 $\pm$ 45783.59 & 26.2 $\pm$ 13.00 & 7870 & 9074 $\pm$ 594.25 \\
\hline
5 & 133597.8 $\pm$ 101495.49 & 39.2 $\pm$ 30.46 & 7700 & 9025 $\pm$ 746.73 \\
\hline 
\end{tabular}
\label{tab:summary_HET}
}
\end{table*}

Table \ref{tab:summary} shows the performance of the evolved controllers over 10 runs of the MCGA with $N=1,\ldots,5$ when applying homogeneous and heterogeneous team learning (Tables \ref{tab:summary_HOM} and \ref{tab:summary_HET}, respectively). Each row is associated to a different number of neighborhoods, displayed in the first column. The second column presents the average computational time; the standard deviation is also reported after the plus-minus sign.\textbf{The third column shows the average number of generations across the 10 runs and the corresponding standard deviation.} The following column illustrates the fitness value $F_1$ of the best controller found \textbf{in the 10 runs}. A higher $F_1$ value corresponds to a lower ghosts' performance, and the other way round. Finally, the last column reports the average fitness value over the 10 runs and the corresponding standard deviation. By observing the tables some conclusions can be drawn.

Concerning the computational time, we can see that a single run takes
quite a significant amount of time to complete\textbf{(more than 30 hours
on average)}. The reason for that is that the most advanced
Ms.\  Pac-Man controllers make use of all the allowed maximum
computational time for each game tick (40 ms). \textbf{According to Table \ref{tab:summary} there does not seem to be a difference between the homogeneous and heterogeneous team learning strategies in term of computational time. In fact, an ANOVA test confirms this result by show that the p-value is equal to 0.7311\footnote{P-values are adjusted to account for the increased risk of a Type I error resulting from doing multiple hypothesis tests. A $p-value\geq0.05$ is considered to indicate that the sample does not support the hypothesis of difference in the means.}.}

\textbf{For the homogeneous team learning case the best controller was obtained
when $N=4$, while the case $N=5$ has the best average fitness. On the other hand, for the heterogeneous team learning case the best controller was obtained when $N=3$, while the best average fitness was found with $N=1$. In both cases, no clear trend can be identified in the best and average fitness. This observation has been verified by running statistical tests. After verifying the normality of the samples with the Kolmogorov-Smirnov test, we run an ANOVA that shows low significance for both the homogeneous and the heterogeneous team learning cases: $p-value=0.8924$ and $p-value=0.7394$, respectively Therefore, we cannot claim that, according to the results obtained in the experiments, a higher number of neighborhoods implies better Ghost Team controllers.}

Finally, we compared the performances of the homogeneous and heterogeneous teams. The results of the Tukey's range test for each value of $N$ are reported in the following.

\begin{itemize}
\item $N=1$, $p-value = 0.5535313$.
\item $N=2$, $p-value = 0.0353661$.
\item $N=3$, $p-value = 0.3842355$.
\item $N=4$, $p-value = 0.0685822$.
\item $N=5$, $p-value = 0.0749569$.
\end{itemize}

\textbf{Our sample shows that there is provable statistical difference only for the case with $N=2$. Therefore, we can assume that, for $N=2$ and the proposed MCGA, the heterogeneous team learning strategies lead to worst controllers than the homogeneous team ones.}

\subsection{Comparison with Other Controllers}
To understand the goodness of the ghost controllers generated by the MCGA we compare their performance to that of other controllers taken from the competition framework and the literature. \textbf{All the controllers not included in the competition framework were obtained by contacting their respective authors.} Table \ref{tab:summary_others} shows the $F_1$ scores obtained (the detailed results of this experiment are illustrated in Table \ref{tab:results_ghosts} in the Appendix).\textbf{In this set of experiments, the fitness values for the Ghost controllers have been calculated by applying the same conditions adopted for the GA, so as to ensure comparability of the results.}

\begin{table} [!t]
\caption{Performance of the other Ghost Team controllers from the competition framework and the literature.}
\label{tab:summary_others}
\centering
\begin{tabular}{|c|c|}
\hline 
Controller & $F_1$ \\
\hline
Memetix\cite{Tose2012} & 6030 \\
\hline
Eiisolver \cite{Verhaard} & 10790 \\
\hline
StarterGhosts & 17410 \\
\hline
Legacy2TheReckoning & 17550 \\
\hline
InfluenceMapGhosts \cite{Svensson2012} & 21500 \\
\hline
Legacy & 24260 \\
\hline
AggressiveGhosts & 32070 \\
\hline
\end{tabular}
\end{table}

\textbf{Eiisolver and Memetix won, respectively, the first and the second place in the CIG 2012 competition \cite{CompetitionURL}. As expected, these two controllers produced the best results. More specifically, Memetix obtained a fitness similar to that of the best controller generated by the MCGA in the experiments, 5140. However, the fitness of Eiisolver is almost twice this value. However, by comparing the scores obtained by each Ms.\ Pac-Man controller (Tables \ref{tab:results_ghosts} and \ref{tab:results_homogeneous}), we can see that Memetix performed better than the best controller generated by the MCGA against 6 out of 8 controllers, while Eiisolver performed better against 3 out of 8 controllers. Since these Ghost controllers do not dominate each other, we can state that they have similar global performances.} These results support the claim that FSs are a viable option for the definition of intelligent controllers.

\subsection{\textbf{Analysis of Performance with Random Direction Reverse Event}}

The proposed MCGA evaluates the candidate solutions without considering the event that forces the ghosts to obligatorily reverse their direction. We now analyze the \textbf{performances} of the FS based controllers generated by the MCGA in the face of this random event. We expect them to be quite resilient, as the FSs choose the next move only according to the relative distance to the other agents and without considering any internal state.

In this experiment, \textbf{we consider the best controller found by the MCGA} and we run 100 games with the probability of the ghost direction reverse event set to the default value. We can use the results of this experiment to analyze the variability in the performance of the controller.

\begin{table}[!t]
\caption{\textbf{Analysis of the performance for the best ghost controller generated by the GA with random direction reverse event.}}
\label{tab:summary_robust}
\centering
\begin{tabular}{|c|c|c|}
\hline
 & $F_1$ & $F_2$ \\
\hline
Avg.	&	14262	&	612,410,738	\\
\hline
St. Dev	&	2658.93	&	156,797,817.09	\\
\hline
CV	&	0.18643	&	0.25603	\\
\hline
\end{tabular}
\end{table}

Table \ref{tab:summary_robust} presents the average, the standard deviation, and the coefficient of variation (CV)\footnote{The CV is defined as the ratio of the standard deviation to the mean.} for objectives $F_1$ and $F_2$, calculated over the \textbf{100} runs. For both objectives the CV takes low values, inferior to 0.30, suggesting that the variation in the performance of the controller is low. Thus, we can claim that the ghost controller generated by the proposed GA is resilient to the random direction reverse event.

\section{Conclusions}
\label{sec:Conclusions}
In this article, we extended the research on the controller for the Ghost Team by proposing a basic MCGA for the effective design of ghosts agents. We analyzed the complexity of a FS controller in terms of memory and computational effort, showing that they are both very small. Therefore, FSs find natural application in all the contexts where both the computational time and the memory consumption are critical, such as commercial games and handheld devices.

We took a step forward from the work in Liberatore \emph{et al.} \cite{Liberatore2014} by including eight Ms.\  Pac-Man controllers having different degrees of complexity in the fitness function. This required a redefinition of the fitness function. We proposed a lexicographic function that assigns high priority to balance and low priority to global performance. We showed empirically that the resulting Multi-Criteria Genetic Algorithm is capable of generating effective and challenging ghost controllers, having better performance than other controllers included in the competition framework or presented in the literature.

There is still a lot to be investigated to ascertain the real capabilities of the FSs. Some possible future lines of research are highlighted in the following.

As showed in the experiments, a single run of the MCGA takes a significant amount of computational time. Strategies for its reduction should be explored. An initial step could be doing a profiling of the program. \textbf{Also, the sensitivity of the performance of the MCGA to the parameters used should be explored.}

The proposed MCGA provided satisfactory results for the homogeneous team learning case. Nevertheless, in the heterogeneous team learning case, the extended solution space did not allow it to converge to a satisfactory solution.\textbf{ Possible solutions that need to be investigated are (1) to warm-start the heterogeneous team GA by using good homogeneous teams and (2) to implement mutation operators that make large changes to the canditate solution, such as replacing the behavior of one ghst with a copy of the behavior of other ghost}.  Optimization methodologies other than GAs could be investigated. Covariance Matrix Adaptation Evolution Strategies (CMA-ES) and Particle Swarm Optimization (PSO) might be sensible choices, as no assumption on the objective function or on the problem are made.

One of the main drawbacks of the fitness function adopted in this work is the amount of time required to evaluate the performance of one individual against eight different Ms.\  Pac-Man controllers. This is mostly due to the time consumption of the controllers based on minimax algorithm and other exploratory methods. Therefore, it could be interesting to co-evolve two distinct populations of ghosts and Ms.\  Pac-Man controllers based on FSs. This would speed up the time taken to compute the fitness of the individuals, allowing for more iterations in the optimization process. Potentially, this could lead to finding better controllers for the Ghost Team.

We hope that this work will be a useful source of ideas for future research on computational intelligence algorithms in games and will contribute further in the development and solution of more complex problems.

\appendices
\section{}
\label{sec:CompleteResults}
Tables \ref{tab:results_homogeneous} and \ref{tab:results_heterogeneous} illustrate the results relative to all the experiments performed. In the tables, the columns present the following information: 

\begin{itemize}
  \item $N$, Number of neighborhoods.
  \item \textbf{\# Gen., Number of generations.}
  \item CPU time, Computational time expressed in seconds.
  \item NearestPill - ICEP-IDDFS, Final score achieved by each Ms.\  Pac-Man controller.
  \item $F_1$ and $F_2$, maximum score (Equation \eqref{eq:minMaxScore}) and sum of squared scores (Equation \eqref{eq:minSquareScore}), respectively.
\end{itemize}

The results relative to the ghosts controllers from other authors are displayed in Table \ref{tab:results_ghosts}.

\begin{sidewaystable}[h]
\caption{Ghosts controllers results.}
\label{tab:results_ghosts}
\centering
\footnotesize
\begin{tabular}{|c|cccccccc|c|}
\hline
Ghosts Controller & NearestPillPM & StarterPM & InfluenceMapPM & MCTSPM & MixMaxPM & StarterExPM & ICEPFeatSpooks & ICEP-IDDFS & $F_1$ \\
\hline
memetix \cite{Tose2012}	&	1310	&	1330	&	1650	&	2020	&	6030	&	1480	&	1470	&	4720	&	6030 \\
eiisolver \cite{Verhaard}	&	1970	&	2440	&	4110	&	3920	&	6200	&	6780	&	10790	&	5470	&	10790	\\
StarterGhosts	&	2020	&	3200	&	7170	&	4490	&	13350	&	15770	&	15410	&	17410	&	17410	\\
Legacy2TheReckoning	&	1570	&	4650	&	11430	&	9900	&	12040	&	7460	&	13660	&	17550	&	17550	\\
InfluenceMapGhosts	\cite{Svensson2012} &	2920	&	6450	&	3660	&	9020	&	16920	&	14010	&	9950	&	21500	&	21500	\\
Legacy	&	3670	&	7670	&	9450	&	8180	&	16190	&	16650	&	9820	&	24260	&	24260	\\
AggressiveGhosts	&	2000	&	5390	&	6850	&	12260	&	13860	&	14280	&	16690	&	32070	&	32070	\\
\hline
\end{tabular}
\end{sidewaystable}

\begin{sidewaystable*}[h]
\caption{Homogeneous team learning results.}
\label{tab:results_homogeneous}
\centering
\footnotesize
\begin{tabular}{|ccc|cccccccc|cc|}
\hline																				
$N$	&	\# Gen.	&	CPU Time (s)	&	NearestPillPM	&	StarterPM	&	InfluenceMapPM	&	MCTSPM	&	MixMaxPM	&	StarterExPM	&	ICEPFeatSpooks	&	ICEP-IDDFS	&	$F_1$	&	$F_2$	\\
\hline																				
1	&	34	&	125310	&	3440	&	3540	&	5640	&	5420	&	7290	&	9740	&	6090	&	9560	&	9740	&	362044600	\\
1	&	11	&	40482	&	1360	&	5850	&	3230	&	5890	&	3800	&	7870	&	7740	&	7200	&	7870	&	269321600	\\
1	&	37	&	120830	&	1560	&	2590	&	3160	&	4460	&	3370	&	3180	&	6080	&	5220	&	6080	&	124703000	\\
1	&	65	&	216727	&	3440	&	5610	&	7870	&	3860	&	5280	&	7010	&	5250	&	7330	&	7870	&	278452100	\\
1	&	31	&	107473	&	1360	&	5530	&	5820	&	5060	&	6080	&	5120	&	6880	&	7210	&	7210	&	254405800	\\
1	&	14	&	49325	&	3040	&	6380	&	6330	&	5120	&	5960	&	8050	&	5810	&	7350	&	8050	&	304332000	\\
1	&	22	&	73570	&	1560	&	2590	&	3160	&	6030	&	3370	&	3180	&	6970	&	6110	&	6970	&	162870500	\\
1	&	33	&	114416	&	3290	&	4800	&	8550	&	5710	&	6740	&	8180	&	5870	&	8760	&	8760	&	363105200	\\
1	&	13	&	47506	&	9220	&	5940	&	3150	&	5500	&	8280	&	8720	&	8570	&	8960	&	9220	&	458787800	\\
1	&	35	&	129084	&	2970	&	8000	&	5640	&	4190	&	5950	&	6840	&	7730	&	8140	&	8140	&	330387200	\\
\hline
2	&	24	&	82857	&	2290	&	4010	&	5030	&	6600	&	7120	&	3910	&	5390	&	7350	&	7350	&	239242200	\\
2	&	36	&	121703	&	3760	&	5430	&	4560	&	5120	&	5400	&	4600	&	6330	&	6450	&	6450	&	222621900	\\
2	&	60	&	199048	&	3440	&	6060	&	4270	&	4990	&	6210	&	9200	&	5460	&	8700	&	9200	&	320395900	\\
2	&	24	&	82209	&	2290	&	3690	&	4810	&	4170	&	8320	&	3690	&	7020	&	8730	&	8730	&	267717000	\\
2	&	20	&	71001	&	1360	&	2590	&	3160	&	5470	&	3370	&	3200	&	6140	&	6690	&	6690	&	152516800	\\
2	&	11	&	40323	&	7170	&	5710	&	7130	&	7250	&	3730	&	6100	&	6580	&	7240	&	7250	&	334249300	\\
2	&	25	&	86829	&	3340	&	7610	&	4880	&	5880	&	6080	&	7310	&	6420	&	7230	&	7610	&	311348300	\\
2	&	12	&	42303	&	2200	&	7650	&	3140	&	6170	&	9240	&	6000	&	7440	&	3180	&	9240	&	298134600	\\
2	&	56	&	196560	&	3150	&	4850	&	8390	&	4630	&	6490	&	8270	&	6240	&	8670	&	8670	&	349893500	\\
2	&	29	&	99040	&	1560	&	2590	&	3160	&	5890	&	3370	&	3180	&	6690	&	6780	&	6780	&	166013200	\\
\hline
3	&	23	&	78636	&	1390	&	2680	&	3350	&	6680	&	5280	&	6630	&	7820	&	8070	&	8070	&	263072000	\\
3	&	22	&	77445	&	3040	&	8830	&	8400	&	5790	&	8040	&	5600	&	5000	&	7160	&	8830	&	363561800	\\
3	&	30	&	103243	&	3540	&	5180	&	5790	&	5160	&	6650	&	6440	&	5770	&	6750	&	6750	&	264065200	\\
3	&	49	&	162516	&	3290	&	3900	&	5520	&	4900	&	5760	&	6590	&	5800	&	6750	&	6750	&	236322700	\\
3	&	34	&	113740	&	2770	&	2660	&	4840	&	4690	&	5450	&	2670	&	5430	&	3190	&	5450	&	136662600	\\
3	&	93	&	336705	&	2950	&	3110	&	3810	&	4700	&	5680	&	5850	&	6250	&	8550	&	8550	&	233630600	\\
3	&	12	&	43391	&	3790	&	5080	&	3130	&	7820	&	3640	&	5650	&	7590	&	9350	&	9350	&	301322500	\\
3	&	13	&	46238	&	1400	&	5520	&	6470	&	6210	&	8480	&	7070	&	5190	&	8520	&	8520	&	334277200	\\
3	&	10	&	37180	&	3120	&	3440	&	7000	&	7420	&	7590	&	9480	&	7640	&	9910	&	9910	&	429680600	\\
3	&	11	&	40583	&	2570	&	2660	&	3150	&	6210	&	3940	&	2670	&	9290	&	7280	&	9290	&	224122100	\\
\hline
4	&	13	&	48391	&	5780	&	4570	&	3130	&	7440	&	5080	&	4710	&	7120	&	7960	&	7960	&	281490300	\\
4	&	30	&	101728	&	3170	&	4000	&	8650	&	4580	&	5630	&	5430	&	7710	&	7860	&	8650	&	304253300	\\
4	&	13	&	45807	&	8990	&	7950	&	3470	&	9690	&	6920	&	3220	&	4950	&	9430	&	9690	&	421641800	\\
4	&	61	&	212354	&	2610	&	2660	&	4110	&	4880	&	5140	&	2670	&	4650	&	3190	&	5140	&	119941300	\\
4	&	10	&	36878	&	2820	&	2670	&	4110	&	8260	&	5320	&	2670	&	7270	&	8650	&	8650	&	263307700	\\
4	&	21	&	71813	&	2820	&	2660	&	5160	&	5520	&	4870	&	2670	&	5220	&	3190	&	5520	&	140394300	\\
4	&	26	&	90157	&	3540	&	6070	&	4670	&	7180	&	7520	&	5430	&	7240	&	6640	&	7520	&	305280300	\\
4	&	15	&	53907	&	2700	&	2590	&	3160	&	6020	&	7280	&	3180	&	6730	&	5070	&	7280	&	194332700	\\
4	&	30	&	106050	&	4050	&	3200	&	8540	&	6190	&	5360	&	6550	&	5950	&	8560	&	8560	&	318198400	\\
4	&	13	&	45757	&	4880	&	4160	&	4930	&	4640	&	4240	&	5130	&	7840	&	8020	&	8020	&	257035000	\\
\hline
5	&	15	&	54495	&	3290	&	5720	&	9030	&	7850	&	6280	&	9220	&	6760	&	8890	&	9220	&	435882400	\\
5	&	21	&	72830	&	2390	&	6080	&	4440	&	6040	&	4460	&	7050	&	8780	&	9030	&	9030	&	327097100	\\
5	&	27	&	93561	&	3380	&	4380	&	8680	&	5980	&	5160	&	5960	&	6220	&	8360	&	8680	&	312436800	\\
5	&	19	&	67000	&	7440	&	3470	&	5240	&	7250	&	6060	&	7170	&	8370	&	8050	&	8370	&	370406500	\\
5	&	53	&	180773	&	3150	&	6270	&	5470	&	6630	&	5540	&	6190	&	4980	&	7150	&	7150	&	268043800	\\
5	&	29	&	99402	&	3170	&	4680	&	3200	&	3940	&	4140	&	5150	&	5570	&	6340	&	6340	&	172597500	\\
5	&	75	&	268289	&	3340	&	4380	&	5170	&	4560	&	5940	&	6060	&	6250	&	5950	&	6250	&	224334700	\\
5	&	80	&	286078	&	3170	&	2890	&	4430	&	3360	&	4100	&	6040	&	6530	&	6560	&	6560	&	188281600	\\
5	&	16	&	55640	&	4690	&	4030	&	5300	&	6780	&	5720	&	3180	&	7340	&	8040	&	8040	&	273643400	\\
5	&	30	&	103978	&	3290	&	4420	&	4410	&	5480	&	5000	&	6780	&	6340	&	7010	&	7010	&	240143100	\\
\hline
Avg.	&	29.72	&	103623.22	&	3366.6	&	4618.6	&	5156.8	&	5785.2	&	5714.4	&	5729.2	&	6566	&	7326.8	&	7859.8	&	275520036	\\
St. Dev.	&	19.62	&	68677.34	&	1722.66	&	1675.71	&	1830.26	&	1260.97	&	1475.31	&	2041.98	&	1084.50	&	1643.77	&	1196.17	&	81950501.44	\\
\hline																				
\end{tabular}
\end{sidewaystable*}

\begin{sidewaystable*}[h]
\caption{Heterogeneous team learning results.}
\label{tab:results_heterogeneous}
\centering
\footnotesize
\begin{tabular}{|ccc|cccccccc|cc|}
\hline																				$N$	&	\# Gen.	&	CPU Time (s)	&	NearestPillPM	&	StarterPM	&	InfluenceMapPM	&	MCTSPM	&	MixMaxPM	&	StarterExPM	&	ICEPFeatSpooks	&	ICEP-IDDFS	&	$F_1$	&	$F_2$	\\
\hline																				1	&	35	&	118398	&	3250	&	6830	&	6070	&	5830	&	8510	&	8330	&	7390	&	8140	&	8510	&	390725900	\\
1	&	48	&	160669	&	3440	&	5950	&	6820	&	5840	&	8460	&	7840	&	6840	&	8520	&	8520	&	380267300	\\
1	&	11	&	38317	&	2350	&	3450	&	8740	&	6240	&	5350	&	8440	&	6130	&	9640	&	9640	&	363112800	\\
1	&	33	&	110836	&	3380	&	5370	&	8450	&	4360	&	6560	&	6330	&	6560	&	8550	&	8550	&	329912000	\\
1	&	11	&	38020	&	4570	&	4180	&	8060	&	6310	&	8660	&	9210	&	8730	&	9080	&	9210	&	461616000	\\
1	&	20	&	67031	&	2890	&	5580	&	4140	&	8570	&	7230	&	3530	&	7270	&	7370	&	8570	&	301976600	\\
1	&	12	&	42247	&	3170	&	4980	&	4090	&	7160	&	6640	&	9900	&	8960	&	9370	&	9900	&	413021100	\\
1	&	25	&	83886	&	5670	&	9040	&	9210	&	5540	&	7190	&	8970	&	5320	&	8940	&	9210	&	469769200	\\
1	&	24	&	81344	&	2890	&	5360	&	9160	&	5780	&	9170	&	5690	&	7430	&	9110	&	9170	&	409057700	\\
1	&	69	&	234233	&	3570	&	5930	&	7730	&	4420	&	6980	&	6740	&	6560	&	7340	&	7730	&	318256300	\\
\hline																				
2	&	18	&	60650	&	3460	&	3470	&	9130	&	5280	&	5630	&	9730	&	6090	&	9570	&	9730	&	390290600	\\
2	&	31	&	104864	&	3170	&	3800	&	8580	&	5530	&	5760	&	8000	&	6870	&	8660	&	8660	&	348056300	\\
2	&	12	&	42947	&	3490	&	3500	&	8450	&	4670	&	6980	&	3920	&	8110	&	9380	&	9380	&	335484800	\\
2	&	32	&	110277	&	2970	&	5750	&	8440	&	4360	&	7180	&	7370	&	8180	&	8540	&	8540	&	377839900	\\
2	&	21	&	70483	&	3840	&	6330	&	9620	&	6580	&	7980	&	4760	&	7620	&	7320	&	9620	&	388640100	\\
2	&	15	&	53233	&	3490	&	4350	&	9860	&	3880	&	7980	&	9840	&	6380	&	9290	&	9860	&	430891100	\\
2	&	15	&	51277	&	3480	&	5600	&	4350	&	5540	&	8040	&	8670	&	8930	&	9360	&	9360	&	400249500	\\
2	&	24	&	81806	&	3090	&	3720	&	8620	&	7720	&	7060	&	5470	&	7530	&	8270	&	8620	&	362147600	\\
2	&	47	&	162947	&	2440	&	5870	&	9120	&	6200	&	6910	&	8980	&	5780	&	9290	&	9290	&	410125900	\\
2	&	23	&	78397	&	4010	&	9720	&	8670	&	6570	&	5980	&	9620	&	6330	&	9200	&	9720	&	481906000	\\
\hline																				
3	&	27	&	92478	&	2970	&	3250	&	4840	&	5870	&	8180	&	8820	&	6150	&	6590	&	8820	&	303221300	\\
3	&	15	&	52270	&	3550	&	1860	&	9520	&	5260	&	7540	&	5550	&	6850	&	9300	&	9520	&	355426700	\\
3	&	32	&	106824	&	3440	&	6430	&	8180	&	6340	&	4880	&	9110	&	6390	&	8350	&	9110	&	377647600	\\
3	&	17	&	58859	&	3370	&	7400	&	9180	&	9920	&	7350	&	7210	&	9840	&	8260	&	9920	&	519855500	\\
3	&	58	&	198230	&	2690	&	7660	&	4630	&	5700	&	7350	&	7040	&	6920	&	5280	&	7660	&	299187500	\\
3	&	15	&	51037	&	4380	&	3460	&	10180	&	6630	&	10140	&	8220	&	8220	&	10220	&	10220	&	521150100	\\
3	&	47	&	158337	&	4920	&	7700	&	8530	&	7890	&	8010	&	9320	&	6300	&	9290	&	9320	&	495526000	\\
3	&	64	&	215176	&	5230	&	3590	&	8710	&	8610	&	7440	&	6170	&	8430	&	8220	&	8710	&	422293000	\\
3	&	46	&	148523	&	2290	&	8130	&	9050	&	5060	&	8880	&	8820	&	6820	&	9110	&	9110	&	464998400	\\
3	&	13	&	45762	&	3490	&	6010	&	9050	&	5550	&	7570	&	9300	&	7770	&	8320	&	9300	&	434395400	\\
\hline																				
4	&	20	&	68727	&	5910	&	8620	&	8910	&	7460	&	9190	&	9300	&	6290	&	8190	&	9300	&	521858500	\\
4	&	24	&	81663	&	2850	&	4820	&	8570	&	5090	&	5000	&	8700	&	6470	&	8740	&	8740	&	349646400	\\
4	&	26	&	89113	&	3770	&	6500	&	8850	&	5700	&	7370	&	9160	&	9130	&	9260	&	9260	&	474602400	\\
4	&	21	&	70907	&	4240	&	8010	&	8280	&	6020	&	6280	&	8450	&	7060	&	8790	&	8790	&	424885100	\\
4	&	39	&	134642	&	2230	&	5160	&	7800	&	4280	&	4960	&	6430	&	6510	&	7870	&	7870	&	281020400	\\
4	&	12	&	42260	&	3090	&	5500	&	10000	&	8660	&	8020	&	9460	&	6760	&	9790	&	10000	&	510147400	\\
4	&	15	&	51208	&	4120	&	5600	&	9540	&	6960	&	8460	&	6440	&	7310	&	9710	&	9710	&	448553000	\\
4	&	25	&	83637	&	3170	&	7050	&	4150	&	6750	&	5680	&	8690	&	6440	&	8870	&	8870	&	350465400	\\
4	&	23	&	78523	&	5080	&	4670	&	9180	&	8830	&	8590	&	9260	&	7380	&	9370	&	9370	&	511653600	\\
4	&	57	&	199676	&	4320	&	5430	&	8830	&	6720	&	8380	&	7050	&	5790	&	8600	&	8830	&	398685600	\\
\hline																				
5	&	23	&	79392	&	3790	&	2970	&	9260	&	6300	&	6680	&	5960	&	4910	&	8630	&	9260	&	327351600	\\
5	&	52	&	174553	&	3720	&	4630	&	8600	&	8100	&	7210	&	8800	&	6890	&	8270	&	8800	&	420134400	\\
5	&	24	&	81418	&	6570	&	8810	&	9900	&	7520	&	7250	&	9210	&	6520	&	9950	&	9950	&	554240900	\\
5	&	90	&	313038	&	2890	&	5400	&	5310	&	7500	&	5190	&	7700	&	7080	&	7530	&	7700	&	315011600	\\
5	&	23	&	79642	&	2970	&	5980	&	8020	&	6220	&	6920	&	5980	&	6450	&	8390	&	8390	&	343231500	\\
5	&	17	&	60009	&	6260	&	4660	&	6440	&	6880	&	6080	&	8640	&	5160	&	9080	&	9080	&	370399200	\\
5	&	14	&	49088	&	2160	&	9640	&	3220	&	5170	&	4200	&	9310	&	5020	&	8410	&	9640	&	334937100	\\
5	&	22	&	76936	&	5000	&	8460	&	9830	&	8310	&	6880	&	9900	&	7450	&	8870	&	9900	&	541780400	\\
5	&	30	&	104817	&	2730	&	4230	&	9320	&	5550	&	5520	&	5060	&	7830	&	8850	&	9320	&	338716100	\\
5	&	97	&	317085	&	4800	&	3570	&	3580	&	5880	&	5640	&	7890	&	7310	&	8210	&	8210	&	298077600	\\
\hline																				
Avg.	&	30.28	&	103113.84	&	3692.4	&	5679.6	&	7935.4	&	6342.2	&	7101.8	&	7845.8	&	7009.2	&	8665.2	&	8665.2	&	385292464.48	\\
St. Dev.	&	19.55	&	65685.62	&	1039.84	&	1872.68	&	1932.69	&	1344.20	&	1297.90	&	1658.06	&	1070.05	&	881.54	&	1932.69106	&	16486187.26531	\\
\hline																				
\end{tabular}
\end{sidewaystable*}


\section*{Acknowledgment}
Liberatore would like to thanks the GeNeura research group at
University of Granada for their kind hospitality during his visit.

\bibliographystyle{IEEEtran}
\bibliography{GhostsGA}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

%\begin{IEEEbiography}{Michael Shell}
%Biography text here.
%\end{IEEEbiography}

% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

%\begin{IEEEbiographynophoto}{Jane Doe}
%Biography text here.
%\end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}

\end{document}


