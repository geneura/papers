\documentclass[twocolumn]{maeb2015}
\usepackage[latin1]{inputenc}
\usepackage[dvips]{epsfig}
\usepackage{graphicx}        % standard LaTeX graphics tool
\usepackage{subfigure}
\usepackage{url}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


\begin{document}

\title{Aplicación de Técnicas de Inteligencia Computacional a un Sistema de Seguridad Corporativa} %!PN

\author{P. De las Cuevas, A.M. Mora, J.J. Merelo, P.A. Castillo \thanks{Departamento de Arquitectura y Tecnología de Computadores. CITIC, ETSIIT,Universidad de Granada
E-mail: \{paloma,amorag,jmerelo, pedro\}@geneura.ugr.es}}

\maketitle


\begin{abstract}
Este artículo presenta una aplicación, basada en un proyecto europeo en desarrollo, que combina métodos de \textit{Data Mining}, \textit{Machine Learning} e Inteligencia Computacional para crear un sistema de seguridad corporativa centrado en el usuario y auto-adaptativo.
De forma que este sistema, llamado MUSES, será capaz de analizar el comportamiento de los usuarios del mismo (modelado como un conjunto de eventos) al interactuar con el servidor de la empresa para acceder a recursos distribuidos (y protegidos), por ejemplo. Como resultado de dicho análisis y tras la aplicación de las técnicas mencionadas, las \textit{Políticas de Seguridad} de la empresa, o más específicamente las \textit{Reglas de Seguridad} derivadas de las mismas, serán adaptadas para manejar nuevas situaciones anómalas o peligrosas (para la seguridad empresarial), así como para gestionar mejor las acciones de los usuarios.
El trabajo revisa, inicialmente, el estado del arte en esta línea, es decir, la aplicación de este tipo de técnicas a cuestiones de seguridad en la empresa.
Posteriormente, se describen las características de MUSES en este sentido y se compara dicho sistema con los métodos y herramientas existentes.
\end{abstract}

\begin{keywords}
Inteligencia Computacional, Inteligencia Artificial, Computación Evolutiva, Algoritmos Evolutivos, Programación Genética, Seguridad Corporativa, Reglas de Seguridad
\end{keywords}

%-------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------------------------------------------------------------------
\section{Introducción}
\noindent 

La seguridad en sistemas distribuidos ha sido un área de investigación muy explotada desde la aparición de las primeras arquitecturas cliente/servidor \cite{computer_security_80}, siendo la seguridad corporativa una de los temas principales

Sin embargo, el entorno ha cambiado drásticamente en los últimos años, empezando por la distribución de la información, la cual ha pasado de estar centralizada en un servidor de la empresa a encontrarse dispersa en múltiples máquinas, tales como dispositivos portátiles, servidores externos o sistemas de almacenamiento en la nube. A esto se une la llamada filosofía de \textit{BYOD: Bring Your Own Device} (usar tu propio dispositivo), en la que los dispositivos que acceden a los sistemas de la empresa pertenecen a usuarios (empleados de la misma), por lo que contendrán al mismo tiempo información personal y profesional.

Este escenario trae consigo nuevos retos o amenazas de seguridad \cite{Opp_Security11}, que deben ser tratados de forma diferente de lo habitual, considerando al mismo tiempo cuestiones de seguridad y de privacidad de los usuarios. A fin de gestionar esta situación se suelen manejar las \textit{Políticas de Seguridad Corporativa} (PSCs).

En este entorno se está desarrollando (dentro de un proyecto europeo) el sistema MUSES (\textit{Multiplatform Usable Endpoint Security}) \cite{MUSES_SAC_14}, un sistema independiente del dispositivo y centrado en el usuario.
Este sistema considera un conjunto de reglas de seguridad, definidas como especializaciones de las PSCs, y tiene la capacidad de `aprender' del comportamiento pasado de los usuarios y adaptar este conjunto de reglas, incluso generando nuevas, para gestionar de forma efectiva futuros incidentes de seguridad debidos a acciones de los usuarios. De esta forma el sistema reaccionará, de forma no intrusiva, a las secuencias de acciones (eventos) potencialmente peligrosas que éstos estén realizando en cada momento.

Con este fin MUSES analizará el comportamiento de los usuarios por medio de técnicas de \textit{Data Mining} (DM)\cite{DataMining_Lee01} y \textit{Machine Learning} (ML)\cite{MachineLearning_Bishop06}, extrayendo un conjunto de patrones que serán procesados posteriormente por medio de métodos de Inteligencia Computacional (IC), principalmente Algoritmos Evolutivos \cite{EAs_Back96,GAs_Goldberg89,GP_Koza92}.

Esto supone un paso adelante en el estado del arte en dos sentidos: primero, respecto a los sistema de seguridad corporativa existentes para el manejo de situaciones de BYOD, como se describe en nuestro trabajo \cite{MUSES_SAC_14}; segundo, en relación con la aplicación de técnicas de IC a este tipo de problemas de seguridad, para su adaptación al comportamiento de los usuarios, como se describirá en este trabajo.

El artículo se estructura de la siguiente forma: la siguiente sección comenta algunos conceptos interesantes en relación a la seguridad corporativa. La Sección \ref{sec:soa} revisa la bibliografía existente respecto a la aplicación de DM, ML e IC a problemas de seguridad en la empresa, principalmente enfocados en el comportamiento del usuario y la adaptación de los sistemas o las reglas de seguridad, principal característica de MUSES.
Dicho sistema se presenta en la Sección \ref{sec:muses}, haciendo hincapié en las técnicas citadas. 
Finalmente, las ventajas de MUSES respecto a otras utilidades son analizadas en la Sección \ref{sec:conclusion}.


%-----------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% BACKGROUND %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------------------------------------------------
\section{Seguridad en la Empresa}

Hasta hace poco tiempo las empresas solían aplicar \textit{Políticas de Seguridad} (PSs) estáticas, enfocadas a controlar estructuras determinadas \cite{BYOD13} en las que los recursos de información (\textit{Information Assets}) y los dispositivos que los acceden son gestionados por la empresa.
Actualmente las redes corporativas se están transformando en redes dinámicas a fin de adaptarse a la filosofía BYOD, lo que está trayendo nuevos focos de riesgo, como que el dispositivo en cuestión no pertenezca a la empresa y, por tanto, escape a un control estricto por parte de la misma. Esto hace que se requieran políticas de seguridad específicas, más concretamente \textit{Políticas de Seguridad sobre Información} (ISPs en inglés), que puedan gestionar y proteger información determinada de la empresa de posibles brechas de seguridad.

Aunque existen estándares, tales como el ISO27002 o el Estándar de Buenas Prácticas del Foro de Seguridad Internacional\footnote{https://www.securityforum.org}, una ISP se define en función de las características de la organización que se quiere controlar con ella.

Normalmente la arquitectura de la red de seguridad de la empresa se adapta para lidiar con ataques externos \cite{MIT05}, sin embargo, con la aparición del BYOD, la clave está en proteger los recursos que se vean comprometidos debido a vulnerabilidades de los dispositivos de los empleados \cite{android11}, o filtraciones que surjan al ser accedidos desde dispositivos conectados a redes inseguras, por ejemplo.
Además, estos dispositivos, como los extendidos \textit{smartphones} suelen combinar información personal y profesional, así como aplicaciones de ambos tipos, lo que añade un factor de riesgo al estar dichas aplicaciones no corporativas poco controladas.

Por tanto, a la hora de diseñar la arquitectura de la red de una compañía, hay que tener en cuenta todos estos factores.
La Figura \ref{fig:proposed_diagram_esp} muestra una propuesta que puede emplearse como punto de partida para el diseño de soluciones que hagan seguro este entorno dinámico. Ésta incluye el caso de tener dispositivos móviles (\textit{smartphones y tablets}) u ordenadores portátiles propios de algunos empleados, además muestra la oportunidad de que dichos dispositivos se conecten desde dentro o desde fuera de la compañía.
Los recursos de información son accedidos continuamente en estas condiciones, considerando como recurso cualquier trozo de información que tenga un valor asociado (coste, dependiendo del riesgo, de que esa información se pierda o se filtre).
Ejemplos de este tipo de recursos podrían ser documentos con información restringida, determinados e-mails críticos, e incluso aplicaciones internas de la compañía.

\begin{figure}[ht]
	\begin{center}
		\includegraphics[scale=0.36]{proposed_diagram_esp.eps}
		\caption{Muestra de arquitectura de red de una empresa, considerando que ésta ha adoptado la filosofía BYOD.}
	\label{fig:proposed_diagram}
	\end{center}
\end{figure}

Otro aspecto importante a considerar es la elaboración de un buen conjunto de ISPs, que sean comprensibles por los usuarios y, lo más importante, no intrusivas para ellos.
Muchos investigadores han estudiado la tendencia natural de los usuarios a cumplir unas políticas y no otras \cite{SecPolComp07,SecPolComp10,SecPolComp12}, concluyendo que si los empleados respetan las políticas de seguridad habrá un aumento del aprendizaje de técnicas para acceder a la información de forma segura \cite{SecPolComp09}, y que dicho aprendizaje se reducirá si lo que se aplica son castigos o penalizaciones al no respetar las políticas de la empresa \cite{SecPolPenalty09}. 

Esta situación conduce a la necesidad de proteger tanto lado de la organización como el de los usuarios, por medio de ISPs sencillas que no interfieran la actividad de los éstos, incluso dejando que los empleados usen dispositivos propios con propósitos personales mientras trabajan, pero asegurando al mismo tiempo la integridad de los recursos de información en riesgo. La combinación de estos aspectos llevará a la consecución de un sistema de seguridad con las características que pretende ofrecer MUSES (ver Sección \ref{sec:muses}).

%-----------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% STATE OF THE ART %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------------------------------------------------------
\section{Estado del Arte}
\label{sec:soa}

La seguridad en sistemas informáticos es un campo de estudio muy amplio desde principios de los años ochenta \cite{computer_security_80}, con miles de trabajos publicados en muchos temas diferentes en relación a este área.

Uno de los campos más prolíficos es la aplicación de técnicas de Inteligencia Artificial (IA) a diferentes problemas de seguridad informática. Esta línea comenzó hace más de veinte años \cite{ai_intrusion_detection_94} y seguirá abierta por muchos años más \cite{ai_cybersecurity_11}.
Los temas tratados por los investigadores son muy variados, incluyendo enfoques basados en \textit{Data Mining (DM)} \cite{botnet_detection_clustering_09,feature_selection_anomalies_08}, así como \textit{Machine Learning (ML)} \cite{learning_network_intrusion_09,user_classification_ml_13}, aplicados a la resolución de diversos problemas.

La Inteligencia Computacional (IC) también ha sido ampliamente usada en este área, siendo los métodos más prolíficos aquellos basados en Computación Evolutiva (CE), principalmente Algoritmos Genéticos (AGs) y Programación Genética (PG).

Existen diversos trabajos aplicando AGs a la resolución de problemas de seguridad, tales como la detección de intrusos (vea \cite{GA_intrusion_detection_survey_14} para un estado del arte), el diseño y evaluación de protocolos de seguridad  \cite{detecting_intrusion_gp_03,eval_security_gas_07,GAs_security_protocols_10} o la optimización de otros aspectos como los costes de seguridad informática en una empresa \cite{optimizing_IT_costs_ea_10} o el diseño de protocolos criptográficos efectivos \cite{cryptographic_gas_06}, por citar algunos.

Este trabajo se centra en la aplicación de diferentes métodos de DM, ML y AI/CI a un nuevo conjunto de problemas de seguridad, que han emergido como consecuencia de las nuevas interacciones entre sistemas y comportamientos de usuarios que ha traído consigo la filosofía BYOD, como se ha comentado en la sección anterior.
Por tanto, los estudios que nos interesan son aquellos que procesen información relativa al comportamiento de los usuarios en el sistema (en este entorno), y la adaptación de las políticas o reglas de seguridad que puedan hacerse.

Siguiendo esta línea, el trabajo de Greenstadt y Beal \cite{cognitive_security_08} combinaba señales de biometría con métodos de ML con el objetivo de obtener una identificación fiable de un usuario en un sistema informático.
P.G. Kelley et al. \cite{user-controllable_learning_08} presentaron un método llamado \textit{user-controllable policy learning} (aprendizaje de políticas de un usuario controlado) en el que el usuario daba su opinión al sistema cada vez que una política de seguridad era aplicada. De esta forma las políticas eran refinadas o mejoradas en base a dicha opinión, a fin de ser más precisas en lo que respecta a las necesidades de los usuarios del sistema.
Este enfoque podría ser adecuado para un dispositivo personal, pero nuestro objetivo en MUSES es contar con un conjunto global de reglas que sea adaptado a todos los usuarios del sistema.

Por otra parte, las políticas podrían crearse con el objetivo de fomentar la privacidad de los usuarios, como propuso Danezis en  \cite{inferring_policies_socialnetworks_09}. Él definió un sistema capaz de inferir restricciones relacionadas con la privacidad por medio de un algoritmo de ML, que se aplicaba en el entorno de una red social. 
En este caso, la idea de inferir políticas (o reglas) se ha contemplado también en MUSES, pero en el entorno de la compañía y más enfocadas a la creación de ISPs.

Un trabajo más cercano a nuestro sistema es el que presentaron Samak et al. \cite{policy_generation_clustering_10}, en el que los autores usaron un método de \textit{clustering} (agrupamiento) para inferir nuevas políticas de gestión del tráfico en una red de información.
Sin embargo, nuestra idea en MUSES, como se explica en la Sección \ref{sec:muses}, es inferir nuevas Reglas de Seguridad (especialización de las ISPs) por medio de PG.

Otros investigadores, como Lim et al., han aplicado esta metaheurística para evolucionar (mejorar) un conjunto de políticas \cite{sec_policy_evolution_gp_08,pol_evol_gp_3_approaches_08}. Ellos infirieron nuevas políticas basadas en las decisiones tomadas en un sistema, considerando además las opiniones de los usuarios del mismo. MUSES aplicará un procedimiento similar, pero la evaluación de las nuevas políticas se automatizará, al menos en parte. Además, el problema de esas propuestas es que se probaron sobre sistemas `sintécticos', es decir, sistemas simulados o no reales. MUSES se ejecutará en compañías reales con usuarios reales.

Por último, el trabajo de Suarez-Tangil et al. \cite{rule_generation_gp_09}, combina PG con la correlación de eventos, lo cual también aplica en MUSES \cite{MUSES_SAC_14}. Sin embargo, su implementación crea el motor o conjunto de reglas para realizar dicho proceso (la correlación), es decir, las decisiones/acciones a realizar considerando los eventos que se han producido y las ISPs.

La sección siguiente presenta el sistema MUSES de forma breve, así como las técnicas de DM, ML e IC que se aplicarán en el mismo, como mecanismos de adaptación de las ISPs al comportamiento de los usuarios del sistema.


%-------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% MUSES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------------------------------------------------------------
\section{El Sistema MUSES}
\label{sec:muses}

Como se ha indicado anteriormente MUSES es un sistema de seguridad corporativa enfocado a trabajar dentro de la filosofía BYOD, es decir, éste gestionará los accesos de usuarios a los servidores de la empresa desde diversos dispositivos, incluyendo propios, hecho que implica diversos riesgos, incluido el propio comportamiento de los usuarios.

\subsection{Arquitectura del sistema}

Como se puede ver en la Figura \ref{fig:architecture_overview} la arquitectura de MUSES se basa en un enfoque cliente/servidor.
%
\begin{figure*}[htp]
\centering
\epsfig{file=architecture_overview.eps, scale=0.61}
\caption{Arquitectura general de MUSES (componentes de alto nivel). Sigue un esquema con varios clientes (parte derecha), dispositivos de los usuarios, y servidor (parte izquierda), en la que se realizan la mayor parte de las decisiones y el procesamiento. \label{fig:architecture_overview}}
\end{figure*}
%

En ésta, la aplicación \textit{cliente} se instalará en todos los dispositivos de los usuarios, y será independiente de la plataforma de que se trate, así como de su sistema operativo (una de las ventajas de MUSES). El \textit{servidor} por su parte se instalará en el centro de seguridad corporativa de la empresa. Ambas partes se conectarán mediante un canal seguro (usando HTTPS) sobre Internet.
Para una descripción más completa, los lectores pueden dirigirse a la página web del proyecto (\texttt{https://www.musesproject.eu)} o al artículo \cite{MUSES_SAC_14}.



Una de las ventajas más importantes del sistema es la auto-adaptación (tanto al usuario, como al contexto) que será capaz de realizar, modificando y mejorando el sistema de Reglas de Seguridad corporativas.

En este trabajo nos centraremos en la parte del servidor (ver Figura \ref{fig:server_architecture}), ya que es en ésta en la que se aplicarán las técnicas de DM, ML e IC sobre los datos recopilados por el sistema (almacenados en la Base de Datos). En concreto en el componente llamado \textit{MusKRS}, por MUSES \textit{Knowledge Refinement System}. Este módulo se ejecutará de forma asíncrona (varias veces o una vez al día, dependiendo del volumen de datos que se genere en la empresa a este respecto), y será el encargado de analizar toda información generada por en los accesos de los usuarios (eventos, contexto, datos de usuario) a los recursos de información que haya en el servidor, tarea de la que se encargará el \textit{Data Miner}. Una vez analizados estos datos, se procederá a realizar una tarea de adaptación o refinado de reglas de seguridad (por el componente \textit{Knowledge Compiler}) para lidiar mejor con esos eventos, intentando predecir futuras amenazas de seguridad debidas al comportamiento de los usuarios.

De modo que el \textit{Data Miner} aplicará, como su nombre indica, técnicas de DM y ML para identificar y extraer patrones relevantes de los datos. Después el \textit{Knowledge Compiler} realizará una labor de inferencia y refinado/ajuste de reglas, mediante técnicas de IC, considerando los datos extraídos en este primer paso. Si bien, este último modulo también se encargará de realizar refinados más sencillos como especialización o generalización de reglas, aplicando métodos más simples.

%
\begin{figure*}[htp]
\centering
\epsfig{file=server_architecture.eps, scale=0.4}
\caption{Arquitectura del servidor de MUSES (submódulos), en la que destaca el componente llamado \textit{Knowledge Refinement System, MusKRS}, responsable de realizar las tareas de \textit{Data Mining}, \textit{Machine Learning} y la adaptación de las reglas se seguridad que rigen el sistema. \label{fig:server_architecture}}
\end{figure*}
%

Un factor a tener en cuenta es que MUSES tendrá un controlador humano, normalmente el jefe de seguridad de la compañía (\textit{Chief Security Officer ,CSO}), que se encargará de supervisar la actividad del sistema en base a logs e informes generados durante estas tareas.
De forma que todas las reglas refinadas o generadas serán etiquetadas como `potenciales' y deberán ser aprobadas por él/ella antes de ser finalmente añadidas al conjunto que rige al sistema.
Aún así, una de las posibles mejoras a implementar será un mecanismo de aprendizaje que sea capaz de predecir si una nueva regla sería aceptada o no por el CSO (en base a decisiones anteriores), a fin de automatizar este proceso en un futuro(tras un periodo de `entrenamiento').

Las siguientes secciones describen estos procesos: primero los métodos de DM que usará automáticamente el MusKRS, así como para una posible herramienta de análisis y ayuda a la decisión para el CSO; en segundo lugar se comentan las técnicas de IC a aplicar, principalmente centradas en el uso de Algoritmos Evolutivos, dado que estas metaheurísticas se comportan muy bien y han sido ampliamente utilizadas en problemas relacionados con la seguridad en la empresa, como se ha comentado en la Sección \ref{sec:soa}.

% ------------------------------------------------------------------
%
\subsection{Data Mining/Machine Learning}
\label{subsec:dm_ml}

Para esta tarea se considerará el conjunto de datos global en la base de datos y se preprocesará para componer subconjuntos más simples o más adecuados para ser tratados con estas técnicas. Después, se aplicarán métodos de clasificación, clustering, o visualización, entre otros, para extraer patrones que el \textit{Knowledge Compiler} procesará con otros métodos.

This task will be performed by the Data Miner module. It will take the `raw' data from the database and will process the information, in order to yield a set of relevant data for the Knowledge Compiler sub-component or for the human controller. In the first case, this sub-component will take them as a reference in order to refine or adapt the current set of security rules (for instance, to deal with anomalous situations).

The process will be mainly non-supervised, and eventually the datasets can be huge (depending on the company's data flows), so Big Data processing methods \cite{BigData_11} will be applied.

The DM/ML techniques will process the so-called patterns, which in this context correspond to events (and their related information) produced by the users' interactions with the system. The methods to be applied are:

\begin{itemize}

\item \textit{Pattern Mining} \cite{PatternMining_Han07}: 
This process will try to identify frequent or, on the contrary, anomalous patterns, in order to process them lately. The idea is that non-frequent patterns are potentially suspicious, and thus, could be of interest to be checked by the CSO or to serve as a reference for the rule-refinement process.

\item \textit{Classification} \cite{classification_67}: 
This technique tries to train a model (classifier) able to associate every pattern in the dataset to a class, so that the model could be used for assign a class for further incoming patterns with an unknown category.
For instance, it could look for events (patterns) that had been marked as `allowed' or `denied' (according to the ISPs). When a new event arises, if it has not an assigned decision, the classifier should provide one based on the similarity with previous (and already labelled) patterns.

\item \textit{Clustering} \cite{Clustering_Jain99}: 
The aim of this method is grouping the patterns considering some similarity criteria, in order to manage them as a set. This could be used for providing data visualisation mechanisms, in order to make it easier to interpret the data interaction and the distribution in clusters with respect to the different properties/features of the patterns.

\item \textit{Feature Selection} \cite{FeatureSelection_Guyon03}: 
It consists on extract the most important features/variables from the data. This could be useful if we want to discard non-key features, which could be interesting in order to reduce the database weight, for improving the performance of other techniques (such as classification or clustering), and even to improve the performance of whole the system, since less information would be gathered and transmitted.

\item \textit{Data Analysis}: 
This will provide the CSO with mechanisms to visualise interesting facts about the data, such as more frequent events, dangerous or suspicious users (according to their behaviour), more triggered rules, etc.

\end{itemize}

%\pagebreak

% ------------------------------------------------------------------
%
\subsection{Inteligencia computacional: métodos de Computación Evolutiva}
\label{subsec:ci}

%+ Clasificación con GP
%- Inferencia de nuevas reglas con GP
%+ Ajuste de valores de recursos con AGs???

MUSES usará la computación evolutica a través de diferentes aproximaciones, a saber inicialmente, de una manera en la parte de minería de datos (DM) y ML, y mediante otras tres técnicas en la fase de adaptación o refinamiento de reglas. Todas ellas se basan en Programación Genética (PG) \cite{GP_Koza92} y Algoritmos Genéticos (AGs) \cite{GAs_Goldberg89}.

El primer método basado en técnicas evolutivas será la \textit{clasificación por PG}. Esto resulta de gran utilidad por dos razones: primero, para obtener balanceo sobre los datos \cite{imbalance_techniques_02}, ya que el tener un conjunto de datos no balanceado es bastante común en este tipo de aplicaciones con datos reales: y después, para un mejor manejo de datos categóricos (no numéricos), ya que la mayoría de variables o características extraídas de la información que ofrece el sistema son de este tipo.

Por tanto, este método sería capaz de trabajar con conjuntos de datos no balanceados, considerando una función fitness en la cual el coste va asociado al porcentaje de aciertos del clasificador, y aplicando una penalización por cada falso negativo obtenido (puesto que, esto significaría que se ha permitido un evento que es potencialmente peligroso) \cite{cost_adjustment_07}.
En cuanto al tipo de datos, debido a que los algoritmos de PG suelen aplicar modelos basados en reglas o en árboles de decisión, estos se pueden aplicar a variables categóricas, obteniendo un buen clasificador como se obtiene en trabajos como \cite{cost_adjustment_07}.

Centrándonos en el proceso de adaptación o refinamiento de reglas, las técnicas empleadas se aplicarían para inferencia u optimización de un conjunto inicial de reglas, y usarían los siguientes datos:

\begin{itemize}

\item La información extraída por el subcomponente que realiza la minería de datos, en concreto los eventos que resulten anómalos, ya sean patrones no clasificados o mal clasificados. Estos son, aquellos patrones que no se incluyen en ninguna de las clases ya existentes, ya que difieren en gran medida de los patrones que sí se encuentran en ellas, y deberían tenerse en cuenta para ser cubiertos por las reglas de seguridad una vez mejoradas.

\item Información relativa al usuario, correspondiente a esos patrones, o eventos, que son anómalos o que no han podido ser clasificados. Así, su número de identificación, localización (fuera o dentro de las instalaciones de la empresa), o puesto en la empresa, serían ejemplos de lo que el sistema consideraría a la hora de seleccionar un conjunto de reglas a aplicar en esa situación.

\item Información de contexto para patrones que sean parecidos, para restringir, de la misma manera que en el punto anterior, el conjunto de reglas a aplicar.

\end{itemize}

Otros tipos de información que podrían ser útiles durante el proceso de refinamiento o adaptación son los siguientes:

\begin{itemize}

\item Información del riesgo que supone un determinado usuario (en términos de su reputación), como por ejemplo. ``¿Ha recibido el usuario con anterioridad muchas notificaciones de `permiso'/`denegación'?''. Si el usuario tiende a recibir denegaciones a las acciones que suele realizar, se le aplicarán reglas más restrictivas que para un usuario que realice más acciones permitidas.

\item Información que ha sido almacenada en registros del sistema. A partir de ellos se puede saber, por ejemplo, cómo actúa el usuario frente a mensajes del sistema (realizando la acción finalmente o no, o si realiza una crítica positiva o negativa cuando se le pregunta), y podría servir para adaptar las reglas existentes si, en otro ejemplo, hay usuarios que ignoran constantemente mensajes que le indican que no debería realizar una acción peligrosa. Además, podría usarse la información interna del funcionamiento del sistema a lo largo del tiempo para la realización de tests para comprobar si las reglas creadas en el proceso son, o no, útiles.

\end{itemize}

De esta manera, los métodos que se implementarían serían los siguientes:

\begin{itemize}

\item \textit{GP rule inference} method, which will generate/create new rules in order to `cover' those situations non contemplated in the current set of rules. Thus, for instance, a new rule could be created in order to deal with the patterns to which the classifier could not assign a class.
The generation will be done considering the so-called \textit{dictionary}, i.e. a set of terms corresponding to all the possible inputs and actions in the system, which will be antecedents (conditions) and consequents in the security rules to be inferred.
The evaluation of these rules will be done considering the stored log information concerning the parameters along with the actions/decisions made in every component in the system. Thus, it will be possible to `simulate' the whole  system behaviour when the new rule is included and get a value of its performance.

\item \textit{GP rule refinement} approach, which will optimise the current set of rules, adjusting the values in the conditions (antecedents), for instance. Thus, some superfluous parts on the rules and even complete rules could be removed or improved, obtaining for instance specialisations or generalisations of existing rules which could mean a better performance.
The evaluation (of the whole set of security rules) will be done considering the number of unlabelled patterns that will be `covered' after the adjustments.

\item \textit{GA optimisation} algorithm for setting up and adapting the assets' values. These are numerical representations of the importance of the corporate assets, and are considered in the Real-Time Risk and Trust Analysis process, in order to assign a risk value to every potential decision that can be made by the system.
If it is possible to evaluate the partial solutions proposed by the GA, this approach could be very useful for the CSO (who is in charge of assigning and adjusting these values over time).
The adaptation or adjustment concerns the change in value that an asset could have due to a loss of importance, once an event has passed (a project presentation, for instance).

\end{itemize}


%-----------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% CONCLUSIONS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------- 
\section{Comparativa con Otros Sistemas y Conclusiones}
\label{sec:conclusion}

Como se ha podido comprobar, MUSES avanzará bastante en la aplicación de técnicas de minería de datos y Machine Learning para mejorar sistemas de seguridad. Esto quedaba claro en el artículo \cite{MUSES_SAC_14}, en el que puede consultarse una comparativa entre MUSES con otros sistemas similares ya comercializándose, pero de los cuales ninguno tiene la cualidad de adaptación que tiene el sistema que aquí hemos presentado.

Así, este sistema se differencia de los demás en que considera el riesgo que el propio usuario constituye para la seguridad de la empresa, sin ser este el enemigo, mientras que otros sistemas tratan de proteger frente a ataques externos. Además, las técnicas que usa, trabajan sobre datos reales, en un sistema real, por lo que sus resultados contribuyen realmente a evitar incidentes de seguridad reales.

Hemos encontrado que algunos autores sí usan técnicas de minería de datos, pero sus trabajos están enfocados a aplicaciones específicas como la detección de amenazas (botnet) \cite{botnet_detection_clustering_09}, o la detección de anomalías \cite{feature_selection_anomalies_08}. Sin embargo, ninguno las combina en el mismo procedimiento para conseguir mejorar los sistemas, como hace MUSES en su etapa de refinamiento de reglas.

Por otra parte, existen algunos trabajos que proponen la inferencia o refinamiento de reglas \cite{inferring_policies_socialnetworks_09,policy_generation_clustering_10}, pero no afectan al conjunto de políticas de la empresa ni el refinamiento está basado en el comportamiento del usuario, como propone el sistema que presentamos.

Además, la programación genética se usa ampliamente por varios autores \cite{rule_generation_gp_09,sec_policy_evolution_gp_08}, incluso para la creación de nuevas políticas o reglas enfocadas a la seguridad, pero de nuevo éstas no afectan al conjunto de políticas de una empresa. Es más, las funciones de evaluación que aquí se han propuesto, para el refinamiento y la inferencia de reglas, es novedoso y estará completamente integrado en el sistema.

Respecto a los Algoritmos Genéticos, son otro elemento cuyo uso puede encontrarse en muchos trabajos, en su mayoría para la detección de anomalías e intrusos, pero no para la optimización de las reglas como en nuestro caso. Sin embargo, hay algunos trabajos que sí podemos tomar como referencia para nuestro trabajo, como \cite{optimizing_IT_costs_ea_10,risk_reduction_ga_12}.

En cualquier caso, algunos de los trabajos revisados nos sirven como consideración para posibles características a añadir a MUSES, tales como el análisis de usuarios a través de redes sociales \cite{inferring_policies_socialnetworks_09,user_classification_ml_13}, la optimización de protocolos de seguridad \cite{GAs_security_protocols_10}, la implementación de mecanismos de detección de intrusos \cite{GA_intrusion_detection_survey_14} o, aunque MUSES ya lo incorpore, la aplicación de técnicas mejoradas de protección de la privacidad \cite{AAI_book_2009}.

%******************************************************************************

\section*{Agradecimientos}
La realización de este trabajo ha sido respaldado por el proyecto europeo MUSES (FP7-318508), además de por el PYR-2014-17 incluído en GENIL - CEI BIOTIC (Granada).

\nocite{*}
\bibliographystyle{maeb2015}

\begin{thebibliography}{1}

\bibitem{SecPolComp12}
A.~Al-Omari, O.~El-Gayar, A.~Deokar, and J.~Walters.
\newblock Security policy compliance: User acceptance perspective.
\newblock In {\em 45th Hawaii International Conference on System Sciences},
  pages 3317--3326. IEEE Press, 2012.

\bibitem{cost_adjustment_07}
E.~Alfaro-Cid, K.~Sharman, and A.~Esparcia-AlcÃ¡zar.
\newblock A genetic programming approach for bankruptcy prediction using a
  highly unbalanced database.
\newblock In M.~Giacobini, editor, {\em Applications of Evolutionary
  Computing}, volume 4448 of {\em Lecture Notes in Computer Science}, pages
  169--178. Springer Berlin Heidelberg, 2007.

\bibitem{computer_security_80}
A.~J.~P. Anderson.
\newblock Computer security threat monitoring and surveillance.
\newblock Technical report, James P. Anderson Co., Fort Washington, PA, 1980.

\bibitem{BYOD13}
S.~Bacik.
\newblock {\em Information Security Management Handbook}, volume~7, chapter
  Security Implications of Bring Your Own Device, IT Consumerization, and
  Managing User Choices, pages 133--142.
\newblock Sixth edition, 2013.

\bibitem{EAs_Back96}
T.~Back.
\newblock {\em Evolutionary algorithms in theory and practice}.
\newblock Oxford University Press, 1996.

\bibitem{MachineLearning_Bishop06}
C.~Bishop.
\newblock {\em Pattern recognition and Machine Learning}.
\newblock Springer, 2006.

\bibitem{SecPolComp10}
B.~Bulgurcu, H.~Cavusoglu, and I.~Benbasat.
\newblock Information security policy compliance: an empirical study of
  rationality-based beliefs and information security awareness.
\newblock {\em MIS Quarterly}, 34(3):523--548, 2010.

\bibitem{botnet_detection_clustering_09}
S.~Chang and T.~E. Daniels.
\newblock P2p botnet detection using behavior clustering \& statistical tests.
\newblock In {\em Proceedings of the 2nd ACM Workshop on Security and
  Artificial Intelligence}, AISec '09, pages 23--30, New York, NY, USA, 2009.
  ACM.

\bibitem{inferring_policies_socialnetworks_09}
G.~Danezis.
\newblock Inferring privacy policies for social networking services.
\newblock In {\em Proceedings of the 2Nd ACM Workshop on Security and
  Artificial Intelligence}, AISec '09, pages 5--10, New York, NY, USA, 2009.
  ACM.

\bibitem{ai_intrusion_detection_94}
J.~Frank and N.~U. Mda-c.
\newblock Artificial intelligence and intrusion detection: Current and future
  directions.
\newblock In {\em In Proceedings of the 17th National Computer Security
  Conference}, 1994.

\bibitem{GAs_Goldberg89}
D.~E. Goldberg.
\newblock {\em Genetic Algorithms in search, optimization and machine
  learning}.
\newblock Addison Wesley, 1989.

\bibitem{learning_network_intrusion_09}
N.~G\"{o}rnitz, M.~Kloft, K.~Rieck, and U.~Brefeld.
\newblock Active learning for network intrusion detection.
\newblock In {\em Proceedings of the 2Nd ACM Workshop on Security and
  Artificial Intelligence}, AISec '09, pages 47--54, New York, NY, USA, 2009.
  ACM.

\bibitem{GA_intrusion_detection_survey_14}
P.~Gowher~Majeed and S.~Kumar.
\newblock Genetic algorithms in intrusion detection systems: A survey.
\newblock {\em International Journal of Innovation and Applied Studies},
  5(3):233--240, March 2014.

\bibitem{cognitive_security_08}
R.~Greenstadt and J.~Beal.
\newblock Cognitive security for personal devices.
\newblock In {\em Proceedings of the 1st ACM Workshop on Workshop on AISec},
  AISec '08, pages 27--30, New York, NY, USA, 2008. ACM.

\bibitem{FeatureSelection_Guyon03}
I.~Guyon and A.~Elisseeff.
\newblock An introduction to variable and feature selection.
\newblock {\em J. Mach. Learn. Res.}, 3:1157--1182, 2003.

\bibitem{PatternMining_Han07}
J.~Han, H.~Cheng, D.~Xin, and X.~Yan.
\newblock Frequent pattern mining: Current status and future directions.
\newblock {\em Data Min. Knowl. Discov.}, 15(1):55--86, 2007.

\bibitem{SecPolPenalty09}
T.~Herath and H.~Rao.
\newblock Protection motivation and deterrence: a framework for security policy
  compliance in organisations.
\newblock {\em European Journal of Information Systems}, 18:106--125, 2009.

\bibitem{Clustering_Jain99}
A.~K. Jain, M.~N. Murty, and P.~J. Flynn.
\newblock Data clustering: A review.
\newblock {\em ACM Comput. Surv.}, 31(3):264--323, Sept. 1999.

\bibitem{imbalance_techniques_02}
N.~Japkowicz and S.~Stephen.
\newblock The class imbalance problem: A systematic study.
\newblock {\em Intell. Data Anal.}, 6(5):429--449, Oct. 2002.

\bibitem{user-controllable_learning_08}
P.~G. Kelley, P.~Hankes~Drielsma, N.~Sadeh, and L.~F. Cranor.
\newblock User-controllable learning of security and privacy policies.
\newblock In {\em Proceedings of the 1st ACM Workshop on Workshop on AISec},
  AISec '08, pages 11--18, New York, NY, USA, 2008. ACM.

\bibitem{optimizing_IT_costs_ea_10}
T.~Kirta and J.~Kivimaab.
\newblock Optimizing it security costs by evolutionary algorithms.
\newblock In C.~Czosseck and K.~Podins, editors, {\em Conference on Cyber
  Conflict}, pages 145--160, Tallinn, Estonia, 2010. CCD COE Publications.

\bibitem{feature_selection_anomalies_08}
M.~Kloft, U.~Brefeld, P.~D\"{u}essel, C.~Gehl, and P.~Laskov.
\newblock Automatic feature selection for anomaly detection.
\newblock In {\em Proceedings of the 1st ACM Workshop on Workshop on AISec},
  AISec '08, pages 71--76, New York, NY, USA, 2008. ACM.

\bibitem{GP_Koza92}
J.~R. Koza.
\newblock {\em Genetic Programming: On the programming of computers by means of
  natural selection}.
\newblock MIT Press, Cambridge, MA, 1992.

\bibitem{DataMining_Lee01}
S.~J. Lee and K.~Siau.
\newblock A review of data mining techniques.
\newblock {\em Industrial Management \& Data Systems}, 101(1):41--46, 2001.

\bibitem{user_classification_ml_13}
A.~Leontjeva, M.~Goldszmidt, Y.~Xie, F.~Yu, and M.~Abadi.
\newblock Early security classification of skype users via machine learning.
\newblock In {\em Proceedings of the 2013 ACM Workshop on Artificial
  Intelligence and Security}, AISec '13, pages 35--44, New York, NY, USA, 2013.
  ACM.

\bibitem{pol_evol_gp_3_approaches_08}
Y.~T. Lim, P.~C. Cheng, J.~Clark, and P.~Rohatgi.
\newblock Policy evolution with genetic programming: A comparison of three
  approaches.
\newblock In {\em Evolutionary Computation, 2008. CEC 2008. (IEEE World
  Congress on Computational Intelligence). IEEE Congress on}, pages 1792--1800,
  June 2008.

\bibitem{sec_policy_evolution_gp_08}
Y.~T. Lim, P.~C. Cheng, P.~Rohatgi, and J.~A. Clark.
\newblock Mls security policy evolution with genetic programming.
\newblock In {\em Proceedings of the 10th Annual Conference on Genetic and
  Evolutionary Computation}, GECCO '08, pages 1571--1578, New York, NY, USA,
  2008. ACM.

\bibitem{MIT05}
R.~Lippmann, K.~Ingols, C.~Scott, K.~Piwowarski, K.~Kratkiewicz, M.~Artz, and
  R.~Cunningham.
\newblock Evaluating and strengthening enterprise network security using attack
  graphs.
\newblock Project report ia-2, Massachusetts Institute of Technology, Lincoln
  Laboratory, October 2005.

\bibitem{detecting_intrusion_gp_03}
W.~Lu and L.~Traore.
\newblock Detecting new forms of network intrusion using genetic programming.
\newblock In {\em Proceedings of the 2003 Congress on Evolutionary
  Computation}, pages 2165--2172, 2003.

\bibitem{classification_67}
J.~MacQueen et~al.
\newblock Some methods for classification and analysis of multivariate
  observations.
\newblock In {\em Proceedings of the fifth Berkeley symposium on mathematical
  statistics and probability}, volume~1, page~14. California, USA, 1967.

\bibitem{MUSES_SAC_14}
A.~Mora, P.~De~las Cuevas, J.~Merelo, S.~Zamarripa, M.~Juan,
  A.~Esparcia-Alcázar, M.~Burvall, H.~Arfwedson, and Z.~Hodaie.
\newblock {MUSES: A corporate user-centric system which applies computational
  intelligence methods}.
\newblock In D.~S. et~al., editor, {\em 29th Symposium On Applied Computing},
  pages 1719--1723, 2014.

\bibitem{ai_cybersecurity_11}
B.~Morel.
\newblock Artificial intelligence and the future of cybersecurity.
\newblock In Y.~Chen, A.~A. Cárdenas, R.~Greenstadt, and B.~I.~P. Rubinstein,
  editors, {\em AISec}, pages 93--98. ACM, 2011.

\bibitem{Opp_Security11}
R.~Oppliger.
\newblock Security and privacy in an online world.
\newblock {\em IEEE Computer}, 44(9):21--22, September 2011.

\bibitem{android11}
C.~Orthacker, P.~Teufl, S.~Kraxberger, G.~Lackner, M.~Gissing, A.~Marsalek,
  J.~Leibetseder, and O.~Prevenhueber.
\newblock Android security permissions - can we trust them?
\newblock In {\em MobiSec Session on Smartphone Security}, Aalborg, 2011.

\bibitem{BigData_11}
B.~Ratner.
\newblock {\em Statistical and Machine-Learning Data Mining: Techniques for
  Better Predictive Modeling and Analysis of Big Data, Second Edition}.
\newblock CRC Press, Inc., Boca Raton, FL, USA, 2nd edition, 2011.

\bibitem{policy_generation_clustering_10}
T.~Samak and E.~Al-Shaer.
\newblock Synthetic security policy generation via network traffic clustering.
\newblock In {\em Proceedings of the 3rd ACM Workshop on Artificial
  Intelligence and Security}, AISec '10, pages 45--53, New York, NY, USA, 2010.
  ACM.

\bibitem{SecPolComp09}
R.~Shaw, C.~Chen, A.~Harris, and H.-J. Huang.
\newblock The impact of information richness on information security awareness
  training effectiveness.
\newblock {\em Computers \& Education}, 52:92--100, 2009.

\bibitem{SecPolComp07}
M.~Siponen, S.~Pahnila, and A.~Mahmood.
\newblock {\em {New Approaches for Security, Privacy and Trust in Complex
  Environments}}, volume 232, chapter {Employees' adherence to information
  security policies: an empirical study}, pages 133--144.
\newblock IFIP International Federation for Information Processing, 2007.

\bibitem{AAI_book_2009}
A.~Solanas and A.~Martínez-bal.
\newblock {\em Advances in Artificial Intelligence for Privacy Protection and
  Security}.
\newblock World Scientific Publishing Co., Inc., River Edge, NJ, USA, 2009.

\bibitem{rule_generation_gp_09}
G.~Suarez-Tangil, E.~Palomar, J.~Fuentes, J.~Blasco, and A.~Ribagorda.
\newblock Automatic rule generation based on genetic programming for event
  correlation.
\newblock In l.~Herrero, P.~Gastaldo, R.~Zunino, and E.~Corchado, editors, {\em
  Computational Intelligence in Security for Information Systems}, volume~63 of
  {\em Advances in Intelligent and Soft Computing}, pages 127--134. Springer
  Berlin Heidelberg, 2009.

\bibitem{risk_reduction_ga_12}
A.~Tamjidyamcholo.
\newblock Genetic algorithm approach for risk reduction of information
  security.
\newblock {\em International Journal of Cyber-Security and Digital Forensics
  (IJCSDF)}, 1(1), 2012.

\bibitem{GAs_security_protocols_10}
L.~Zarza, J.~Forné~Muñoz, J.~R. Pegueroles~Vallés, and M.~Soriano~Ibáñez.
\newblock {\em Advances in artificial intelligence for privacy protection and
  security}, chapter Genetic algorithms for designing network security
  protocols, pages 325--358.
\newblock World Scientific, 2010.

\bibitem{eval_security_gas_07}
L.~Zarza, J.~Pegueroles, and M.~Soriano.
\newblock Evaluation function for synthesizing security protocols by means of
  genetic algorithms.
\newblock In {\em Proceedings of the The Second International Conference on
  Availability, Reliability and Security}, ARES '07, pages 1207--1213,
  Washington, DC, USA, 2007. IEEE Computer Society.

\bibitem{cryptographic_gas_06}
L.~Zarza, J.~Pegueroles, M.~Soriano, and R.~Martínez.
\newblock Design of cryptographic protocols by means of genetic algorithms
  techniques.
\newblock In M.~Malek, E.~Fernández-Medina, and J.~Hernando, editors, {\em
  SECRYPT}, pages 316--319. INSTICC Press, 2006.

\end{thebibliography}
\end{document}
