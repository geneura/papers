\documentclass[twocolumn]{maeb2015}
\usepackage[latin1]{inputenc}
\usepackage[dvips]{epsfig}
\usepackage{graphicx}        % standard LaTeX graphics tool
\usepackage{subfigure}
\usepackage{url}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


\begin{document}

\title{Aplicación de Técnicas de Inteligencia Computacional a Sistemas de Seguridad Corporativa. \\El caso del proyecto MUSES} %!PN

\author{P. De las Cuevas, A.M. Mora, J.J. Merelo, P.A. Castillo \thanks{Departamento de Arquitectura y Tecnología de Computadores. CITIC, ETSIIT,Universidad de Granada
E-mail: \{paloma,amorag,jmerelo, pedro\}@geneura.ugr.es}}

\maketitle


\begin{abstract}
Este artículo presenta una aplicación, basada en un proyecto europeo en desarrollo, que combina métodos de \textit{Data Mining}, \textit{Machine Learning} e Inteligencia Computacional para crear un sistema de seguridad corporativa centrado en el usuario y auto-adaptativo.
De forma que este sistema, llamado MUSES, será capaz de analizar el comportamiento de los usuarios del mismo (modelado como un conjunto de eventos) al interactuar con el servidor de la empresa para acceder a recursos distribuidos (y protegidos), por ejemplo. Como resultado de dicho análisis y tras la aplicación de las técnicas mencionadas, las \textit{Políticas de Seguridad} de la empresa, o más específicamente las \textit{Reglas de Seguridad} derivadas de las mismas, serán adaptadas para manejar nuevas situaciones anómalas o peligrosas (para la seguridad empresarial), así como para gestionar mejor las acciones de los usuarios.
El trabajo revisa, inicialmente, el estado del arte en esta línea, es decir, la aplicación de este tipo de técnicas a cuestiones de seguridad en la empresa.
Posteriormente, se describen las características de MUSES en este sentido y se compara dicho sistema con los métodos y herramientas existentes.
\end{abstract}

\begin{keywords}
Inteligencia Computacional, Inteligencia Artificial, Computación Evolutiva, Algoritmos Evolutivos, Programación Genética, Seguridad Corporativa, Reglas de Seguridad
\end{keywords}

%-------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------------------------------------------------------------------
\section{Introducción}
\noindent 

La seguridad en sistemas distribuidos ha sido un área de investigación muy explotada desde la aparición de las primeras arquitecturas cliente/servidor \cite{computer_security_80}, siendo la seguridad corporativa una de los temas principales

Sin embargo, el entorno ha cambiado drásticamente en los últimos años, empezando por la distribución de la información, la cual ha pasado de estar centralizada en un servidor de la empresa a encontrarse dispersa en múltiples máquinas, tales como dispositivos portátiles, servidores externos o sistemas de almacenamiento en la nube. A esto se une la llamada filosofía de \textit{BYOD: Bring Your Own Device} (usar tu propio dispositivo), en la que los dispositivos que acceden a los sistemas de la empresa pertenecen a usuarios (empleados de la misma), por lo que contendrán al mismo tiempo información personal y profesional.

Este escenario trae consigo nuevos retos o amenazas de seguridad \cite{Opp_Security11}, que deben ser tratados de forma diferente de lo habitual, considerando al mismo tiempo cuestiones de seguridad y de privacidad de los usuarios. A fin de gestionar esta situación se suelen manejar las \textit{Políticas de Seguridad Corporativa} (PSCs).

En este entorno se está desarrollando (dentro de un proyecto europeo) el sistema MUSES (\textit{Multiplatform Usable Endpoint Security}) \cite{MUSES_SAC_14}, un sistema independiente del dispositivo y centrado en el usuario.
Este sistema considera un conjunto de reglas de seguridad, definidas como especializaciones de las PSCs, y tiene la capacidad de `aprender' del comportamiento pasado de los usuarios y adaptar este conjunto de reglas, incluso generando nuevas, para gestionar de forma efectiva futuros incidentes de seguridad debidos a acciones de los usuarios. De esta forma el sistema reaccionará, de forma no intrusiva, a las secuencias de acciones (eventos) potencialmente peligrosas que éstos estén realizando en cada momento.

Con este fin MUSES analizará el comportamiento de los usuarios por medio de técnicas de \textit{Data Mining} (DM)\cite{DataMining_Lee01} y \textit{Machine Learning} (ML)\cite{MachineLearning_Bishop06}, extrayendo un conjunto de patrones que serán procesados posteriormente por medio de métodos de Inteligencia Computacional (IC), principalmente Algoritmos Evolutivos \cite{EAs_Back96,GAs_Goldberg89,GP_Koza92}.

Esto supone un paso adelante en el estado del arte en dos sentidos: primero, respecto a los sistema de seguridad corporativa existentes para el manejo de situaciones de BYOD, como se describe en nuestro trabajo \cite{MUSES_SAC_14}; segundo, en relación con la aplicación de técnicas de IC a este tipo de problemas de seguridad, para su adaptación al comportamiento de los usuarios, como se describirá en este trabajo.

El artículo se estructura de la siguiente forma: la siguiente sección comenta algunos conceptos interesantes en relación a la seguridad corporativa. La Sección \ref{sec:soa} revisa la bibliografía existente respecto a la aplicación de DM, ML e IC a problemas de seguridad en la empresa, principalmente enfocados en el comportamiento del usuario y la adaptación de los sistemas o las reglas de seguridad, principal característica de MUSES.
Dicho sistema se presenta en la Sección \ref{sec:muses}, haciendo hincapié en las técnicas citadas. 
Finalmente, las ventajas de MUSES respecto a otras utilidades son analizadas en la Sección \ref{sec:conclusion}.


%-----------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% BACKGROUND %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------------------------------------------------
\section{Seguridad en la Empresa}

Hasta hace poco tiempo las empresas solían aplicar \textit{Políticas de Seguridad} (PSs) estáticas, enfocadas a controlar estructuras determinadas \cite{BYOD13} en las que los recursos de información (\textit{Information Assets}) y los dispositivos que los acceden son gestionados por la empresa.
Actualmente las redes corporativas se están transformando en redes dinámicas a fin de adaptarse a la filosofía BYOD, lo que está trayendo nuevos focos de riesgo, como que el dispositivo en cuestión no pertenezca a la empresa y, por tanto, escape a un control estricto por parte de la misma. Esto hace que se requieran políticas de seguridad específicas, más concretamente \textit{Políticas de Seguridad sobre Información} (ISPs en inglés), que puedan gestionar y proteger información determinada de la empresa de posibles brechas de seguridad.

Aunque existen estándares, tales como el ISO27002 o el Estándar de Buenas Prácticas del Foro de Seguridad Internacional\footnote{https://www.securityforum.org}, una ISP se define en función de las características de la organización que se quiere controlar con ella.

Normalmente la arquitectura de la red de seguridad de la empresa se adapta para lidiar con ataques externos \cite{MIT05}, sin embargo, con la aparición del BYOD, la clave está en proteger los recursos que se vean comprometidos debido a vulnerabilidades de los dispositivos de los empleados \cite{android11}, o filtraciones que surjan al ser accedidos desde dispositivos conectados a redes inseguras, por ejemplo.
Además, estos dispositivos, como los extendidos \textit{smartphones} suelen combinar información personal y profesional, así como aplicaciones de ambos tipos, lo que añade un factor de riesgo al estar dichas aplicaciones no corporativas poco controladas.

Por tanto, a la hora de diseñar la arquitectura de la red de una compañía, hay que tener en cuenta todos estos factores.
La Figura \ref{fig:proposed_diagram_esp} muestra una propuesta que puede emplearse como punto de partida para el diseño de soluciones que hagan seguro este entorno dinámico. Ésta incluye el caso de tener dispositivos móviles (\textit{smartphones y tablets}) u ordenadores portátiles propios de algunos empleados, además muestra la oportunidad de que dichos dispositivos se conecten desde dentro o desde fuera de la compañía.
Los recursos de información son accedidos continuamente en estas condiciones, considerando como recurso cualquier trozo de información que tenga un valor asociado (coste, dependiendo del riesgo, de que esa información se pierda o se filtre).
Ejemplos de este tipo de recursos podrían ser documentos con información restringida, determinados e-mails críticos, e incluso aplicaciones internas de la compañía.

\begin{figure}[ht]
	\begin{center}
		\includegraphics[scale=0.36]{proposed_diagram_esp.eps}
		\caption{Muestra de arquitectura de red de una empresa, considerando que ésta ha adoptado la filosofía BYOD.}
	\label{fig:proposed_diagram}
	\end{center}
\end{figure}

Otro aspecto importante a considerar es la elaboración de un buen conjunto de ISPs, que sean comprensibles por los usuarios y, lo más importante, no intrusivas para ellos.
Muchos investigadores han estudiado la tendencia natural de los usuarios a cumplir unas políticas y no otras \cite{SecPolComp07,SecPolComp10,SecPolComp12}, concluyendo que si los empleados respetan las políticas de seguridad habrá un aumento del aprendizaje de técnicas para acceder a la información de forma segura \cite{SecPolComp09}, y que dicho aprendizaje se reducirá si lo que se aplica son castigos o penalizaciones al no respetar las políticas de la empresa \cite{SecPolPenalty09}. 

Esta situación conduce a la necesidad de proteger tanto lado de la organización como el de los usuarios, por medio de ISPs sencillas que no interfieran la actividad de los éstos, incluso dejando que los empleados usen dispositivos propios con propósitos personales mientras trabajan, pero asegurando al mismo tiempo la integridad de los recursos de información en riesgo. La combinación de estos aspectos llevará a la consecución de un sistema de seguridad con las características que pretende ofrecer MUSES (ver Sección \ref{sec:muses}).

%-----------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% STATE OF THE ART %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------------------------------------------------------
\section{Estado del Arte}
\label{sec:soa}

La seguridad en sistemas informáticos es un campo de estudio muy amplio desde principios de los años ochenta \cite{computer_security_80}, con miles de trabajos publicados en muchos temas diferentes en relación a este área.

Uno de los campos más prolíficos es la aplicación de técnicas de Inteligencia Artificial (IA) a diferentes problemas de seguridad informática. Esta línea comenzó hace más de veinte años \cite{ai_intrusion_detection_94} y seguirá abierta por muchos años más \cite{ai_cybersecurity_11}.
Los temas tratados por los investigadores son muy variados, incluyendo enfoques basados en \textit{Data Mining (DM)} \cite{botnet_detection_clustering_09,feature_selection_anomalies_08}, así como \textit{Machine Learning (ML)} \cite{learning_network_intrusion_09,user_classification_ml_13}, aplicados a la resolución de diversos problemas.

La Inteligencia Computacional (IC) también ha sido ampliamente usada en este área, siendo los métodos más prolíficos aquellos basados en Computación Evolutiva (CE), principalmente Algoritmos Genéticos (AGs) y Programación Genética (PG).

Existen diversos trabajos aplicando AGs a la resolución de problemas de seguridad, tales como la detección de intrusos (vea \cite{GA_intrusion_detection_survey_14} para un estado del arte), el diseño y evaluación de protocolos de seguridad  \cite{detecting_intrusion_gp_03,eval_security_gas_07,GAs_security_protocols_10} o la optimización de otros aspectos como los costes de seguridad informática en una empresa \cite{optimizing_IT_costs_ea_10} o el diseño de protocolos criptográficos efectivos \cite{cryptographic_gas_06}, por citar algunos.

Este trabajo se centra en la aplicación de diferentes métodos de DM, ML y AI/CI a un nuevo conjunto de problemas de seguridad, que han emergido como consecuencia de las nuevas interacciones entre sistemas y comportamientos de usuarios que ha traído consigo la filosofía BYOD, como se ha comentado en la sección anterior.
Por tanto, los estudios que nos interesan son aquellos que procesen información relativa al comportamiento de los usuarios en el sistema (en este entorno), y la adaptación de las políticas o reglas de seguridad que puedan hacerse.

Siguiendo esta línea, el trabajo de Greenstadt y Beal \cite{cognitive_security_08} combinaba señales de biometría con métodos de ML con el objetivo de obtener una identificación fiable de un usuario en un sistema informático.
P.G. Kelley et al. \cite{user-controllable_learning_08} presentaron un método llamado \textit{user-controllable policy learning} (aprendizaje de políticas de un usuario controlado) en el que el usuario daba su opinión al sistema cada vez que una política de seguridad era aplicada. De esta forma las políticas eran refinadas o mejoradas en base a dicha opinión, a fin de ser más precisas en lo que respecta a las necesidades de los usuarios del sistema.
Este enfoque podría ser adecuado para un dispositivo personal, pero nuestro objetivo en MUSES es contar con un conjunto global de reglas que sea adaptado a todos los usuarios del sistema.

Por otra parte, las políticas podrían crearse con el objetivo de fomentar la privacidad de los usuarios, como propuso Danezis en  \cite{inferring_policies_socialnetworks_09}. Él definió un sistema capaz de inferir restricciones relacionadas con la privacidad por medio de un algoritmo de ML, que se aplicaba en el entorno de una red social. 
En este caso, la idea de inferir políticas (o reglas) se ha contemplado también en MUSES, pero en el entorno de la compañía y más enfocadas a la creación de ISPs.

Un trabajo más cercano a nuestro sistema es el que presentaron Samak et al. \cite{policy_generation_clustering_10}, en el que los autores usaron un método de \textit{clustering} (agrupamiento) para inferir nuevas políticas de gestión del tráfico en una red de información.
Sin embargo, nuestra idea en MUSES, como se explica en la Sección \ref{sec:muses}, es inferir nuevas Reglas de Seguridad (especialización de las ISPs) por medio de PG.

Otros investigadores, como Lim et al., han aplicado esta metaheurística para evolucionar (mejorar) un conjunto de políticas \cite{sec_policy_evolution_gp_08,pol_evol_gp_3_approaches_08}. Ellos infirieron nuevas políticas basadas en las decisiones tomadas en un sistema, considerando además las opiniones de los usuarios del mismo. MUSES aplicará un procedimiento similar, pero la evaluación de las nuevas políticas se automatizará, al menos en parte. Además, el problema de esas propuestas es que se probaron sobre sistemas `sintécticos', es decir, sistemas simulados o no reales. MUSES se ejecutará en compañías reales con usuarios reales.

Por último, el trabajo de Suarez-Tangil et al. \cite{rule_generation_gp_09}, combina PG con la correlación de eventos, lo cual también aplica en MUSES \cite{MUSES_SAC_14}. Sin embargo, su implementación crea el motor o conjunto de reglas para realizar dicho proceso (la correlación), es decir, las decisiones/acciones a realizar considerando los eventos que se han producido y las ISPs.

La sección siguiente presenta el sistema MUSES de forma breve, así como las técnicas de DM, ML e IC que se aplicarán en el mismo, como mecanismos de adaptación de las ISPs al comportamiento de los usuarios del sistema.


%-------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% MUSES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------------------------------------------------------------
\section{El Sistema MUSES}
\label{sec:muses}

As previously stated, MUSES will be a whole corporate security system aimed to deal with the new BYOD philosophy, i.e. it will manage user's accesses to the company servers from diverse own devices, which could be dangerous for several reasons, including the user's behaviour.

The defined MUSES architecture is shown in Figure \ref{fig:architecture_overview}.
%
\begin{figure*}[htp]
\centering
\epsfig{file=architecture_overview.eps, scale=0.61}
\caption{MUSES Architecture Overview (high-level components)\label{fig:architecture_overview}}
\end{figure*}
%
It is a \textit{client/server} approach in which the \textit{client} program will be installed in every user's mobile or portable device, independently of the platform (operating system and type of device). The \textit{server} side would be installed in the corporate security operations centre. Both sides are connected through a secure channel (using HTTPS) over Internet.

One of the main features of this system will be the self-adaptation (to the user and context) of the set of Corporate Security Rules (specification of the ISPs). 
To this end, there is a component in the designed architecture (Figure \ref{fig:architecture_overview}, left side) named \textit{MusKRS}, from MUSES \textit{Knowledge Refinement System}. This will be run asynchronously in the server and will be in charge of analysing all the gathered information (events, context, user-related data), and adapting/refining the security rules to better deal with these events, also trying to predict future threats due to the user's behaviour.

This process will be composed by two steps: first, a Data Mining/Machine Learning procedure will be performed (in the \textit{Data Miner} sub-component);  second, a refinement and inference process will be done (in the \textit{Knowledge Compiler} sub-component), considering the data `extracted' in the first step, by means of Computational Intelligence techniques.
It should be noticed that part of the refinement (or adaptation) of the security rules will be made using simpler methods, such as generalisation or specialisation of rules, for instance. Then, other parts of the process would be conducted using CI.

Another important fact is that MUSES will count with a human controller, normally the company Chief Security Officer (CSO), who will supervise the system activity by means of logs. Thus, adapted and inferred security rules will not be directly added to the current set of rules. Instead, they are proposed to this controller in order that he/she accepts them if they are interesting and correct. It is planned that the system will be able to `learn' from this decisions so, after a so-called training or `warm up' period, the rules would be directly accepted or rejected autonomously.

The following sections describe these processes: first focusing on DM techniques to be used both automatically by the KRS, and as a kind of decision-aid/monitoring tool for the CSO; second, the CI techniques are explained, mainly focusing in Evolutionary Computation approaches, since these methods perform very well, and have been widely used in security-based environments, as has been presented in Section \ref{sec:stateofart}.

% ------------------------------------------------------------------
%
\subsection{Data Mining/Machine Learning}
\label{subsec:dm_ml}

This task will be performed by the Data Miner module. It will take the `raw' data from the database and will process the information, in order to yield a set of relevant data for the Knowledge Compiler sub-component or for the human controller. In the first case, this sub-component will take them as a reference in order to refine or adapt the current set of security rules (for instance, to deal with anomalous situations).

The process will be mainly non-supervised, and eventually the datasets can be huge (depending on the company's data flows), so Big Data processing methods \cite{BigData_11} will be applied.

The DM/ML techniques will process the so-called patterns, which in this context correspond to events (and their related information) produced by the users' interactions with the system. The methods to be applied are:

\begin{itemize}

\item \textit{Pattern Mining} \cite{PatternMining_Han07}: 
This process will try to identify frequent or, on the contrary, anomalous patterns, in order to process them lately. The idea is that non-frequent patterns are potentially suspicious, and thus, could be of interest to be checked by the CSO or to serve as a reference for the rule-refinement process.

\item \textit{Classification} \cite{classification_67}: 
This technique tries to train a model (classifier) able to associate every pattern in the dataset to a class, so that the model could be used for assign a class for further incoming patterns with an unknown category.
For instance, it could look for events (patterns) that had been marked as `allowed' or `denied' (according to the ISPs). When a new event arises, if it has not an assigned decision, the classifier should provide one based on the similarity with previous (and already labelled) patterns.

\item \textit{Clustering} \cite{Clustering_Jain99}: 
The aim of this method is grouping the patterns considering some similarity criteria, in order to manage them as a set. This could be used for providing data visualisation mechanisms, in order to make it easier to interpret the data interaction and the distribution in clusters with respect to the different properties/features of the patterns.

\item \textit{Feature Selection} \cite{FeatureSelection_Guyon03}: 
It consists on extract the most important features/variables from the data. This could be useful if we want to discard non-key features, which could be interesting in order to reduce the database weight, for improving the performance of other techniques (such as classification or clustering), and even to improve the performance of whole the system, since less information would be gathered and transmitted.

\item \textit{Data Analysis}: 
This will provide the CSO with mechanisms to visualise interesting facts about the data, such as more frequent events, dangerous or suspicious users (according to their behaviour), more triggered rules, etc.

\end{itemize}

%\pagebreak

% ------------------------------------------------------------------
%
\subsection{Computational Intelligence: Evolutionary Computation Methods}
\label{subsec:ci}

%+ Clasificación con GP
%- Inferencia de nuevas reglas con GP
%+ Ajuste de valores de recursos con AGs???

MUSES will use different EC approaches, initially, one in the DM/ML part of the process, and three in the rule-refinement/adaptation phase. They are based in GPs \cite{GP_Koza92}, and GAs \cite{GAs_Goldberg89}.

The first evolutionary-based approach will be a \textit{GP classification} method. This will be useful for two main reasons: first, in order to deal with the data class imbalance \cite{imbalance_techniques_02}, very common in classification problems inside real systems (with real data); and second, to better manage categorical (non-numeric) data, since most of the features/variables and information gathered from the events take these kind of values.

Thus, this approach will be able to manage unbalanced datasets considering a fitness function in which a cost can be associated to the classifier accuracy at every epoch, having a penalty cost when the classifier makes a false negative (an element from the minority class which is classified as belonging to the majority class) \cite{cost_adjustment_07}.
Regarding the type of data, since GP algorithms can manage rule- or tree-based models, it will work perfectly with any categorical variable, yielding a good classifier as it has been made in other works (such as the aforementioned \cite{cost_adjustment_07}).

The second set of EC approaches are, as stated, part of the rule-refinement (or adaptation) process. These techniques will be used for inference and optimisation, and will consider this data as a part of the process:

\begin{itemize}

\item The information extracted from the Data Miner sub-component, mainly concerning the anomalous, unclassified or misclassified patterns. These are those patterns which did not match with any of the existing classes (they are quite different from the patterns belonging to those classes), so they cannot be included in any of the classes and thus they should be taken into account for a potential inference or update in the set of security rules, in order to `cover' them.

\item User-related information corresponding to those anomalous or unlabelled patterns (events). Thus, the user's ID, location and role, for instance, will be considered in order to select the applicable set of rules for that conditions.

\item Context information for the same patterns, in order to also restrict the applicable set of rules considering this information. 

\end{itemize}

Another useful information to consider in the refinement/ adaptation process will be:

\begin{itemize}

\item Risk information extracted from the user profile (reputation), e.g. "Did the user received a lot of `denies'/`allows' before?", i.e. "Is he/she trustworthy?". In case the user is not, more restrictive rules would be created for him, otherwise the corresponding rules could be `eased' for that user.

\item The information stored in logs along the system, which can, for instance, tell about how the user responds to system messages (either an action or if he gives feedback). This could result in the inference of new rules or in adaptation, in order to deal with, for instance, users that repeatedly ignore warning messages.
Moreover, important log information regarding the parameters used or the decisions made in the different modules will be used for further tests of new inferred rules, as it is explained below.

\end{itemize}

So, the approaches that will be implemented are:

\begin{itemize}

\item \textit{GP rule inference} method, which will generate/create new rules in order to `cover' those situations non contemplated in the current set of rules. Thus, for instance, a new rule could be created in order to deal with the patterns to which the classifier could not assign a class.
The generation will be done considering the so-called \textit{dictionary}, i.e. a set of terms corresponding to all the possible inputs and actions in the system, which will be antecedents (conditions) and consequents in the security rules to be inferred.
The evaluation of these rules will be done considering the stored log information concerning the parameters along with the actions/decisions made in every component in the system. Thus, it will be possible to `simulate' the whole  system behaviour when the new rule is included and get a value of its performance.

\item \textit{GP rule refinement} approach, which will optimise the current set of rules, adjusting the values in the conditions (antecedents), for instance. Thus, some superfluous parts on the rules and even complete rules could be removed or improved, obtaining for instance specialisations or generalisations of existing rules which could mean a better performance.
The evaluation (of the whole set of security rules) will be done considering the number of unlabelled patterns that will be `covered' after the adjustments.

\item \textit{GA optimisation} algorithm for setting up and adapting the assets' values. These are numerical representations of the importance of the corporate assets, and are considered in the Real-Time Risk and Trust Analysis process, in order to assign a risk value to every potential decision that can be made by the system.
If it is possible to evaluate the partial solutions proposed by the GA, this approach could be very useful for the CSO (who is in charge of assigning and adjusting these values over time).
The adaptation or adjustment concerns the change in value that an asset could have due to a loss of importance, once an event has passed (a project presentation, for instance).

\end{itemize}


%-----------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% CONCLUSIONS %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------- 
\section{Comparativa con Otros Sistemas y Conclusiones}
\label{sec:conclusion}

Como se ha podido comprobar, MUSES avanzará bastante en la aplicación de técnicas de minería de datos y Machine Learning para mejorar sistemas de seguridad. Esto quedaba claro en el artículo \cite{MUSES_SAC_14}, en el que puede consultarse una comparativa entre MUSES con otros sistemas similares ya comercializándose, pero de los cuales ninguno tiene la cualidad de adaptación que tiene el sistema que aquí hemos presentado.

Así, este sistema se differencia de los demás en que considera el riesgo que el propio usuario constituye para la seguridad de la empresa, sin ser este el enemigo, mientras que otros sistemas tratan de proteger frente a ataques externos. Además, las técnicas que usa, trabajan sobre datos reales, en un sistema real, por lo que sus resultados contribuyen realmente a evitar incidentes de seguridad reales.

Hemos encontrado que algunos autores sí usan técnicas de minería de datos, pero sus trabajos están enfocados a aplicaciones específicas como la detección de amenazas (botnet) \cite{botnet_detection_clustering_09}, o la detección de anomalías \cite{feature_selection_anomalies_08}. Sin embargo, ninguno las combina en el mismo procedimiento para conseguir mejorar los sistemas, como hace MUSES en su etapa de refinamiento de reglas.

Por otra parte, existen algunos trabajos que proponen la inferencia o refinamiento de reglas \cite{inferring_policies_socialnetworks_09,policy_generation_clustering_10}, pero no afectan al conjunto de políticas de la empresa ni el refinamiento está basado en el comportamiento del usuario, como propone el sistema que presentamos.

Además, la programación genética se usa ampliamente por varios autores \cite{rule_generation_gp_09,sec_policy_evolution_gp_08}, incluso para la creación de nuevas políticas o reglas enfocadas a la seguridad, pero de nuevo éstas no afectan al conjunto de políticas de una empresa. Es más, las funciones de evaluación que aquí se han propuesto, para el refinamiento y la inferencia de reglas, es novedoso y estará completamente integrado en el sistema.

Respecto a los Algoritmos Genéticos, son otro elemento cuyo uso puede encontrarse en muchos trabajos, en su mayoría para la detección de anomalías e intrusos, pero no para la optimización de las reglas como en nuestro caso. Sin embargo, hay algunos trabajos que sí podemos tomar como referencia para nuestro trabajo, como \cite{optimizing_IT_costs_ea_10,risk_reduction_ga_12}.

En cualquier caso, algunos de los trabajos revisados nos sirven como consideración para posibles características a añadir a MUSES, tales como el análisis de usuarios a través de redes sociales \cite{inferring_policies_socialnetworks_09,user_classification_ml_13}, la optimización de protocolos de seguridad \cite{GAs_security_protocols_10}, la implementación de mecanismos de detección de intrusos \cite{GA_intrusion_detection_survey_14} o, aunque MUSES ya lo incorpore, la aplicación de técnicas mejoradas de protección de la privacidad \cite{AAI_book_2009}.

%******************************************************************************

\section*{Agradecimientos}
La realización de este trabajo ha sido respaldado por el proyecto europeo MUSES (FP7-318508), además de por el PYR-2014-17 incluído en GENIL - CEI BIOTIC (Granada).

\nocite{*}
\bibliographystyle{maeb2015}

\begin{thebibliography}{1}

\bibitem{SecPolComp12}
A.~Al-Omari, O.~El-Gayar, A.~Deokar, and J.~Walters.
\newblock Security policy compliance: User acceptance perspective.
\newblock In {\em 45th Hawaii International Conference on System Sciences},
  pages 3317--3326. IEEE Press, 2012.

\bibitem{cost_adjustment_07}
E.~Alfaro-Cid, K.~Sharman, and A.~Esparcia-AlcÃ¡zar.
\newblock A genetic programming approach for bankruptcy prediction using a
  highly unbalanced database.
\newblock In M.~Giacobini, editor, {\em Applications of Evolutionary
  Computing}, volume 4448 of {\em Lecture Notes in Computer Science}, pages
  169--178. Springer Berlin Heidelberg, 2007.

\bibitem{computer_security_80}
A.~J.~P. Anderson.
\newblock Computer security threat monitoring and surveillance.
\newblock Technical report, James P. Anderson Co., Fort Washington, PA, 1980.

\bibitem{BYOD13}
S.~Bacik.
\newblock {\em Information Security Management Handbook}, volume~7, chapter
  Security Implications of Bring Your Own Device, IT Consumerization, and
  Managing User Choices, pages 133--142.
\newblock Sixth edition, 2013.

\bibitem{EAs_Back96}
T.~Back.
\newblock {\em Evolutionary algorithms in theory and practice}.
\newblock Oxford University Press, 1996.

\bibitem{MachineLearning_Bishop06}
C.~Bishop.
\newblock {\em Pattern recognition and Machine Learning}.
\newblock Springer, 2006.

\bibitem{SecPolComp10}
B.~Bulgurcu, H.~Cavusoglu, and I.~Benbasat.
\newblock Information security policy compliance: an empirical study of
  rationality-based beliefs and information security awareness.
\newblock {\em MIS Quarterly}, 34(3):523--548, 2010.

\bibitem{botnet_detection_clustering_09}
S.~Chang and T.~E. Daniels.
\newblock P2p botnet detection using behavior clustering \& statistical tests.
\newblock In {\em Proceedings of the 2nd ACM Workshop on Security and
  Artificial Intelligence}, AISec '09, pages 23--30, New York, NY, USA, 2009.
  ACM.

\bibitem{inferring_policies_socialnetworks_09}
G.~Danezis.
\newblock Inferring privacy policies for social networking services.
\newblock In {\em Proceedings of the 2Nd ACM Workshop on Security and
  Artificial Intelligence}, AISec '09, pages 5--10, New York, NY, USA, 2009.
  ACM.

\bibitem{ai_intrusion_detection_94}
J.~Frank and N.~U. Mda-c.
\newblock Artificial intelligence and intrusion detection: Current and future
  directions.
\newblock In {\em In Proceedings of the 17th National Computer Security
  Conference}, 1994.

\bibitem{GAs_Goldberg89}
D.~E. Goldberg.
\newblock {\em Genetic Algorithms in search, optimization and machine
  learning}.
\newblock Addison Wesley, 1989.

\bibitem{learning_network_intrusion_09}
N.~G\"{o}rnitz, M.~Kloft, K.~Rieck, and U.~Brefeld.
\newblock Active learning for network intrusion detection.
\newblock In {\em Proceedings of the 2Nd ACM Workshop on Security and
  Artificial Intelligence}, AISec '09, pages 47--54, New York, NY, USA, 2009.
  ACM.

\bibitem{GA_intrusion_detection_survey_14}
P.~Gowher~Majeed and S.~Kumar.
\newblock Genetic algorithms in intrusion detection systems: A survey.
\newblock {\em International Journal of Innovation and Applied Studies},
  5(3):233--240, March 2014.

\bibitem{cognitive_security_08}
R.~Greenstadt and J.~Beal.
\newblock Cognitive security for personal devices.
\newblock In {\em Proceedings of the 1st ACM Workshop on Workshop on AISec},
  AISec '08, pages 27--30, New York, NY, USA, 2008. ACM.

\bibitem{FeatureSelection_Guyon03}
I.~Guyon and A.~Elisseeff.
\newblock An introduction to variable and feature selection.
\newblock {\em J. Mach. Learn. Res.}, 3:1157--1182, 2003.

\bibitem{PatternMining_Han07}
J.~Han, H.~Cheng, D.~Xin, and X.~Yan.
\newblock Frequent pattern mining: Current status and future directions.
\newblock {\em Data Min. Knowl. Discov.}, 15(1):55--86, 2007.

\bibitem{SecPolPenalty09}
T.~Herath and H.~Rao.
\newblock Protection motivation and deterrence: a framework for security policy
  compliance in organisations.
\newblock {\em European Journal of Information Systems}, 18:106--125, 2009.

\bibitem{Clustering_Jain99}
A.~K. Jain, M.~N. Murty, and P.~J. Flynn.
\newblock Data clustering: A review.
\newblock {\em ACM Comput. Surv.}, 31(3):264--323, Sept. 1999.

\bibitem{imbalance_techniques_02}
N.~Japkowicz and S.~Stephen.
\newblock The class imbalance problem: A systematic study.
\newblock {\em Intell. Data Anal.}, 6(5):429--449, Oct. 2002.

\bibitem{user-controllable_learning_08}
P.~G. Kelley, P.~Hankes~Drielsma, N.~Sadeh, and L.~F. Cranor.
\newblock User-controllable learning of security and privacy policies.
\newblock In {\em Proceedings of the 1st ACM Workshop on Workshop on AISec},
  AISec '08, pages 11--18, New York, NY, USA, 2008. ACM.

\bibitem{optimizing_IT_costs_ea_10}
T.~Kirta and J.~Kivimaab.
\newblock Optimizing it security costs by evolutionary algorithms.
\newblock In C.~Czosseck and K.~Podins, editors, {\em Conference on Cyber
  Conflict}, pages 145--160, Tallinn, Estonia, 2010. CCD COE Publications.

\bibitem{feature_selection_anomalies_08}
M.~Kloft, U.~Brefeld, P.~D\"{u}essel, C.~Gehl, and P.~Laskov.
\newblock Automatic feature selection for anomaly detection.
\newblock In {\em Proceedings of the 1st ACM Workshop on Workshop on AISec},
  AISec '08, pages 71--76, New York, NY, USA, 2008. ACM.

\bibitem{GP_Koza92}
J.~R. Koza.
\newblock {\em Genetic Programming: On the programming of computers by means of
  natural selection}.
\newblock MIT Press, Cambridge, MA, 1992.

\bibitem{DataMining_Lee01}
S.~J. Lee and K.~Siau.
\newblock A review of data mining techniques.
\newblock {\em Industrial Management \& Data Systems}, 101(1):41--46, 2001.

\bibitem{user_classification_ml_13}
A.~Leontjeva, M.~Goldszmidt, Y.~Xie, F.~Yu, and M.~Abadi.
\newblock Early security classification of skype users via machine learning.
\newblock In {\em Proceedings of the 2013 ACM Workshop on Artificial
  Intelligence and Security}, AISec '13, pages 35--44, New York, NY, USA, 2013.
  ACM.

\bibitem{pol_evol_gp_3_approaches_08}
Y.~T. Lim, P.~C. Cheng, J.~Clark, and P.~Rohatgi.
\newblock Policy evolution with genetic programming: A comparison of three
  approaches.
\newblock In {\em Evolutionary Computation, 2008. CEC 2008. (IEEE World
  Congress on Computational Intelligence). IEEE Congress on}, pages 1792--1800,
  June 2008.

\bibitem{sec_policy_evolution_gp_08}
Y.~T. Lim, P.~C. Cheng, P.~Rohatgi, and J.~A. Clark.
\newblock Mls security policy evolution with genetic programming.
\newblock In {\em Proceedings of the 10th Annual Conference on Genetic and
  Evolutionary Computation}, GECCO '08, pages 1571--1578, New York, NY, USA,
  2008. ACM.

\bibitem{MIT05}
R.~Lippmann, K.~Ingols, C.~Scott, K.~Piwowarski, K.~Kratkiewicz, M.~Artz, and
  R.~Cunningham.
\newblock Evaluating and strengthening enterprise network security using attack
  graphs.
\newblock Project report ia-2, Massachusetts Institute of Technology, Lincoln
  Laboratory, October 2005.

\bibitem{detecting_intrusion_gp_03}
W.~Lu and L.~Traore.
\newblock Detecting new forms of network intrusion using genetic programming.
\newblock In {\em Proceedings of the 2003 Congress on Evolutionary
  Computation}, pages 2165--2172, 2003.

\bibitem{classification_67}
J.~MacQueen et~al.
\newblock Some methods for classification and analysis of multivariate
  observations.
\newblock In {\em Proceedings of the fifth Berkeley symposium on mathematical
  statistics and probability}, volume~1, page~14. California, USA, 1967.

\bibitem{MUSES_SAC_14}
A.~Mora, P.~De~las Cuevas, J.~Merelo, S.~Zamarripa, M.~Juan,
  A.~Esparcia-Alcázar, M.~Burvall, H.~Arfwedson, and Z.~Hodaie.
\newblock {MUSES: A corporate user-centric system which applies computational
  intelligence methods}.
\newblock In D.~S. et~al., editor, {\em 29th Symposium On Applied Computing},
  pages 1719--1723, 2014.

\bibitem{ai_cybersecurity_11}
B.~Morel.
\newblock Artificial intelligence and the future of cybersecurity.
\newblock In Y.~Chen, A.~A. Cárdenas, R.~Greenstadt, and B.~I.~P. Rubinstein,
  editors, {\em AISec}, pages 93--98. ACM, 2011.

\bibitem{Opp_Security11}
R.~Oppliger.
\newblock Security and privacy in an online world.
\newblock {\em IEEE Computer}, 44(9):21--22, September 2011.

\bibitem{android11}
C.~Orthacker, P.~Teufl, S.~Kraxberger, G.~Lackner, M.~Gissing, A.~Marsalek,
  J.~Leibetseder, and O.~Prevenhueber.
\newblock Android security permissions - can we trust them?
\newblock In {\em MobiSec Session on Smartphone Security}, Aalborg, 2011.

\bibitem{BigData_11}
B.~Ratner.
\newblock {\em Statistical and Machine-Learning Data Mining: Techniques for
  Better Predictive Modeling and Analysis of Big Data, Second Edition}.
\newblock CRC Press, Inc., Boca Raton, FL, USA, 2nd edition, 2011.

\bibitem{policy_generation_clustering_10}
T.~Samak and E.~Al-Shaer.
\newblock Synthetic security policy generation via network traffic clustering.
\newblock In {\em Proceedings of the 3rd ACM Workshop on Artificial
  Intelligence and Security}, AISec '10, pages 45--53, New York, NY, USA, 2010.
  ACM.

\bibitem{SecPolComp09}
R.~Shaw, C.~Chen, A.~Harris, and H.-J. Huang.
\newblock The impact of information richness on information security awareness
  training effectiveness.
\newblock {\em Computers \& Education}, 52:92--100, 2009.

\bibitem{SecPolComp07}
M.~Siponen, S.~Pahnila, and A.~Mahmood.
\newblock {\em {New Approaches for Security, Privacy and Trust in Complex
  Environments}}, volume 232, chapter {Employees' adherence to information
  security policies: an empirical study}, pages 133--144.
\newblock IFIP International Federation for Information Processing, 2007.

\bibitem{AAI_book_2009}
A.~Solanas and A.~Martínez-bal.
\newblock {\em Advances in Artificial Intelligence for Privacy Protection and
  Security}.
\newblock World Scientific Publishing Co., Inc., River Edge, NJ, USA, 2009.

\bibitem{rule_generation_gp_09}
G.~Suarez-Tangil, E.~Palomar, J.~Fuentes, J.~Blasco, and A.~Ribagorda.
\newblock Automatic rule generation based on genetic programming for event
  correlation.
\newblock In l.~Herrero, P.~Gastaldo, R.~Zunino, and E.~Corchado, editors, {\em
  Computational Intelligence in Security for Information Systems}, volume~63 of
  {\em Advances in Intelligent and Soft Computing}, pages 127--134. Springer
  Berlin Heidelberg, 2009.

\bibitem{risk_reduction_ga_12}
A.~Tamjidyamcholo.
\newblock Genetic algorithm approach for risk reduction of information
  security.
\newblock {\em International Journal of Cyber-Security and Digital Forensics
  (IJCSDF)}, 1(1), 2012.

\bibitem{GAs_security_protocols_10}
L.~Zarza, J.~Forné~Muñoz, J.~R. Pegueroles~Vallés, and M.~Soriano~Ibáñez.
\newblock {\em Advances in artificial intelligence for privacy protection and
  security}, chapter Genetic algorithms for designing network security
  protocols, pages 325--358.
\newblock World Scientific, 2010.

\bibitem{eval_security_gas_07}
L.~Zarza, J.~Pegueroles, and M.~Soriano.
\newblock Evaluation function for synthesizing security protocols by means of
  genetic algorithms.
\newblock In {\em Proceedings of the The Second International Conference on
  Availability, Reliability and Security}, ARES '07, pages 1207--1213,
  Washington, DC, USA, 2007. IEEE Computer Society.

\bibitem{cryptographic_gas_06}
L.~Zarza, J.~Pegueroles, M.~Soriano, and R.~Martínez.
\newblock Design of cryptographic protocols by means of genetic algorithms
  techniques.
\newblock In M.~Malek, E.~Fernández-Medina, and J.~Hernando, editors, {\em
  SECRYPT}, pages 316--319. INSTICC Press, 2006.

\end{thebibliography}
\end{document}
