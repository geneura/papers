\documentclass[twocolumn]{maeb2015}
\usepackage[latin1]{inputenc}
\usepackage[dvips]{epsfig}
\usepackage{graphicx}        % standard LaTeX graphics tool
\usepackage{subfigure}
\usepackage{url}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\hyphenation{res-pe-tar pro-pu-es-ta de-pen-dien-do di-fe-ren-tes ha-cer-se u-su-a-rios me-dian-te vi-sua-li-zar co-rres-pon-dien-te}

\begin{document}

\title{Aplicación de Técnicas de Inteligencia Computacional a un Sistema de Ciberseguridad Corporativa} %!PN

\author{P. De las Cuevas, A.M. Mora, J.J. Merelo, P.A. Castillo \thanks{Departamento de Arquitectura y Tecnología de Computadores. CITIC, ETSIIT,Universidad de Granada
E-mail: \{paloma,amorag,jmerelo, pedro\}@geneura.ugr.es}}

\maketitle


\begin{abstract}
Este artículo presenta una aplicación, basada en un proyecto europeo en desarrollo, que combina métodos de \textit{Data Mining}, \textit{Machine Learning} e Inteligencia Computacional para crear un sistema de seguridad corporativa centrado en el usuario y auto-adaptativo.
De forma que este sistema, llamado MUSES, será capaz de analizar el comportamiento de los usuarios del mismo (modelado como un conjunto de eventos) al interactuar con el servidor de la empresa para acceder a recursos distribuidos (y protegidos), por ejemplo. Como resultado de dicho análisis y tras la aplicación de las técnicas mencionadas, las \textit{Políticas de Seguridad} de la empresa, o más específicamente las \textit{Reglas de Seguridad} derivadas de las mismas, serán adaptadas para manejar nuevas situaciones anómalas o peligrosas (para la seguridad empresarial), así como para gestionar mejor las acciones de los usuarios.
El trabajo revisa, inicialmente, el estado del arte en esta línea, es decir, la aplicación de este tipo de técnicas a cuestiones de seguridad en la empresa.
Posteriormente, se describen las características de MUSES en este sentido y se compara dicho sistema con los métodos y herramientas existentes.
\end{abstract}

\begin{keywords}
Inteligencia Computacional, Inteligencia Artificial, Computación Evolutiva, Algoritmos Evolutivos, Programación Genética, Seguridad Corporativa, Reglas de Seguridad
\end{keywords}

%-------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% INTRODUCTION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------------------------------------------------------------------
\section{Introducción}
\noindent 

La seguridad en sistemas distribuidos ha sido un área de investigación muy explotada desde la aparición de las primeras arquitecturas cliente/ servidor \cite{computer_security_80}, siendo la seguridad corporativa uno de los temas principales

Sin embargo, el entorno ha cambiado drásticamente en los últimos años, empezando por la distribución de la información, la cual ha pasado de estar centralizada en un servidor de la empresa a encontrarse dispersa en múltiples máquinas, tales como dispositivos portátiles, servidores externos o sistemas de almacenamiento en la nube. A esto se une la llamada filosofía de \textit{BYOD: Bring Your Own Device} (usar tu propio dispositivo), en la que los dispositivos que acceden a los sistemas de la empresa pertenecen a usuarios (empleados de la misma), por lo que contendrán al mismo tiempo información personal y profesional.

Este escenario trae consigo nuevos retos o amenazas de seguridad \cite{Opp_Security11}, que deben ser tratados de forma diferente de lo habitual, considerando al mismo tiempo cuestiones de seguridad y de privacidad de los usuarios. A fin de gestionar esta situación se suelen manejar las \textit{Políticas de Seguridad Corporativa} (PSCs).

En este entorno se está desarrollando (dentro de un proyecto europeo) el sistema MUSES (\textit{Multiplatform Usable Endpoint Security}) \cite{MUSES_SAC_14}, un sistema independiente del dispositivo y centrado en el usuario.
Este sistema considera un conjunto de reglas de seguridad, definidas como especializaciones de las PSCs, y tiene la capacidad de `aprender' del comportamiento pasado de los usuarios y adaptar este conjunto de reglas, incluso generando nuevas, para gestionar de forma efectiva futuros incidentes de seguridad debidos a acciones de los usuarios. De esta forma el sistema reaccionará, de forma no intrusiva, a las secuencias de acciones (eventos) potencialmente peligrosas que éstos estén realizando en cada momento.

Con este fin MUSES analizará el comportamiento de los usuarios por medio de técnicas de \textit{Data Mining} (DM)\cite{DataMining_Lee01} y \textit{Machine Learning} (ML)\cite{MachineLearning_Bishop06}, extrayendo un conjunto de patrones que serán procesados posteriormente por medio de métodos de Inteligencia Computacional (IC), principalmente Algoritmos Evolutivos \cite{EAs_Back96,GAs_Goldberg89,GP_Koza92}.

Esto supone un paso adelante en el estado del arte en dos sentidos: primero, respecto a los sistemas de seguridad corporativa existentes para el manejo de situaciones de BYOD, como se describe en nuestro trabajo \cite{MUSES_SAC_14}; segundo, en relación con la aplicación de técnicas de IC a este tipo de problemas de seguridad, para su adaptación al comportamiento de los usuarios, como se describirá en este trabajo.

El artículo se estructura de la siguiente forma: la siguiente sección comenta algunos conceptos interesantes en relación a la seguridad corporativa. La Sección \ref{sec:soa} revisa la bibliografía existente respecto a la aplicación de DM, ML e IC a problemas de seguridad en la empresa, principalmente enfocados en el comportamiento del usuario y la adaptación de los sistemas o las reglas de seguridad, principal característica de MUSES.
Dicho sistema se presenta en la Sección \ref{sec:muses}, haciendo hincapié en las técnicas citadas. 
Finalmente, las ventajas de MUSES respecto a otras utilidades son analizadas en la Sección \ref{sec:conclusion}.


%-----------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% BACKGROUND %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------------------------------------------------
\section{Seguridad en la Empresa}

Hasta hace poco tiempo las empresas solían aplicar \textit{Políticas de Seguridad} (PSs) estáticas, enfocadas a controlar estructuras determinadas \cite{BYOD13} en las que los recursos de información (\textit{Information Assets}) y los dispositivos que los acceden son gestionados por la empresa.
Actualmente las redes corporativas se están transformando en redes dinámicas a fin de adaptarse a la filosofía BYOD, lo que está trayendo nuevos focos de riesgo, como que el dispositivo en cuestión no pertenezca a la empresa y, por tanto, escape a un control estricto por parte de la misma. Esto hace que se requieran políticas de seguridad específicas, más concretamente \textit{Políticas de Seguridad sobre Información} (ISPs en inglés), que puedan gestionar y proteger información determinada de la empresa de posibles brechas de seguridad.

Aunque existen estándares, tales como el ISO27002 o el Estándar de Buenas Prácticas del Foro de Seguridad Internacional\footnote{https://www.securityforum.org}, una ISP se define en función de las características de la organización que se quiere controlar con ella.

Normalmente la arquitectura de la red de seguridad de la empresa se adapta para lidiar con ataques externos \cite{MIT05}, sin embargo, con la aparición del BYOD, la clave está en proteger los recursos que se vean comprometidos debido a vulnerabilidades de los dispositivos de los empleados \cite{android11}, o filtraciones que surjan al ser accedidos desde dispositivos conectados a redes inseguras, por ejemplo.
Además, estos dispositivos, como los extendidos \textit{smartphones} suelen combinar información personal y profesional, así como aplicaciones de ambos tipos, lo que añade un factor de riesgo al estar dichas aplicaciones no corporativas poco controladas.

Por tanto, a la hora de diseñar la arquitectura de la red de una compañía, hay que tener en cuenta todos estos factores.
La Figura \ref{fig:proposed_diagram} muestra una propuesta que puede emplearse como punto de partida para el diseño de soluciones que hagan seguro este entorno dinámico. Ésta incluye el caso de tener dispositivos móviles (\textit{smartphones y tablets}) u ordenadores portátiles propios de algunos empleados, además muestra la oportunidad de que dichos dispositivos se conecten desde dentro o desde fuera de la compañía.
Los recursos de información son accedidos continuamente en estas condiciones, considerando como recurso cualquier trozo de información que tenga un valor asociado (coste, dependiendo del riesgo, de que esa información se pierda o se filtre).
Ejemplos de este tipo de recursos podrían ser documentos con información restringida, determinados e-mails críticos, e incluso aplicaciones internas de la compañía.

\begin{figure}[ht]
	\begin{center}
		\includegraphics[scale=0.36]{proposed_diagram_esp.eps}
		\caption{Muestra de arquitectura de red de una empresa, considerando que ésta ha adoptado la filosofía BYOD.}
	\label{fig:proposed_diagram}
	\end{center}
\end{figure}

Otro aspecto importante a considerar es la elaboración de un buen conjunto de ISPs, que sean comprensibles por los usuarios y, lo más importante, no intrusivas para ellos.
Muchos investigadores han estudiado la tendencia natural de los usuarios a cumplir unas políticas y no otras \cite{SecPolComp07,SecPolComp10,SecPolComp12}, concluyendo que si los empleados respetan las políticas de seguridad habrá un aumento del aprendizaje de técnicas para acceder a la información de forma segura \cite{SecPolComp09}, y que dicho aprendizaje se reducirá si lo que se aplica son castigos o penalizaciones al no respetar las políticas de la empresa \cite{SecPolPenalty09}. 

Esta situación conduce a la necesidad de proteger tanto lado de la organización como el de los usuarios, por medio de ISPs sencillas que no interfieran la actividad de los éstos, incluso dejando que los empleados usen dispositivos propios con propósitos personales mientras trabajan, pero asegurando al mismo tiempo la integridad de los recursos de información en riesgo. La combinación de estos aspectos llevará a la consecución de un sistema de seguridad con las características que pretende ofrecer MUSES (ver Sección \ref{sec:muses}).

%-----------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% STATE OF THE ART %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-----------------------------------------------------------------------
\section{Estado del Arte}
\label{sec:soa}

La seguridad en sistemas informáticos es un campo de estudio muy amplio desde principios de los años ochenta \cite{computer_security_80}, con miles de trabajos publicados en muchos temas diferentes en relación a este área.

Uno de los campos más prolíficos es la aplicación de técnicas de Inteligencia Artificial (IA) a diferentes problemas de seguridad informática. Esta línea comenzó hace más de veinte años \cite{ai_intrusion_detection_94} y seguirá abierta por muchos años más \cite{ai_cybersecurity_11}.
Los temas tratados por los investigadores son muy variados, incluyendo enfoques basados en \textit{Data Mining (DM)} \cite{botnet_detection_clustering_09,feature_selection_anomalies_08}, así como \textit{Machine Learning (ML)} \cite{learning_network_intrusion_09,user_classification_ml_13}, aplicados a la resolución de diversos problemas.

La Inteligencia Computacional (IC) también ha sido ampliamente usada en este área, siendo los métodos más prolíficos aquellos basados en Computación Evolutiva (CE), principalmente Algoritmos Genéticos (AGs) y Programación Genética (PG).

Existen diversos trabajos aplicando AGs a la re\-solución de problemas de seguridad, tales como la detección de intrusos (vea \cite{GA_intrusion_detection_survey_14} para un estado del arte), el diseño y evaluación de protocolos de seguridad  \cite{detecting_intrusion_gp_03,eval_security_gas_07,GAs_security_protocols_10} o la optimización de otros aspectos como los costes de seguridad informática en una empresa \cite{optimizing_IT_costs_ea_10} o el diseño de protocolos criptográficos efectivos \cite{cryptographic_gas_06}, por citar algunos.

Este trabajo se centra en la aplicación de diferentes métodos de DM, ML y AI/CI a un nuevo conjunto de problemas de seguridad, que han emergido como consecuencia de las nuevas interacciones entre sistemas y comportamientos de usuarios que ha traído consigo la filosofía BYOD, como se ha comentado en la sección anterior.
Por tanto, los estudios que nos interesan son aquellos que procesen información relativa al comportamiento de los usuarios en el sistema (en este entorno), y la adaptación de las políticas o reglas de seguridad que puedan hacerse.

Siguiendo esta línea, el trabajo de Greenstadt y Beal \cite{cognitive_security_08} combinaba señales de biometría con métodos de ML con el objetivo de obtener una identificación fiable de un usuario en un sistema informático.
P.G. Kelley et al. \cite{user-controllable_learning_08} presentaron un método llamado \textit{user-controllable policy learning} (aprendizaje de políticas de un usuario controlado) en el que el usuario daba su opinión al sistema cada vez que una política de seguridad era aplicada. De esta forma las políticas eran refinadas o mejoradas en base a dicha opinión, a fin de ser más precisas en lo que respecta a las necesidades de los usuarios del sistema.
Este enfoque podría ser adecuado para un dispositivo personal, pero nuestro objetivo en MUSES es contar con un conjunto global de reglas que sea adaptado a todos los usuarios del sistema.

Por otra parte, las políticas podrían crearse con el objetivo de fomentar la privacidad de los usuarios, como propuso Danezis en  \cite{inferring_policies_socialnetworks_09}. Él definió un sistema capaz de inferir restricciones relacionadas con la privacidad por medio de un algoritmo de ML, que se aplicaba en el entorno de una red social. 
En este caso, la idea de inferir políticas (o reglas) se ha contemplado también en MUSES, pero en el entorno de la compañía y más enfocadas a la creación de ISPs.

Un trabajo más cercano a nuestro sistema es el que presentaron Samak et al. \cite{policy_generation_clustering_10}, en el que los autores usaron un método de \textit{clustering} (agrupamiento) para inferir nuevas políticas de gestión del tráfico en una red de información.
Sin embargo, nuestra idea en MUSES, como se explica en la Sección \ref{sec:muses}, es inferir nuevas Reglas de Seguridad (especialización de las ISPs) por medio de PG.

Otros investigadores, como Lim et al., han aplicado esta metaheurística para evolucionar (mejorar) un conjunto de políticas \cite{sec_policy_evolution_gp_08,pol_evol_gp_3_approaches_08}. Ellos infirieron nuevas políticas basadas en las decisiones tomadas en un sistema, considerando además las opiniones de los usuarios del mismo. MUSES aplicará un procedimiento similar, pero la evaluación de las nuevas políticas se automatizará, al menos en parte. Además, el problema de esas propuestas es que se probaron sobre sistemas `sintécticos', es decir, sistemas simulados o no reales. MUSES se ejecutará en compañías reales con usuarios reales.

Por último, el trabajo de Suarez-Tangil et al. \cite{rule_generation_gp_09}, combina PG con la correlación de eventos, lo cual también aplica en MUSES \cite{MUSES_SAC_14}. Sin embargo, su implementación crea el motor o conjunto de reglas para realizar dicho proceso (la correlación), es decir, las decisiones/acciones a realizar considerando los eventos que se han producido y las ISPs.

La sección siguiente presenta el sistema MUSES de forma breve, así como las técnicas de DM, ML e IC que se aplicarán en el mismo, como mecanismos de adaptación de las ISPs al comportamiento de los usuarios del sistema.


%-------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% MUSES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%-------------------------------------------------------------
\section{El Sistema MUSES}
\label{sec:muses}

Como se ha indicado anteriormente MUSES es un sistema de seguridad corporativa enfocado a trabajar dentro de la filosofía BYOD, es decir, éste gestionará los accesos de usuarios a los servidores de la empresa desde diversos dispositivos, incluyendo propios, hecho que implica diversos riesgos, incluido el propio comportamiento de los usuarios.

\subsection{Arquitectura del sistema}

Como se puede ver en la Figura \ref{fig:architecture_overview} la arquitectura de MUSES se basa en un enfoque cliente/servidor.
%
\begin{figure*}[htp]
\centering
\epsfig{file=architecture_overview.eps, scale=0.57}
\caption{Arquitectura general de MUSES (componentes de alto nivel). Sigue un esquema con varios clientes (parte derecha), dispositivos de los usuarios, y servidor (parte izquierda), en la que se realizan la mayor parte de las decisiones y el procesamiento. \label{fig:architecture_overview}}
\end{figure*}
%

En ésta, la aplicación \textit{cliente} se instalará en todos los dispositivos de los usuarios, y será independiente de la plataforma de que se trate, así como de su sistema operativo (una de las ventajas de MUSES). El \textit{servidor} por su parte se instalará en el centro de seguridad corporativa de la empresa. Ambas partes se conectarán mediante un canal seguro (usando HTTPS) sobre Internet.
Para una descripción más completa, los lectores pueden dirigirse a la página web del proyecto (\texttt{https://www.musesproject.eu)} o al artículo \cite{MUSES_SAC_14}.



Una de las ventajas más importantes del sistema es la auto-adaptación (tanto al usuario, como al contexto) que será capaz de realizar, modificando y mejorando el sistema de Reglas de Seguridad corporativas.

En este trabajo nos centraremos en la parte del servidor (ver Figura \ref{fig:server_architecture}), ya que es en ésta en la que se aplicarán las técnicas de DM, ML e IC sobre los datos recopilados por el sistema (almacenados en la Base de Datos). En concreto en el componente llamado \textit{MusKRS}, por MUSES \textit{Knowledge Refinement System}. Este módulo se ejecutará de forma asíncrona (varias veces o una vez al día, dependiendo del volumen de datos que se genere en la empresa a este respecto), y será el encargado de analizar toda información generada por los accesos de los usuarios (eventos, contexto, datos de usuario) a los recursos de información que haya en el servidor, tarea de la que se encargará el \textit{Data Miner}. Una vez analizados estos datos, se procederá a realizar una tarea de adaptación o refinado de reglas de seguridad (por el componente \textit{Knowledge Compiler}) para lidiar mejor con esos eventos, intentando predecir futuras amenazas de seguridad debidas al comportamiento de los usuarios.

De modo que el \textit{Data Miner} aplicará, como su nombre indica, técnicas de DM y ML para identificar y extraer patrones relevantes de los datos. Después el \textit{Knowledge Compiler} realizará una labor de inferencia y refinado/ajuste de reglas, mediante técnicas de IC, considerando los datos extraídos en este primer paso. Si bien, este último modulo también se encargará de realizar refinados más sencillos como especialización o generalización de reglas, aplicando métodos más simples.

%
\begin{figure*}[htp]
\centering
\epsfig{file=server_architecture.eps, scale=0.4}
\caption{Arquitectura del servidor de MUSES (submódulos), en la que destaca el componente llamado \textit{Knowledge Refinement System, MusKRS}, responsable de realizar las tareas de \textit{Data Mining}, \textit{Machine Learning} y la adaptación de las reglas se seguridad que rigen el sistema. \label{fig:server_architecture}}
\end{figure*}
%

Un factor a tener en cuenta es que MUSES tendrá un controlador humano, normalmente el jefe de seguridad de la compañía (\textit{Chief Security Officer ,CSO}), que se encargará de supervisar la actividad del sistema en base a logs e informes generados durante estas tareas.
De forma que todas las reglas refinadas o generadas serán etiquetadas como `potenciales' y deberán ser aprobadas por él/ella antes de ser finalmente añadidas al conjunto que rige al sistema.
Aún así, una de las posibles mejoras a implementar será un mecanismo de aprendizaje que sea capaz de predecir si una nueva regla sería aceptada o no por el CSO (en base a decisiones anteriores), a fin de automatizar este proceso en un futuro(tras un periodo de `entrenamiento').

Las siguientes secciones describen estos procesos: primero los métodos de DM que usará automáticamente el MusKRS, así como para una posible herramienta de análisis y ayuda a la decisión para el CSO; en segundo lugar se comentan las técnicas de IC a aplicar, principalmente centradas en el uso de Algoritmos Evolutivos, dado que estas metaheurísticas se comportan muy bien y han sido ampliamente utilizadas en problemas relacionados con la seguridad en la empresa, como se ha comentado en la Sección \ref{sec:soa}.

% ------------------------------------------------------------------
%
\subsection{Data Mining/Machine Learning}
\label{subsec:dm_ml}

Para esta tarea se considerará el conjunto de datos global en la base de datos y se preprocesará para componer subconjuntos más simples o más adecuados para ser tratados con estas técnicas. Después, se aplicarán métodos de clasificación, clustering, o visualización, entre otros, para extraer patrones que el \textit{Knowledge Compiler} procesará con otros métodos, o que se ofrecerán al controlador humano (CSO) para su información.

El proceso será principalmente no supervisado y procesará, eventualmente, grandes cantidades de datos (dependiendo de los flujos de trabajo de la compañía), por lo que será necesario aplicar técnicas de procesado de \textit{Big Data} \cite{BigData_11}.

Los métodos de DM/ML procesarán patrones que, en este contexto, se corresponderán con eventos (y su información correspondiente) producidos por las interacciones de los usuarios con el sistema.
En concreto se aplicarán:

\begin{itemize}

\item \textit{Pattern Mining} (extracción de patrones) \cite{PatternMining_Han07}: 
Este proceso tratará de identificar patrones de comportamiento en los datos, tanto frecuentes, como anómalos, a fin de procesarlos posteriormente. La idea subyacente es que los patrones poco frecuentes son potencialmente sospechosos, por lo que será interesante que el CSO esté al corriente, así como que puedan servir de base para el proceso de refinado de reglas.

\item \textit{Clasificación} \cite{classification_67}: 
Esta técnica trata de entrenar un modelo (clasificador) capaz de asociar cada patrón en el conjunto de datos con una etiqueta o clase, de forma que dicho modelo podría utilizarse para asignar una clase a nuevos patrones con categorías desconocidas, en base a su similitud con patrones previos.
Por ejemplo, se podrían considerar como modelo patrones de acciones que los usuarios quieren realizar, etiquetadas como `permitidas' o `denegadas' según las reglas de seguridad existentes. De forma que ante una nueva solicitud (un nuevo evento de acción) el clasificador pudiese asignar una clase a dicho patrón y, por tanto, una decisión, que estaría basada en patrones/decisiones anteriores.

\item \textit{Clustering} (agrupamiento) \cite{Clustering_Jain99}: 
El objetivo de esta técnica es agrupar los patrones considerando criterios de similaridad (distancias), a fin de gestionarlos como un conjunto. Esto puede ser útil para ofrecer herramientas de visualización de datos (al CSO), que permitan interpretar los datos de forma más sencilla e identificar visualmente los grupos que se forman en relación a distintas características y los patrones conflictivos o extraños, por estar desubicados o fuera de lugar.

\item \textit{Selección de Características} \cite{FeatureSelection_Guyon03}: 
Consiste en extraer las características más relevantes de los datos. Esto suele ser muy útil para descartar variables superflúas (para labores de clasificación, por ejemplo) que puedan agilizar otros procesos o reducir el espacio ocupado en la base de datos, mejorando el rendimiento de todo el sistema.

\item \textit{Análisis de Datos}: 
Se trata de proveer al CSO de herramientas o mecanismos para identificar o visualizar cuestiones interesantes o relevantes respecto a los datos, comportamientos sospechosos, reglas más utilizadas, etc.

\end{itemize}

%\pagebreak

% ------------------------------------------------------------------
%
\subsection{Inteligencia computacional: métodos de Computación Evolutiva}
\label{subsec:ci}

%+ Clasificación con GP
%- Inferencia de nuevas reglas con GP
%+ Ajuste de valores de recursos con AGs???

MUSES usará métodos de computación evolutiva mediante diversas implementaciones, inicialmente, una en el proceso de DM y ML, y otras tres técnicas en la fase de adaptación o refinado de reglas. Todas ellas se basarán en la Programación Genética (PG) \cite{GP_Koza92} y los Algoritmos Genéticos (AGs) \cite{GAs_Goldberg89}.

El primer método basado en técnicas evolutivas será la \textit{Clasificación mediante PG}. Ésta resulta de gran utilidad por dos razones principales: primero, para aplicar un método de balanceo de datos adecuado \cite{imbalance_techniques_02}, dado que en sistemas reales los datos suelen estar desbalanceados; en segundo lugar, para hacer una gestión efectiva de los datos categóricos (no numéricos), ya que la mayoría de variables o ca\-racterísticas extraídas de la información que ofrece el sistema serán de este tipo.

Por tanto, este método sería capaz de trabajar con conjuntos de datos no balanceados, considerando una función de fitness en la cual se pueda asociar un coste al porcentaje de aciertos del clasificador en cada generación, aplicando una penalización por cada falso negativo obtenido (un elemento de la clase minoritaria clasificado como miembro de la clase mayoritaria)  \cite{cost_adjustment_07}.
En cuanto al tipo de datos, dado que los algoritmos de PG suelen aplicar modelos basados en reglas o en árboles de decisión, estos se pueden aplicar a variables categóricas, obteniendo un buen clasificador como se muestra en el trabajo \cite{cost_adjustment_07}.

Centrándonos en el proceso de adaptación/refinado de reglas, las técnicas empleadas se aplicarán para inferencia y optimización, considerando los siguientes datos:

\begin{itemize}

\item La información extraída por el \textit{Data Miner}, en concreto los patrones anómalos, no clasificados o mal clasificados. Estos patrones serán aquellos que no se incluyen en ninguna de las clases ya existentes, ya que difieren en gran medida de los patrones de dichas clases. De modo que deberían tenerse en cuenta con el objetivo de mejorar el sistema de reglas de seguridad  para que sean `cubiertos' por ellas.

\item Información relativa al usuario, correspondiente a esos patrones o eventos, que son anómalos o que no han podido ser clasificados. Así, su número de identificación, localización (fuera o dentro de las instalaciones de la empresa), o puesto en la empresa, serían ejemplos de lo que el sistema consideraría a la hora de seleccionar un conjunto de reglas a aplicar en esa situación.

\item Información de contexto de dichos patrones, para restringir, de la misma forma que en el punto anterior, el conjunto de reglas a aplicar.

\end{itemize}

Otros tipos de información que podrían ser útiles durante el proceso de refinado o adaptación son los siguientes:

\begin{itemize}

\item Información del riesgo asociado a un determinado usuario (en términos de su reputación), como por ejemplo ``¿Ha recibido el usuario con anterioridad muchas notificaciones de `permitido'/`denegado'?''. Si el usuario tiende a recibir denegaciones a las acciones que suele realizar, se le aplicarán reglas más restrictivas que para un usuario que realice más acciones permitidas.

\item Información almacenada en \textit{ficheros de log} del sistema, que puede indicar, por ejemplo, cómo actúa un usuario frente a mensajes de advertencia del sistema (realizando la acción finalmente o no, o respondiendo de cierta manera a las preguntas que se le hagan o requisitos que se le exijan para continuar). Esto podría desembocar en la inferencia de nuevas reglas o en su adaptación para, por ejemplo, tratar con usuarios que repetidamente ignoran mensajes de advertencia.
Además, podría usarse la información interna del funcionamiento del sistema (parámetros y valores utilizados por los módulos para calcular riesgos, confianza y para tomar decisiones, por ejemplo) para aplicar tests sobre las nuevas reglas inferidas, como se explica debajo.

\end{itemize}

De esta manera, los métodos que se implementarán serán los siguientes:

\begin{itemize}

\item \textit{Inferencia de reglas mediante PG}, con el que se generarán o crearán nuevas reglas de seguridad para `cubrir' aquellas situaciones que no están contempladas en el conjunto inicial. Así, por ejemplo, se crearían reglas para poder clasificar aquellos eventos que no pudieron ser clasificados inicialmente. Esta generación de reglas se haría teniendo en cuenta un \textit{diccionario}, es decir, un conjunto de términos correspondiente a todas las posibles entradas y acciones del sistema, las cuales serían respectivamente los antecedentes (condiciones), y los respectivos consecuentes en las reglas a inferir. La evaluación de las reglas creadas se realizaría en base a la información de log almacenada, de manera que se podría `simu\-lar' el comportamiento del sistema al incluir las nuevas reglas, y se obtendría una medida de si las reglas creadas mejoran o no su rendimiento.

\item \textit{Refinado de reglas mediante PG}, por el cual se optimizará el conjunto de reglas actual, ajustando los valores de las condiciones (antecedentes). Así, se podrían eliminar partes superfluas de las reglas o incluso reglas completas, obteniendo de esta forma especializaciones o generalizaciones de reglas existentes que mejoren el rendimiento del sistema. La evaluación del conjunto total de reglas se haría considerando el número de patrones no clasificados que se `cubrirían' una vez realizados los ajustes.

\item \textit{Optimización basada en Algoritmos Genéticos} que adapten o ajusten los valores asociados a los recursos de información. Dichos valores son ponderaciones numéricas de la importancia que tiene ese recurso para la empresa. Se consideran en el proceso de análisis de riesgo y confianza/fiabilidad (\textit{Risk and Trust Analysis}), para calcular un valor de riesgo a cada decisión potencial que pudiese tomar el sistema (de forma autónoma en base a las reglas de seguridad). Si es posible evaluar las soluciones parciales propuestas por el AG, esta implementación podría ser muy útil para el CSO (persona a cargo de asignar y ajustar estos valores para cada recurso). Este ajuste se refiere a la pérdida de importancia que tendrá el recurso una vez que un evento en el que se usó ha pasado (o al contrario, el incremento de relevancia que adquiere si el evento se acerca).

\end{itemize}


%-----------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%% CONCLUSIONES %%%%%%%%%%%%%%%%%%%%%%%%%%%%
%----------------------------------------------------------------- 
\section{Comparativa con Otros Sistemas y Conclusiones}
\label{sec:conclusion}

Como se ha podido comprobar, MUSES supondrá un avance significativo en la aplicación de técnicas de \textit{Data Mining} y \textit{Machine Learning} para la mejora de sistemas de seguridad. Esto se dejó patente en el artículo \cite{MUSES_SAC_14}, en el que puede verse una comparativa entre MUSES y otros sistemas similares ya comercializados, ninguno de los cuales tiene la capacidad de adaptación que ofrece el sistema que hemos presentado.

MUSES se diferencia de los demás, principalmente, porque considera el riesgo que el propio usuario constituye para la seguridad de la empresa, sin considerarlo como una amenaza, por supuesto, mientras que otros sistemas se centran en la protección frente a ataques externos. Además, las técnicas que aplica, trabajan sobre datos reales (en un sistema real), por lo que sus resultados contribuyen realmente a evitar incidentes de seguridad reales.

Existen otros autores que también usan técnicas de \textit{Data Mining}, pero sus trabajos se centran en aplicaciones específicas, como la detección de amenazas (\textit{botnet}) \cite{botnet_detection_clustering_09}, o de anomalías \cite{feature_selection_anomalies_08}. Sin embargo, ninguno las combina en el mismo procedimiento para conseguir mejorar el propio sistema, como sí hace MUSES en su etapa de refinado de reglas.

Del mismo modo existen trabajos que proponen procesos de inferencia o refinado de reglas \cite{inferring_policies_socialnetworks_09,policy_generation_clustering_10}, pero que no alteran el conjunto de políticas o reglas de seguridad de la empresa. Además en ningún caso dicho refinado está basado en el comportamiento de los usuarios del propio sistema, siguiendo el modelo que aplica MUSES.

Respecto a la Programación Genética, ésta ha sido ampliamente utilizada por varios autores \cite{rule_generation_gp_09,sec_policy_evolution_gp_08}, incluso para la creación de nuevas políticas o reglas enfocadas a la seguridad, pero de nuevo éstas no afectan al conjunto de políticas de una empresa. Además, las funciones de evaluación que aquí se han propuesto, para el refinado y la inferencia de reglas, las consideramos novedosas por estar completamente integradas en el sistema.

Los Algoritmos Genéticos, por su parte, son otras metaheurísticas que pueden verse aplicadas en muchos trabajos, en su mayoría para la detección de anomalías e intrusos, pero no para la optimización de reglas de seguridad, como en nuestro caso. Sin embargo, hay algunos trabajos de optimización de costes y riesgos que sí podemos tomar como referencia para ampliar nuestro trabajo, como \cite{optimizing_IT_costs_ea_10,risk_reduction_ga_12}.

En cualquier caso, los trabajos revisados nos sirven como base para posibles características a añadir a MUSES, tales como el análisis de usuarios a través de redes sociales \cite{inferring_policies_socialnetworks_09,user_classification_ml_13}, la optimización de protocolos de seguridad \cite{GAs_security_protocols_10}, la implementación de mecanismos de detección de intrusos \cite{GA_intrusion_detection_survey_14} o, aunque MUSES ya lo incorpore, la aplicación de técnicas mejoradas de protección de la privacidad \cite{AAI_book_2009}.

%******************************************************************************

\section*{Agradecimientos}
La realización de este trabajo ha sido financiada por el proyecto europeo MUSES (FP7-318508), además de por el proyecto PYR-2014-17 incluido en GENIL - CEI BIOTIC (Granada).

\nocite{*}
\bibliographystyle{maeb2015}

\begin{thebibliography}{1}

\bibitem{SecPolComp12}
A.~Al-Omari, O.~El-Gayar, A.~Deokar, and J.~Walters.
\newblock Security policy compliance: User acceptance perspective.
\newblock In {\em 45th Hawaii International Conference on System Sciences},
  pages 3317--3326. IEEE Press, 2012.

\bibitem{cost_adjustment_07}
E.~Alfaro-Cid, K.~Sharman, and A.~Esparcia-AlcÃ¡zar.
\newblock A genetic programming approach for bankruptcy prediction using a
  highly unbalanced database.
\newblock In M.~Giacobini, editor, {\em Applications of Evolutionary
  Computing}, volume 4448 of {\em Lecture Notes in Computer Science}, pages
  169--178. Springer Berlin Heidelberg, 2007.

\bibitem{computer_security_80}
A.~J.~P. Anderson.
\newblock Computer security threat monitoring and surveillance.
\newblock Technical report, James P. Anderson Co., Fort Washington, PA, 1980.

\bibitem{BYOD13}
S.~Bacik.
\newblock {\em Information Security Management Handbook}, volume~7, chapter
  Security Implications of Bring Your Own Device, IT Consumerization, and
  Managing User Choices, pages 133--142.
\newblock Sixth edition, 2013.

\bibitem{EAs_Back96}
T.~Back.
\newblock {\em Evolutionary algorithms in theory and practice}.
\newblock Oxford University Press, 1996.

\bibitem{MachineLearning_Bishop06}
C.~Bishop.
\newblock {\em Pattern recognition and Machine Learning}.
\newblock Springer, 2006.

\bibitem{SecPolComp10}
B.~Bulgurcu, H.~Cavusoglu, and I.~Benbasat.
\newblock Information security policy compliance: an empirical study of
  rationality-based beliefs and information security awareness.
\newblock {\em MIS Quarterly}, 34(3):523--548, 2010.

\bibitem{botnet_detection_clustering_09}
S.~Chang and T.~E. Daniels.
\newblock P2p botnet detection using behavior clustering \& statistical tests.
\newblock In {\em Proceedings of the 2nd ACM Workshop on Security and
  Artificial Intelligence}, AISec '09, pages 23--30, New York, NY, USA, 2009.
  ACM.

\bibitem{inferring_policies_socialnetworks_09}
G.~Danezis.
\newblock Inferring privacy policies for social networking services.
\newblock In {\em Proceedings of the 2Nd ACM Workshop on Security and
  Artificial Intelligence}, AISec '09, pages 5--10, New York, NY, USA, 2009.
  ACM.

\bibitem{ai_intrusion_detection_94}
J.~Frank and N.~U. Mda-c.
\newblock Artificial intelligence and intrusion detection: Current and future
  directions.
\newblock In {\em In Proceedings of the 17th National Computer Security
  Conference}, 1994.

\bibitem{GAs_Goldberg89}
D.~E. Goldberg.
\newblock {\em Genetic Algorithms in search, optimization and machine
  learning}.
\newblock Addison Wesley, 1989.

\bibitem{learning_network_intrusion_09}
N.~G\"{o}rnitz, M.~Kloft, K.~Rieck, and U.~Brefeld.
\newblock Active learning for network intrusion detection.
\newblock In {\em Proceedings of the 2Nd ACM Workshop on Security and
  Artificial Intelligence}, AISec '09, pages 47--54, New York, NY, USA, 2009.
  ACM.

\bibitem{GA_intrusion_detection_survey_14}
P.~Gowher~Majeed and S.~Kumar.
\newblock Genetic algorithms in intrusion detection systems: A survey.
\newblock {\em International Journal of Innovation and Applied Studies},
  5(3):233--240, March 2014.

\bibitem{cognitive_security_08}
R.~Greenstadt and J.~Beal.
\newblock Cognitive security for personal devices.
\newblock In {\em Proceedings of the 1st ACM Workshop on Workshop on AISec},
  AISec '08, pages 27--30, New York, NY, USA, 2008. ACM.

\bibitem{FeatureSelection_Guyon03}
I.~Guyon and A.~Elisseeff.
\newblock An introduction to variable and feature selection.
\newblock {\em J. Mach. Learn. Res.}, 3:1157--1182, 2003.

\bibitem{PatternMining_Han07}
J.~Han, H.~Cheng, D.~Xin, and X.~Yan.
\newblock Frequent pattern mining: Current status and future directions.
\newblock {\em Data Min. Knowl. Discov.}, 15(1):55--86, 2007.

\bibitem{SecPolPenalty09}
T.~Herath and H.~Rao.
\newblock Protection motivation and deterrence: a framework for security policy
  compliance in organisations.
\newblock {\em European Journal of Information Systems}, 18:106--125, 2009.

\bibitem{Clustering_Jain99}
A.~K. Jain, M.~N. Murty, and P.~J. Flynn.
\newblock Data clustering: A review.
\newblock {\em ACM Comput. Surv.}, 31(3):264--323, Sept. 1999.

\bibitem{imbalance_techniques_02}
N.~Japkowicz and S.~Stephen.
\newblock The class imbalance problem: A systematic study.
\newblock {\em Intell. Data Anal.}, 6(5):429--449, Oct. 2002.

\bibitem{user-controllable_learning_08}
P.~G. Kelley, P.~Hankes~Drielsma, N.~Sadeh, and L.~F. Cranor.
\newblock User-controllable learning of security and privacy policies.
\newblock In {\em Proceedings of the 1st ACM Workshop on Workshop on AISec},
  AISec '08, pages 11--18, New York, NY, USA, 2008. ACM.

\bibitem{optimizing_IT_costs_ea_10}
T.~Kirta and J.~Kivimaab.
\newblock Optimizing it security costs by evolutionary algorithms.
\newblock In C.~Czosseck and K.~Podins, editors, {\em Conference on Cyber
  Conflict}, pages 145--160, Tallinn, Estonia, 2010. CCD COE Publications.

\bibitem{feature_selection_anomalies_08}
M.~Kloft, U.~Brefeld, P.~D\"{u}essel, C.~Gehl, and P.~Laskov.
\newblock Automatic feature selection for anomaly detection.
\newblock In {\em Proceedings of the 1st ACM Workshop on Workshop on AISec},
  AISec '08, pages 71--76, New York, NY, USA, 2008. ACM.

\bibitem{GP_Koza92}
J.~R. Koza.
\newblock {\em Genetic Programming: On the programming of computers by means of
  natural selection}.
\newblock MIT Press, Cambridge, MA, 1992.

\bibitem{DataMining_Lee01}
S.~J. Lee and K.~Siau.
\newblock A review of data mining techniques.
\newblock {\em Industrial Management \& Data Systems}, 101(1):41--46, 2001.

\bibitem{user_classification_ml_13}
A.~Leontjeva, M.~Goldszmidt, Y.~Xie, F.~Yu, and M.~Abadi.
\newblock Early security classification of skype users via machine learning.
\newblock In {\em Proceedings of the 2013 ACM Workshop on Artificial
  Intelligence and Security}, AISec '13, pages 35--44, New York, NY, USA, 2013.
  ACM.

\bibitem{pol_evol_gp_3_approaches_08}
Y.~T. Lim, P.~C. Cheng, J.~Clark, and P.~Rohatgi.
\newblock Policy evolution with genetic programming: A comparison of three
  approaches.
\newblock In {\em Evolutionary Computation, 2008. CEC 2008. (IEEE World
  Congress on Computational Intelligence). IEEE Congress on}, pages 1792--1800,
  June 2008.

\bibitem{sec_policy_evolution_gp_08}
Y.~T. Lim, P.~C. Cheng, P.~Rohatgi, and J.~A. Clark.
\newblock Mls security policy evolution with genetic programming.
\newblock In {\em Proceedings of the 10th Annual Conference on Genetic and
  Evolutionary Computation}, GECCO '08, pages 1571--1578, New York, NY, USA,
  2008. ACM.

\bibitem{MIT05}
R.~Lippmann, K.~Ingols, C.~Scott, K.~Piwowarski, K.~Kratkiewicz, M.~Artz, and
  R.~Cunningham.
\newblock Evaluating and strengthening enterprise network security using attack
  graphs.
\newblock Project report ia-2, Massachusetts Institute of Technology, Lincoln
  Laboratory, October 2005.

\bibitem{detecting_intrusion_gp_03}
W.~Lu and L.~Traore.
\newblock Detecting new forms of network intrusion using genetic programming.
\newblock In {\em Proceedings of the 2003 Congress on Evolutionary
  Computation}, pages 2165--2172, 2003.

\bibitem{classification_67}
J.~MacQueen et~al.
\newblock Some methods for classification and analysis of multivariate
  observations.
\newblock In {\em Proceedings of the fifth Berkeley symposium on mathematical
  statistics and probability}, volume~1, page~14. California, USA, 1967.

\bibitem{MUSES_SAC_14}
A.~Mora, P.~De~las Cuevas, J.~Merelo, S.~Zamarripa, M.~Juan,
  A.~Esparcia-Alcázar, M.~Burvall, H.~Arfwedson, and Z.~Hodaie.
\newblock {MUSES: A corporate user-centric system which applies computational
  intelligence methods}.
\newblock In D.~S. et~al., editor, {\em 29th Symposium On Applied Computing},
  pages 1719--1723, 2014.

\bibitem{ai_cybersecurity_11}
B.~Morel.
\newblock Artificial intelligence and the future of cybersecurity.
\newblock In Y.~Chen, A.~A. Cárdenas, R.~Greenstadt, and B.~I.~P. Rubinstein,
  editors, {\em AISec}, pages 93--98. ACM, 2011.

\bibitem{Opp_Security11}
R.~Oppliger.
\newblock Security and privacy in an online world.
\newblock {\em IEEE Computer}, 44(9):21--22, September 2011.

\bibitem{android11}
C.~Orthacker, P.~Teufl, S.~Kraxberger, G.~Lackner, M.~Gissing, A.~Marsalek,
  J.~Leibetseder, and O.~Prevenhueber.
\newblock Android security permissions - can we trust them?
\newblock In {\em MobiSec Session on Smartphone Security}, Aalborg, 2011.

\bibitem{BigData_11}
B.~Ratner.
\newblock {\em Statistical and Machine-Learning Data Mining: Techniques for
  Better Predictive Modeling and Analysis of Big Data, Second Edition}.
\newblock CRC Press, Inc., Boca Raton, FL, USA, 2nd edition, 2011.

\bibitem{policy_generation_clustering_10}
T.~Samak and E.~Al-Shaer.
\newblock Synthetic security policy generation via network traffic clustering.
\newblock In {\em Proceedings of the 3rd ACM Workshop on Artificial
  Intelligence and Security}, AISec '10, pages 45--53, New York, NY, USA, 2010.
  ACM.

\bibitem{SecPolComp09}
R.~Shaw, C.~Chen, A.~Harris, and H.-J. Huang.
\newblock The impact of information richness on information security awareness
  training effectiveness.
\newblock {\em Computers \& Education}, 52:92--100, 2009.

\bibitem{SecPolComp07}
M.~Siponen, S.~Pahnila, and A.~Mahmood.
\newblock {\em {New Approaches for Security, Privacy and Trust in Complex
  Environments}}, volume 232, chapter {Employees' adherence to information
  security policies: an empirical study}, pages 133--144.
\newblock IFIP International Federation for Information Processing, 2007.

\bibitem{AAI_book_2009}
A.~Solanas and A.~Martínez-bal.
\newblock {\em Advances in Artificial Intelligence for Privacy Protection and
  Security}.
\newblock World Scientific Publishing Co., Inc., River Edge, NJ, USA, 2009.

\bibitem{rule_generation_gp_09}
G.~Suarez-Tangil, E.~Palomar, J.~Fuentes, J.~Blasco, and A.~Ribagorda.
\newblock Automatic rule generation based on genetic programming for event
  correlation.
\newblock In l.~Herrero, P.~Gastaldo, R.~Zunino, and E.~Corchado, editors, {\em
  Computational Intelligence in Security for Information Systems}, volume~63 of
  {\em Advances in Intelligent and Soft Computing}, pages 127--134. Springer
  Berlin Heidelberg, 2009.

\bibitem{risk_reduction_ga_12}
A.~Tamjidyamcholo.
\newblock Genetic algorithm approach for risk reduction of information
  security.
\newblock {\em International Journal of Cyber-Security and Digital Forensics
  (IJCSDF)}, 1(1), 2012.

\bibitem{GAs_security_protocols_10}
L.~Zarza, J.~Forné~Muñoz, J.~R. Pegueroles~Vallés, and M.~Soriano~Ibáñez.
\newblock {\em Advances in artificial intelligence for privacy protection and
  security}, chapter Genetic algorithms for designing network security
  protocols, pages 325--358.
\newblock World Scientific, 2010.

\bibitem{eval_security_gas_07}
L.~Zarza, J.~Pegueroles, and M.~Soriano.
\newblock Evaluation function for synthesizing security protocols by means of
  genetic algorithms.
\newblock In {\em Proceedings of the The Second International Conference on
  Availability, Reliability and Security}, ARES '07, pages 1207--1213,
  Washington, DC, USA, 2007. IEEE Computer Society.

\bibitem{cryptographic_gas_06}
L.~Zarza, J.~Pegueroles, M.~Soriano, and R.~Martínez.
\newblock Design of cryptographic protocols by means of genetic algorithms
  techniques.
\newblock In M.~Malek, E.~Fernández-Medina, and J.~Hernando, editors, {\em
  SECRYPT}, pages 316--319. INSTICC Press, 2006.

\end{thebibliography}
\end{document}
