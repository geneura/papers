% --------------------------------------------------------------------------
% @brief Artículo sobre L-Co-R aplicado a datos de SIPESCA
% @author Víctor M. Rivas Santos (vrivas@ujaen.es)
% @date 28-Oct-2014
%
% Atención: Utilizar codificación ISO-8859-1 para que compile correctamente
% --------------------------------------------------------------------------
\documentclass[twocolumn]{maeb2015}
\usepackage[spanish]{babel}
\usepackage[latin1]{inputenc}
\usepackage{graphicx}
\usepackage{caption}
     
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


\newtheorem{theorem}{Teorema}

\begin{document}

\title{Predicción a muy corto plazo de series temporales de volumen de tráfico rodado mediante co-evolución de RBFNs } %!PN

\author{
Víctor M. Rivas$^{1}$\thanks{$^{1}$Departamento de Informática. Escuela Politécnica Superior de Jaén. Univ. de Jaén
E-mail: vrivas@ujaen.es}, 
Elisabet Parras-Gutiérrez$^{1}$, 
Antonio Fernández-Ares$^{2}$\thanks{$^{2}$Departamento de Arquitectura y Tecnología de Computadores. Univ. de Granada},
Pedro A. Castillo$^{2}$,
Pedro García-Fernández$^{3}$\thanks{$^{3}$Departamento de Electrónica y Tecnología de Computadores. Univ. de Granada},

}

\maketitle

\begin{abstract}
Este es el resumen del trabajo.!!!Escribir
\end{abstract}

\begin{keywords}
Algoritmos coevolutivos, Predicción de tráfico, Series temporales, Redes Neuronales de Funciones Base Radiales
\end{keywords}

\section{Introducción}
 Recuerde incrustar las fuentes en el PDF. !!!Eliminar


La predicción en tiempo real del tráfico de vehículos por carretera o ciudad se ha convertido en una necesidad cada vez más demandada tanto por las administraciones como por los propios usuarios~\cite{Min2011606}. Por este motivo, cada vez existen más mecanismos que permiten medir el volumen del tráfico, generando una vasta cantidad de información pendiente de ser debidamente tratada y analizada para obtener predicciones cada vez más fiables. Actualmente, la posibilidad de obtener datos en tiempo real sobre volumen de tráfico o velocidades medias en numerosos puntos de las redes viales es ya un hecho; sin embargo, la toma de decisiones acerca de las medidas a tomar y la predicción de en qué modo aumentarán o disminuirán ambas variables sigue siendo una tarea que llevan a cabo tanto los gestores de las salas de control de tráfico como los propios conductores.

Durante los tres últimos años, gracias al proyecto SIPESCA\footnote{http://sipesca.ugr.es/}, se ha desarrollado y puesto en marcha una nueva técnica para estimar el número de vehículos que circulan por una vía, así como su velocidad. En concreto, se han ubicado en distintos puntos de Andalucía (tanto en ciudad como en autovía) unos sensores capaces de detectar, almacenar y transmitir el identificador único de los dispositivos Bluetooth de los vehículos que circulan próximos a cada sensor. La base de datos que se ha generado (y que sigue mejorándose y ampliándose) es ahora un recurso de enorme valor desde el cual estamos realizando distintos tipos de estudio, tanto por su capacidad de proporcionar información en tiempo real como por las posibilidades que ofrece para realizar predicciones.

Partiendo de los datos recopilados por el proyecto SIPESCA, este trabajo presenta los resultados obtenidos al aplicar distintas métricas y métodos de predicción de series temporales, entre ellos el algoritmo co-evolutivo {L-Co-R} \cite{parras2012}) para la predicción a muy corto plazo de volumen de tráfico. Concretamente, el trabajo se centra en la predicción a 15 minutos, 30 minutos, 45 minutos y 1 hora. La motivación para usar concretamente estos tiempos coincide con la indicada por Min y Wynter en \cite{Min2011606}: por un lado, las oficinas de gestión de tráfico necesitan actualizar de forma dinámica la señalización y mensajes dirigidos a ordenar correctamente el tráfico, y para ello deben basarse en las condiciones previstas para el tráfico en un futuro cercano, no en predicciones hechas con mucha anterioridad y que pueden estar totalmente obsoletas. Por otro lado, los propios conductores solicitan cada vez más información y predicciones actualizadas en el mismo instante en que están desarrollando la actividad de conducir, mostrando poca confianza en las condiciones que existían cuando planificaron el trayecto.

Uno de los aspectos más innovadores que introducimos en este trabajo es la selección del conjunto de valores pasados que utilizaremos para construir el modelo con el que realizar la predicción. En este sentido, hemos considerado solamente los datos recopilados en las últimas 24 horas. Los motivos son dos: en primer lugar, permite tratar el problema bajo el paradigma correcto de la predicción de series temporales, esto es, utilizar un conjunto de datos consecutivos para realizar una predicción más o menos diferida en el tiempo\footnote{Este importante aspecto fue puesto de manifiesto por los ganadores de la competición de predicción de series temporales realizada en el simposio SICO, integrado dentro del congreso CEDI 2010 realizado en Zaragoza)}. En segundo lugar, nos permite situar un punto de referencia para futuros trabajos ya planificados en los cuales la construcción del modelo predictor se realizará en dispositivos de poca capacidad de cálculo y almacenamiento, los cuales cooperarán en un entorno distribuido logrando mejorar las soluciones usando un enfoque colaborativo. Estos trabajos se enmarcan dentro de una línea de investigación ya iniciada en Rivas et al. \cite{EvoStar2014:jsEO} y Merelo et al. \cite{DBLP:conf/gecco/GuervosVGES14}, y permitirán la descentralización del proceso de creación de los modelos predictores al mismo tiempo que la difusión de los mismos a los dispositivos interesados en explotarlos.

El resto del trabajo se compone de los siguientes apartados: la sección \ref{sec:soa} describe el estado del arte del problema tratado; la sección \ref{sec:metodologia} presenta tanto los datos que se han utilizado, como los algoritmos empleados y las medidas de error que se permiten comparar la bondad de los mismos; a continuación, la sección \ref{sec:resultados} se presentan los resultados que se han obtenido, utilizando para ello un resumen del número de veces que cada algoritmo ha hallado el modelo que devolvía el menor error. Finalmente, en la sección \ref{sec:conclusiones} se destacan las principales conclusiones obtenidas.



\section{Estado del arte}
\label{sec:soa}
Existen numerosos ejemplos en la literatura en los que el problema de predicción de tráfico a 15 minutos ha sido tratado. En la mayor parte de ellos, el método utilizado ha sido ARIMA \cite{BoxJenk}, como por ejemplo en Smith et al. \cite{Smith2002303} donde se compara la técnica del vecino más cercano con los modelos autorregresivos. Un trabajo más reciente es el correspondiente a Chandra y Al-Deek \cite{Chandra200953} que, como el anterior está centrado en los modelos ARIMA; a su vez ambos trabajos son similares al realizado por Min y Wynter \cite{Min2011606} en cuanto a la metodología utilizada, consistente en !!!

Desde hace una década, es posible encontrar trabajos en los que distintos tipos de redes neuronales han sido empleados para predecir problemas similares, tales como los trabajos de Van Lint et al. \cite{vanLint2005347}, Vlahogianni et al. \cite{Vlahogianni2005211} y Zheng et al. \cite{Zheng2006114}. Este último, realiza un enfoque muy similar al nuestro, capturando los datos en zonas puntuales y tratando de predecir el volumen de tráfico de los 15 minutos que siguen al último dato registrado. No obstante, los autores exclyen de la captura de datos las horas correspondientes a la noche, así como los fines de semana.

!!!Hablar de que no tratan los datos como ST y describir bien el de Min

!!! Describir L-Co-R, trabajos ya realizados

%Kamarianakis and Prastacos (2003) estimate parameters in a model that takes into account both spatial and temporal correlations across the road network. While the basic form of their model has some similarity to ours, significant differences exist. Their model requires estimating a very large number of parameters, and yet does not take into account several important characteristics of a transportation network. In particular, they assume that the spatial correlations are represented by a fixed set of matrices, which depend upon the distances between links. However, on a transportation network, depending upon whether a link is congested or not, the other network links influencing its traffic flow will vary considerably. This is not captured by the approach of Kamarianakis and Prastacos (2003). Furthermore, the method proposed by the authors in Kamarianakis and Prastacos (2003) assumes stationarity of the system. While the authors note that the traffic flow parameters are clearly not stationary over the time period being modeled, they propose to perform differencing of the data points, with a differencing period of 1 day. This does not, however, deal with inter-day fluctuations, which should violate the stationarity assumption and introduce non-negligible bias into the estimated parameters. A more recent work by the authors makes use of GARCH models to handle the fact that variance in the data is different at peak and off-peak times; however, the accuracy achieved was quite poor. A line of references by Wang et al. makes use of macroscopic traffic flow modeling for real-time traffic prediction. That approach can handle only segments of expressways and while no numerical accuracy is provided by the authors, the graphics do not suggest a level of accuracy near that which is provided by our method (see Wang et al., 2007 and references therein).

\section{Metodología experimental}
\label{sec:metodologia}
Los experimentos que hemos realizado se han centrado en la predicción del número de vehículos que iban a pasar  a las 07:00, 07:15, 07:30 y 07:45 del jueves, 24 de enero de 2013, por 5 sensores o nodos distintos. Los sensores están etiquetados como "347", "721", "419", "420" y "440". El día de la semana y horas escogidas están basados en los utilizados en \cite{Min2011606}. Para realizar esta predicción, se han aportado a los distintos algoritmos empleados los datos recogidos durante las 23 horas anteriores, agrupados por intervalos de 15 minutos. De esta forma, el conjunto de entrenamiento estaba formado por 92 datos, y el de test por 4 datos (ver fig. \ref{fig:datos}); dado que los datos han sido agregados de 15 en 15 minutos, este conjunto de test es equivalente a la predicción de un solo dato para cada uno de los horizontes 1, 2, 3 y 4, respectivamente.

\begin{figure*}[hbt]
  \centering
  \includegraphics[width=3in]{347.png}
 \includegraphics[width=3in]{721.png} \\
  \includegraphics[width=3in]{419.png}
 \includegraphics[width=3in]{420.png} \\
 \includegraphics[width=3in]{440.png}

  \caption[Número de dispositivos Bluetooth detectados por dispositivos "347", "721", "419", "420" y "440"]
   {Datos de entrenamiento y test consistentes en el número de dispositivos Bluetooth detectados por los nodos etiquetados como "347", "721", "419", "420" y "440". Los datos están agrupados por períodos de 15 minutos.}
\label{fig:datos}
\end{figure*}


De los cinco algoritmos que hemos utilizado, cuatro de ellos pertenecen al paquete {\em Forecast}~\cite{hyndman2007automatic} de la aplicación R: ETS ({\em Exponential smoothing state space model}, ARIMA, Croston y Theta. Cada uno de estos algoritmos ha sido ejecutado una vez, proporcionando las estimaciones de cada uno de los 4 valores a predecir.

Como quinto algoritmo, proponemos utilizar L-Co-R \cite{parras2012}. Se trata de un algoritmo co-evolutivo en el que dos poblaciones evolucionan simultáneamente de forma cooperativa. La primera de ellas es una población de redes neuronales de funciones base radiales, mientras la segunda es una población de retardos (o {\em lags}). La coevolución permite encontrar la mejor combinación entre red neuronal y conjunto de retardos a utilizar para predecir los futuros valores de una serie temporal para cualquier horizonte que se le indique como parámetro. 

En la actualidad, el algoritmo no está paralelizado, por lo que ambas poblaciones evolucionan de forma secuencial: un primer bucle realiza un proceso de evolución de las redes que son evaluadas usando el mejor conjunto de retardos hallados hasta ese momento; a continuación, es el conjunto de retardos el que es evolucionado durante algunas generaciones siendo evaluado con la mejor red encontrada hasta el momento. Ambos ciclos de evolución (o bucles interiores) se encuentran a su vez dentro de un bucle más general que itera el procedimiento anterior durante un determinado número de generaciones totales (bucle exterior).

Dado que es un algoritmo estocástico, cada experimento se ha ejecutado 30 veces y los valores que mostramos para cada uno de los errores corresponden a la media aritmética de los 30 errores obtenidos, uno por ejecución. Los parámetros con los que se han ejecutado son los establecidos por defecto para este algoritmo, esto es:

\begin{itemize}
\item Número de generaciones totales (bucle exterior): 20
\item Número de generaciones por cada evolución de retardos (bucle interior): 5
\item Número de generaciones por cada evolución de redes (bucle interior): 10
\item Número de individuos de la población de retardos: 50
\item Número de individuos de la población de redes: 50
\end{itemize}

Todas las ejecuciones se han realizado en un ordenador con sistema operativo Linux (kernel 3.13.0-32), un procesador Intel i7 a 2,8GHz y  6GB de memoria RAM. Todas las ejecuciones se han realizado mientras el ordenador se utilizaba como estación de trabajo al mismo tiempo que gestiona un servidor de páginas web que soporta un bajo número de accesos. Aunque no describimos los tiempos de ejecución, hemos de indicar que el algoritmo más costoso en este aspecto, L-Co-R, ha sido capaz de realizar las 30 ejecuciones en menos de 15 minutos para cada nodo. Por tanto, sería viable la explotación de un servicio que actualizase las previsiones en tiempo real a medida que nuevos datos fuesen siendo capturados por los sensores.

Finalmente, en relación a la medida de error a utilizar, incluimos los resultados obtenidos por cada algoritmo para cada nodo y en relación a cada uno de los 4 horizontes de predicción. Las medidas utilizadas son propuestas por \cite{giojer}, donde se indica claramente que toda medida de error posee ventajas e inconvenientes por lo que es necesario evaluar cada método con varias de ellas para tener una idea certera de la idoneidad del mismo. Las medidas que hemos utilizado son las 9 siguientes (ecuaciones \ref{eq:MAE} a \ref{eq:sMdAPE}: error cuadrático medio (MSE), raíz del error cuadrático medio (RMSE), error absoluto medio (MAE), error promedio porcentual (MPE),  error absoluto porcentual medio (MAPE), mediana del error absoluto (MdAE), mediana del error absoluto porcentual (MdAPE), media simétrica del error asoluto expresado como porcentaje (sMAPE (\%)), mediana simétrica del error absoluto expresado como porcentaje (sMdAPE (\%)).

\begin{itemize}
  \item \it{Error cuadrático medio} (MSE):
        \begin{equation}\label{eq:MSE}
            MSE = \frac{1}{n}\sum_{i=1}^n {e_t}^2
        \end{equation}

  \item \it{Raíz del error cuadrático medio} (RMSE):
        \begin{equation}\label{eq:RMSE}
            RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^n {e_t}^2}
        \end{equation}

  \item \it{Error absoluto medio} (MAE):
        \begin{equation}\label{eq:MAE}
            MAE = mean(\mid e_t\mid)
        \end{equation}

 \item \it{Error promedio porcentual} (MPE):
        \begin{equation}\label{eq:MPE}
            MPE = 100*\frac{e_t}{Y_t))
        \end{equation}

  \item \it{Error absoluto porcentual medio} (MAPE):
        \begin{equation}\label{eq:MAPE}
            MAPE = mean(\mid p_t\mid)
        \end{equation}

  \item \it{Mediana del error absoluto} (MdAE):
        \begin{equation}\label{eq:MDAPE}
            MdAPE = median(\mid e_t\mid)
        \end{equation}


  \item \it{Mediana del error abosluto porcentual} (MdAPE):
        \begin{equation}\label{eq:MDAPE}
            MdAPE = median(\mid p_t\mid)
        \end{equation}

  \item \it{Media simétrica del error asoluto expresado como porcentaje} (sMAPE (\%)):
        \begin{equation}\label{eq:MDAPE}
            sMAPE = 100mean(2*\mid Y_t-F_t] )/ (Y_t+F_t)\mid)
        \end{equation}

  \item \it{Mediana simétrica del error absoluto expresado como porcentaje} (MdAPE):
        \begin{equation}\label{eq:MDAPE}
            sMdAPE = 100median(2*\mid Y_t-F_t] )/ (Y_t+F_t)\mid)
        \end{equation}

,  (sMdAPE (\%))


donde  $Y_t$ es el dato observado en tiempo $t = {1,...,n}$; $F_t$ es la predicción de  $Y_t$; $e_t$
es el error de predicción (i.e. $e_t= Y_t - F_t$); $p_t = 100e_t/Y_t$ es el porcentaje de error y 
         $q_t = \displaystyle\frac{e_t}{\displaystyle\frac{1}{n-1} \sum_{i=2}^n \mid Y_i - Y_{i-1} \mid }$
\end{itemize}



\section{Resultados}
\label{sec:resultados}
Las tablas \ref{tablas} recogen los resultados de cada algoritmo para cada nodo, horizonte de predicción y medida de error; el menor de los valores para cada uno de las medidas de error se ha destacado sobre los demás. A modo de resumen, las tablas \ref{tablaresumen1} y \ref{tablasresumen2} muestran el número de medidas para las que cada algoritmo consigue el menor error. 
La primera de las tablas (tabla \ref{tablaresumen1}) se ha realizado teniendo en cuenta solo los algoritmos especialmente indicados para el trabajo con series temporales, esto es, todos menos el que calcula el valor promedio ({\em meanf}); mientras que la segunda (tabla \ref{tablaresumen2}) muestra el resumen de resultados incluyendo también dicho método.

\begin{table*}[htb]
\caption{Número de ocasiones en los que cada algoritmo de los especialmente diseñados para resolver series temporales (esto es sin incluir {\em meanf} de la biblioteca {\em Forecast} del paquete R) obtiene el menor error. Se contabiliza el total sobre 5 series temporales y 10 medidas de error para cada una de ellas.}
\begin{center}
{\tt
\begin{tabular}{|l||c|c|c|c|}\hline
Algoritmo & Horizonte 1 & Horizonte 2 & Horizonte 3 & Horizonte 4 \\\hline
ETS     & 7 & 3 & 12 & 8 \\\hline
ARIMA   & 9 & 11 & 3 & 9  \\\hline
CROSTON & {\bf13} & {\bf22} & 12 & {\bf16}   \\\hline
THETA   & 4 & 0 & 0 &  0  \\\hline
L-Co-R  & 12 & 9 & {\bf18} & 12  \\\hline
\end{tabular}
}
\end{center}
\label{tablaresumen1}
\end{table*}


\begin{table*}[htb]
\caption{Número de ocasiones en los que cada algoritmo obtiene el menor error, sobre 5 series temporales y 10 medidas de error para cada una de ellas. Esta tabla es similar a la tabla \ref{tablaresumen1}, variando los datos al incorporar esta vez el algoritmo {\em meanf}, el cual calcula el valor promedio como predicción de futuro. }
\begin{center}
{\tt
\begin{tabular}{|l||c|c|c|c|}\hline
Algoritmo & Horizonte 1 & Horizonte 2 & Horizonte 3 & Horizonte 4 \\\hline
ETS      & 7  & 0 & 7 & 7 \\\hline
ARIMA    & 9  & 3 & 3 & 3  \\\hline
CROSTON  & 8  & 6 & 7 & 7   \\\hline
THETA    & 4  & 0 & 0 & 0  \\\hline
MEANF    & {\bf14} & {\bf21} & {\bf28} & {\bf28} \\\hline
L-Co-R   & 3  & 15 & 0 & 0  \\\hline
\end{tabular}
}
\end{center}
\label{tablaresumen1}
\end{table*}
Comenzando por la primera tabla resumen (tabla \ref{tablaresumen1}) podemos observar que en general los algoritmos que en mayor número de ocasiones consiguen el menor error son L-Co-R y Croston. De hecho, salvo para el horizonte 2 en el que Croston obtiene los mejores resultados, L-Co-R resulta ser el algoritmo más adecuado, produciendo las predicciones más cercanas a los valores esperados. De los demás algoritmos, ETS y en ocasiones ARIMA obtienen también los errores más pequeños, siendo Theta el algoritmo que sale peor parado en cualquiera de los horizontes considerados.

No obstante, si consideramos todos los métodos incluyendo el del valor promedio, obtenemos que este último es el que consigue los mejores resultados en todos los casos (ver \ref{tablaresumen2}). En comparación con este algoritmo, todos los demás obtienen resultados que difícilmente son comparables si exceptuamos el horizonte 2, para el cual L-Co-R obtiene en el menor valor en 17 de las medidas que se han calculado.



\section{Conclusiones}
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.
Estas son las conclusiones.

\section*{Agradecimientos}
Este trabajo se está desarrollando gracias a la financiación del proyecto {\em ANYSELF :: UGR: Self-* Properties in P2P and Cloud Systems}, código TIN2011-28627-C04, financiado por el Ministerio de Ciencia e Innovación.


\bibliographystyle{maeb2015}
\bibliography{lcor-maeb-2015,geneura}

\end{document}




